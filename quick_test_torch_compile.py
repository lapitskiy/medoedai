#!/usr/bin/env python3
"""
üöÄ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç torch.compile –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
"""

import torch
import os

def quick_test():
    print("üß™ –ë–´–°–¢–†–´–ô –¢–ï–°–¢ TORCH.COMPILE")
    print("=" * 40)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    disable_compile = os.environ.get('DISABLE_TORCH_COMPILE', 'false').lower() == 'true'
    print(f"üîß DISABLE_TORCH_COMPILE: {disable_compile}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º PyTorch
    print(f"üì¶ PyTorch: {torch.__version__}")
    print(f"üîß torch.compile –¥–æ—Å—Ç—É–ø–µ–Ω: {hasattr(torch, 'compile')}")
    
    if not hasattr(torch, 'compile'):
        print("‚ùå torch.compile –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º CUDA
    print(f"üöÄ CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.cuda.is_available()}")
    
    if not torch.cuda.is_available():
        print("‚ÑπÔ∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return False
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
    device_name = torch.cuda.get_device_name()
    device_capability = torch.cuda.get_device_capability()
    
    print(f"üéØ GPU: {device_name}")
    print(f"üîç CUDA Capability: {device_capability[0]}.{device_capability[1]}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º torch.compile
    try:
        print("\nüöÄ –¢–µ—Å—Ç–∏—Ä—É—é torch.compile...")
        
        # –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å
        model = torch.nn.Linear(10, 1).to('cuda')
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–µ–∂–∏–º—ã
        if "Tesla P100" in device_name:
            print("‚ö†Ô∏è Tesla P100 - —Ç–µ—Å—Ç–∏—Ä—É—é —Ç–æ–ª—å–∫–æ —Ä–µ–∂–∏–º 'default'")
            modes_to_test = ['default']
        elif device_capability[0] >= 7:
            print("‚úÖ –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π GPU - —Ç–µ—Å—Ç–∏—Ä—É—é –≤—Å–µ —Ä–µ–∂–∏–º—ã")
            modes_to_test = ['max-autotune', 'default', 'reduce-overhead']
        else:
            print("‚ö†Ô∏è –°—Ç–∞—Ä—ã–π GPU - —Ç–µ—Å—Ç–∏—Ä—É—é –±–∞–∑–æ–≤—ã–µ —Ä–µ–∂–∏–º—ã")
            modes_to_test = ['default', 'reduce-overhead']
        
        for mode in modes_to_test:
            try:
                print(f"  üîÑ –¢–µ—Å—Ç–∏—Ä—É—é —Ä–µ–∂–∏–º '{mode}'...")
                compiled_model = torch.compile(model, mode=mode)
                
                # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω
                x = torch.randn(100, 10, device='cuda')
                _ = compiled_model(x)
                
                print(f"  ‚úÖ –†–µ–∂–∏–º '{mode}' —Ä–∞–±–æ—Ç–∞–µ—Ç!")
                return True
                
            except Exception as e:
                print(f"  ‚ùå –†–µ–∂–∏–º '{mode}' –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e}")
                continue
        
        print("‚ùå –ù–∏ –æ–¥–∏–Ω —Ä–µ–∂–∏–º –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        return False
        
    except Exception as e:
        print(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞: {e}")
        return False

if __name__ == "__main__":
    success = quick_test()
    
    if success:
        print("\nüéâ torch.compile —Ä–∞–±–æ—Ç–∞–µ—Ç!")
    else:
        print("\n‚ùå torch.compile –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print("\nüí° –†–ï–®–ï–ù–ò–Ø:")
        print("  1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ DISABLE_TORCH_COMPILE=true")
        print("  2. –ü–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä")
        print("  3. –û–±–Ω–æ–≤–∏—Ç–µ PyTorch –¥–æ –≤–µ—Ä—Å–∏–∏ 2.0+")
