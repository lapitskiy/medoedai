from dataclasses import dataclass, field
from typing import Dict, Any
import os
import torch
from datetime import datetime
from .gpu_configs import get_optimal_config, apply_gpu_config_to_vconfig
   
@dataclass
class vDqnConfig:  
    # === Œµ‚Äëgreedy exploration ===
    eps_start: float       = 1.0     # –Ω–∞—á–∞–ª—å–Ω–æ–µ Œµ
    eps_final: float       = 0.005   # –±—ã—Å—Ç—Ä–µ–µ –≤—ã–π—Ç–∏ –≤ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—é
    eps_decay_steps: int   = 1_200_000 # –æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–µ–º—Å—è –Ω–∞ ~25% –æ—Ç –ø–ª–∞–Ω–æ–≤—ã—Ö —à–∞–≥–æ–≤

    # === replay‚Äëbuffer ===
    memory_size: int       = 200_000  # –±—É–¥–µ—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ GPU-–∫–æ–Ω—Ñ–∏–≥–æ–º
    batch_size: int        = 4096     # –±—É–¥–µ—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ GPU-–∫–æ–Ω—Ñ–∏–≥–æ–º
    prioritized: bool      = True     # Prioritized Experience Replay
    alpha: float           = 0.6      # –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è PER
    beta: float            = 0.4      # importance sampling –¥–ª—è PER
    beta_increment: float  = 0.001    # —É–≤–µ–ª–∏—á–µ–Ω–∏–µ beta

    # === —Å–µ—Ç—å / –æ–±—É—á–µ–Ω–∏–µ ===
    lr: float              = 3e-4     # –±–∞–∑–æ–≤—ã–π lr; –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω GPU-–∫–æ–Ω—Ñ–∏–≥–æ–º
    gamma: float           = 0.99     # discount factor
    soft_tau: float        = 1e-2     # –º—è–≥–∫–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–∞—Ä–≥–µ—Ç–∞
    soft_update_every: int = 1        # –ø—Ä–∏–º–µ–Ω—è–µ–º –∫–∞–∂–¥—ã–π —à–∞–≥
    hidden_sizes: tuple    = (512, 256, 128)  # –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    target_update_freq: int = 5_000   # —É–≤–µ–ª–∏—á–∏–ª –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    train_repeats: int     = 2        # –º–µ–Ω—å—à–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å–≤–µ–∂–µ–º —Ä–µ–ø–ª–µ–µ
    
    # === —É–ª—É—á—à–µ–Ω–∏—è —Å–µ—Ç–∏ ===
    dropout_rate: float    = 0.1      # —É–º–µ—Ä–µ–Ω–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è DQN
    layer_norm: bool       = True     # Layer Normalization
    double_dqn: bool       = True     # Double DQN
    dueling_dqn: bool      = True     # Dueling DQN
    activation: str        = 'silu'    # Activation for MLP feature blocks
    use_residual_blocks: bool = True  # Residual skip connections inside MLP
    use_swiglu_gate: bool  = True     # SwiGLU gating inside MLP blocks
    
    # === –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –∫–ª–∏–ø–ø–∏–Ω–≥ ===
    grad_clip: float       = 0.5      # –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–∏–π –∫–ª–∏–ø–ø–∏–Ω–≥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    
    # === GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ ===
    device: str             = "cuda"      # GPU (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ DDR4 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ)
    run_name: str           = "stable-dqn"
    use_gpu_storage: bool   = True        # –•—Ä–∞–Ω–∏—Ç—å replay buffer –Ω–∞ GPU
    use_torch_compile: bool = True        # PyTorch 2.x compile –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —É—Å–∫–æ—Ä–µ–Ω–∏—è
    torch_compile_fallback: bool = True   # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π fallback –¥–ª—è —Å—Ç–∞—Ä—ã—Ö GPU
    torch_compile_force_disable: bool = False  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å torch.compile
    
    def __post_init__(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        import os
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è torch.compile
        if os.environ.get('DISABLE_TORCH_COMPILE', 'false').lower() == 'true':
            self.use_torch_compile = False
            self.torch_compile_force_disable = True
            print("‚ö†Ô∏è torch.compile –æ—Ç–∫–ª—é—á–µ–Ω —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è DISABLE_TORCH_COMPILE=true")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ GPU –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
        self._apply_gpu_optimization()
    
    def _apply_gpu_optimization(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç GPU –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —Ç–µ–∫—É—â–µ–π GPU
            gpu_config = get_optimal_config()
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            gpu_settings = apply_gpu_config_to_vconfig(gpu_config)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            self.batch_size = gpu_settings['batch_size']
            self.memory_size = gpu_settings['memory_size']
            self.hidden_sizes = gpu_settings['hidden_sizes']
            self.train_repeats = gpu_settings['train_repeats']
            self.use_amp = gpu_settings['use_amp']
            self.use_gpu_storage = gpu_settings['use_gpu_storage']
            self.lr = gpu_settings['learning_rate']
            self.use_torch_compile = gpu_settings['use_torch_compile']
            # –ù–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ GPU-–∫–æ–Ω—Ñ–∏–≥–∞
            try:
                self.eps_decay_steps = gpu_settings.get('eps_decay_steps', self.eps_decay_steps)
            except Exception:
                pass
            try:
                self.dropout_rate = gpu_settings.get('dropout_rate', self.dropout_rate)
            except Exception:
                pass
            
            print(f"üöÄ –ü—Ä–∏–º–µ–Ω–µ–Ω—ã –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è {gpu_config.name}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
            print("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    
    # === –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ ===
    use_mixed_precision: bool = True   # Mixed Precision Training
    use_amp: bool          = True      # Automatic Mixed Precision
    num_workers: int       = 8         # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ worker –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ V100)
    pin_memory: bool       = True      # pin memory –¥–ª—è GPU
    prefetch_factor: int   = 4         # prefetch factor –¥–ª—è DataLoader
    
    # === —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ===
    save_frequency: int    = 50        # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –º–æ–¥–µ–ª—å –∫–∞–∂–¥—ã–µ N —ç–ø–∏–∑–æ–¥–æ–≤
    save_only_on_improvement: bool = False  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ winrate
    
    # === Early Stopping –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ===
    early_stopping_patience: int = 3000  # –ë–∞–∑–æ–≤—ã–π patience –¥–ª—è early stopping
    min_episodes_before_stopping: int = 1000  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 500 –¥–æ 1000
    early_stopping_trend_threshold: float = 0.03  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 0.02 –¥–æ 0.03 –¥–ª—è –±–æ–ª–µ–µ –º—è–≥–∫–æ–≥–æ stopping
    long_term_patience_multiplier: float = 2.5  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 2.0 –¥–æ 2.5
    
    # === Rainbow DQN –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ===
    use_n_step_learning: bool = True      # –í–∫–ª—é—á–∏—Ç—å n-step learning
    n_step: int = 3                       # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –¥–ª—è n-step learning
    use_distributional_rl: bool = False   # –í–∫–ª—é—á–∏—Ç—å Distributional RL (–ø–æ–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–æ)
    n_atoms: int = 51                     # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ç–æ–º–æ–≤ –¥–ª—è Distributional RL
    v_min: float = -10.0                  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è Distributional RL
    v_max: float = 10.0                   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è Distributional RL
    use_noisy_networks: bool = True       # –í–∫–ª—é—á–∏—Ç—å Noisy Networks
    
    # === –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—á—ë—Ç—á–∏–∫–∏ ===
    global_step: int        = field(init=False, default=0)    
    
    # path
    model_path="dqn_model.pth"
    buffer_path="replay_buffer.pkl"
    encoder_path="encoder_only.pth"
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (GPU –∏–ª–∏ CPU), —É—á–∏—Ç—ã–≤–∞–µ–º GPU_COUNT
    _gpu_count_env = os.environ.get('GPU_COUNT', '').strip().lower()
    _want_gpu = False
    try:
        _want_gpu = (_gpu_count_env != '' and _gpu_count_env not in ('0', 'false', 'no', 'off'))
    except Exception:
        _want_gpu = False
    device = torch.device("cuda" if (_want_gpu and torch.cuda.is_available()) else "cpu")    
    
    use_wandb: bool = False
        
    tick_every: int = 1000      # —É–º–µ–Ω—å—à–∏–ª –¥–ª—è –±–æ–ª–µ–µ —á–∞—Å—Ç–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    tick_slow_ms: float = 10.0  # —É–º–µ–Ω—å—à–∏–ª –ø–æ—Ä–æ–≥ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    
    
    