import os
import uuid
import time
import json as _json
import hashlib
import platform
from datetime import datetime
import random
from collections import deque
import torch
import numpy as np
from pathlib import Path
from typing import Dict, Optional, Callable
import gymnasium as gym
import signal
import io

from tianshou.env import SubprocVectorEnv
from tianshou.data import Batch, Collector, VectorReplayBuffer
from tianshou.policy import DQNPolicy
try:
    from tianshou.trainer import offpolicy_trainer
except Exception:
    try:
        from tianshou.trainer import OffpolicyTrainer as _OffpolicyTrainer
        def offpolicy_trainer(*args, **kwargs):
            return _OffpolicyTrainer(*args, **kwargs).run()
    except Exception:
        raise
try:
    from tianshou.utils.logger import CSVLogger  # –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö
except Exception:
    CSVLogger = None

from agents.vdqn.dqnn import DQNN
from envs.dqn_model.gym.crypto_trading_env_tainshou import CryptoTradingEnvOptimized as CryptoTradingEnvOptimized
from envs.dqn_model.gym.crypto_trading_env_multi import MultiCryptoTradingEnv
from envs.dqn_model.gym.gconfig import GymConfig
from agents.vdqn.hyperparameter.symbol_overrides import get_symbol_override
from utils.config_loader import get_config_value
from utils.adaptive_normalization import adaptive_normalizer
from threading import Thread
from gymnasium.wrappers import TimeLimit
from agents.vdqn.tianshou.env_wrappers import PositionAwareEpisodeWrapper


class MaskedDQNPolicy(DQNPolicy):
    """DQNPolicy with action_mask support (mask only, no market logic).

    Mask is expected in batch.info as scalar keys: mask_0/mask_1/mask_2 (0/1).
    """

    def _extract_mask(self, batch: Batch):
        try:
            info = getattr(batch, 'info', None)
            if info is None:
                return None
            m0 = info.get('mask_0', None)
            m1 = info.get('mask_1', None)
            m2 = info.get('mask_2', None)
            if m0 is None or m1 is None or m2 is None:
                return None
            # convert to tensor shape [B, 3]
            m = np.stack([np.asarray(m0), np.asarray(m1), np.asarray(m2)], axis=-1).astype(np.int64)
            return torch.as_tensor(m, device=self.model_device)
        except Exception:
            return None

    @property
    def model_device(self):
        try:
            return next(self.model.parameters()).device
        except Exception:
            return torch.device('cpu')

    def forward(self, batch: Batch, state=None, **kwargs):
        obs = batch.obs
        if not torch.is_tensor(obs):
            obs = torch.as_tensor(np.array(obs, dtype=np.float32), device=self.model_device)
        else:
            obs = obs.to(self.model_device)
        out = self.model(obs)
        q = out[0] if isinstance(out, tuple) else out

        mask = self._extract_mask(batch)
        if mask is not None:
            try:
                q = q.clone()
                q[mask == 0] = -1e9
            except Exception:
                pass

        act = torch.argmax(q, dim=1)

        # epsilon-greedy exploration with mask-aware random choice
        eps = float(getattr(self, 'eps', 0.0) or 0.0)
        if eps > 0:
            rnd = torch.rand(act.shape[0], device=act.device)
            do_rand = rnd < eps
            if bool(do_rand.any()):
                for i in range(int(act.shape[0])):
                    if not bool(do_rand[i]):
                        continue
                    if mask is None:
                        act[i] = int(np.random.randint(0, int(q.shape[1])))
                    else:
                        allowed = torch.where(mask[i] > 0)[0]
                        if allowed.numel() > 0:
                            j = int(torch.randint(0, int(allowed.numel()), (1,), device=act.device).item())
                            act[i] = int(allowed[j].item())
        return Batch(logits=q, act=act, state=state)
from agents.vdqn.cfg.extension_config import SYMBOL_EXTENSION_CONFIG, DEFAULT_EXTENSION_CONFIG


def _symbol_code(sym: str) -> str:
    if not isinstance(sym, str) or not sym:
        return "model"
    s = sym.upper().replace('/', '')
    for suffix in ["USDT", "USD", "USDC", "BUSD", "USDP"]:
        if s.endswith(suffix):
            s = s[:-len(suffix)]
            break
    s = s.lower() if s else "model"
    if s in ("–º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–∞", "multi", "multicrypto"):
        s = "multi"
    return s


def _sha256_of_file(path: str) -> Optional[str]:
    try:
        h = hashlib.sha256()
        with open(path, 'rb') as f:
            for chunk in iter(lambda: f.read(1024 * 1024), b''):
                h.update(chunk)
        return h.hexdigest()
    except Exception:
        return None


def _format_bytes(num_bytes: int) -> str:
    try:
        gb = num_bytes / (1024 ** 3)
        if gb >= 1:
            return f"{gb:.1f} GB"
        mb = num_bytes / (1024 ** 2)
        return f"{mb:.0f} MB"
    except Exception:
        return str(num_bytes)


def _log_resource_usage(tag: str = "train", extra: str = "") -> None:
    try:
        import psutil
        process = psutil.Process(os.getpid())
        total_cpus = os.cpu_count() or 1
        cpu_total_pct = psutil.cpu_percent(interval=0.0)
        cpu_proc_pct = process.cpu_percent(interval=0.0)
        mem = psutil.virtual_memory()
        mem_total_pct = mem.percent
        mem_proc = process.memory_info().rss
        try:
            load1, _load5, _load15 = os.getloadavg()
            load_str = f"{load1:.1f}/{total_cpus}"
        except Exception:
            load_str = "n/a"
        line = (
            f"[RES-{tag}] CPU {cpu_total_pct:.0f}% (proc {cpu_proc_pct:.0f}%), load {load_str}, "
            f"mem {mem_total_pct:.0f}% (proc {_format_bytes(mem_proc)})"
            + (f" | {extra}" if extra else "")
        )
        print(line, flush=True)
    except Exception:
        pass


# –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è env: –ø—Ä–æ–∫–∏–¥—ã–≤–∞–µ—Ç —Ç—Ä–µ–π–¥—ã/–º–µ—Ç—Ä–∏–∫–∏ –≤ info –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —ç–ø–∏–∑–æ–¥–∞
class TradingEnvWrapper(gym.Env):
    def __init__(self, env):
        self.env = env
        # –ü—Ä–æ–∫—Å–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã/–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
        self.action_space = getattr(env, 'action_space', None)
        self.observation_space = getattr(env, 'observation_space', None)
        self.observation_space_shape = getattr(env, 'observation_space_shape', None)
        self.symbol = getattr(env, 'symbol', None)
        self.cfg = getattr(env, 'cfg', None)
        # –°—á–µ—Ç—á–∏–∫–∏ —ç–ø–∏–∑–æ–¥–∞ –¥–ª—è –ª–∞–∫–æ–Ω–∏—á–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self._episode_idx = -1
        self._episode_steps = 0

        # –°–Ω–∏–º–æ–∫ –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏—á–∏–Ω –ø—Ä–æ–¥–∞–∂ –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–∞—Ö —ç–ø–∏–∑–æ–¥–æ–≤
        self.cumulative_sell_stats = {}
        self._episode_reward = 0.0

    def reset(self, *args, **kwargs):
        # –§–æ—Ä—Å–∏—Ä—É–µ–º –¥–ª–∏–Ω—É —ç–ø–∏–∑–æ–¥–∞ –Ω–∞ –≤—Ö–æ–¥–µ
        target_len = kwargs.get('episode_length') if 'episode_length' in kwargs else None
        if target_len is None and args:
            try:
                target_len = args[0]
            except Exception:
                target_len = None
        if target_len is None:
            target_len = getattr(self.env, 'episode_length', None)

        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º cfg –∏ env –¥–ª–∏–Ω—É —ç–ø–∏–∑–æ–¥–∞
        try:
            if target_len is not None:
                target_len = int(target_len)
                if hasattr(self.env, 'cfg'):
                    setattr(self.env.cfg, 'episode_length', target_len)
                if hasattr(self.env, 'episode_length'):
                    self.env.episode_length = target_len
        except Exception:
            pass

        result = self.env.reset(*args, **kwargs)
        # –ù–æ–≤—ã–π —ç–ø–∏–∑–æ–¥
        try:
            self._episode_idx += 1
            self._episode_steps = 0
            self._episode_reward = 0.0
            try:
                cfg_len = getattr(self.env.cfg, 'episode_length', None) if hasattr(self.env, 'cfg') else None
                env_len = getattr(self.env, 'episode_length', None)
                print(f"‚û°Ô∏è Reset env: cfg_episode_length={cfg_len} env_episode_length={env_len}")
            except Exception:
                pass
        except Exception:
            pass
        if isinstance(result, tuple) and len(result) == 2:
            obs, info = result
        else:
            obs, info = result, {}
        return obs, info

    def step(self, action):
        result = self.env.step(action)
        if isinstance(result, tuple) and len(result) == 5:
            state_next, reward, terminated, truncated, info = result
        else:
            # –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º API (obs, reward, done, info)
            state_next, reward, done, info = result
            terminated = bool(done)
            truncated = False

        self._episode_steps += 1
        self._episode_reward = float(self._episode_reward) + float(reward)

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–≥—Ä–∞–¥—ã –ø–æ cfg.reward_scale (–∫–∞–∫ –≤ legacy DQN)
        try:
            rs = 1.0
            if hasattr(self.env, 'cfg') and hasattr(self.env.cfg, 'reward_scale'):
                rs = float(getattr(self.env.cfg, 'reward_scale', 1.0))
            reward = float(reward) * rs
        except Exception:
            pass

        # –î–ª–∏–Ω—É —ç–ø–∏–∑–æ–¥–∞ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –±–∞–∑–æ–≤–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ/TimeLimit

        # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –ª–æ–≥–∏ —É–±—Ä–∞–Ω—ã —Ä–∞–¥–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏; –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–µ
        try:
            if terminated or truncated:
                # –°–æ–±–∏—Ä–∞–µ–º —Ç—Ä–µ–π–¥—ã –∑–∞ —ç–ø–∏–∑–æ–¥, –µ—Å–ª–∏ env –∏—Ö —Ö—Ä–∞–Ω–∏—Ç
                trades = []
                for attr in ('all_trades', 'trades'):
                    if hasattr(self.env, attr) and getattr(self.env, attr):
                        try:
                            trades = list(getattr(self.env, attr))
                            break
                        except Exception:
                            trades = []
                # –ö–ª–æ–Ω–∏—Ä—É–µ–º info –∏ –¥–æ–±–∞–≤–∏–º –∫–ª—é—á —Ç–æ–ª—å–∫–æ –Ω–∞ boundary —à–∞–≥–∞—Ö
                if not isinstance(info, dict):
                    info = {}
                info = dict(info)
                if trades:
                    info['trades_episode'] = trades
                # –°–Ω–∏–º–µ–º —Å–Ω–∞–ø—à–æ—Ç cumulative_sell_types –¥–æ reset() —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã Collector
                try:
                    base_env = self.env
                    for _ in range(10):
                        if hasattr(base_env, 'env'):
                            base_env = getattr(base_env, 'env')
                        else:
                            break
                    st = getattr(base_env, 'cumulative_sell_types', None)
                    if isinstance(st, dict):
                        self.cumulative_sell_stats = dict(st)
                except Exception:
                    pass
                # –ü—Ä–æ–∫—Å–∏—Ä—É–µ–º buy-* –º–µ—Ç—Ä–∏–∫–∏, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –≤ env
                for k_src, k_dst in (
                    ('buy_attempts', 'buy_attempts'),
                    ('buy_rejected_vol', 'buy_rejected_vol'),
                    ('buy_rejected_roi', 'buy_rejected_roi'),
                ):
                    if hasattr(self.env, k_src):
                        try:
                            info[k_dst] = int(getattr(self.env, k_src) or 0)
                        except Exception:
                            pass
                # –ö—Ä–∞—Ç–∫–∞—è —Å—Ç—Ä–æ–∫–∞ –ª–æ–≥–∞ –ø–æ —ç–ø–∏–∑–æ–¥—É ¬´–∫–∞–∫ –≤ dqn¬ª
                try:
                    act_stats = getattr(self.env, 'action_counts', {}) if hasattr(self.env, 'action_counts') else {}
                    eps_val = getattr(self.env, 'epsilon', None)
                    trades_cnt = len(trades) if isinstance(trades, list) else (len(getattr(self.env, 'trades', []) or []) if hasattr(self.env, 'trades') else 0)
                    print(
                        f"üèÅ Ep {self._episode_idx}: steps={self._episode_steps} reward={self._episode_reward:.4f} "
                        f"actions={act_stats} trades={trades_cnt}"
                        + (f" eps={eps_val:.3f}" if isinstance(eps_val, (int, float)) else "")
                    )
                except Exception:
                    pass
        except Exception:
            pass
        try:
            info = _sanitize_info_for_tianshou(info)
        except Exception:
            pass
        return state_next, reward, terminated, truncated, info

    # –ü—Ä–æ–∫—Å–∏—Ä—É–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    def __getattr__(self, item):
        return getattr(self.env, item)


def _export_norm_stats_safe(dfs: Dict, episode_length: Optional[int]) -> Optional[dict]:
    try:
        env = make_env_fn(dfs, episode_length)()
        stats = None
        if hasattr(env, 'export_normalization_stats'):
            stats = env.export_normalization_stats()
        # –ü–æ–ø—ã—Ç–∫–∞ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –∑–∞–∫—Ä—ã—Ç—å, –µ—Å–ª–∏ –µ—Å—Ç—å close
        try:
            if hasattr(env, 'close'):
                env.close()
        except Exception:
            pass
        return stats
    except Exception:
        return None


def _try_load_legacy_replay(path: str, buf) -> bool:
    """–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç replay.pkl –≤ –±—É—Ñ–µ—Ä Tianshou.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–∏: {states, actions, rewards, next_states, dones}.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ —É–¥–∞–ª–æ—Å—å —á—Ç–æ-—Ç–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å.
    """
    try:
        import pickle
        if not os.path.isfile(path):
            return False
        with open(path, 'rb') as f:
            data = pickle.load(f)
        # –í–∞—Ä–∏–∞–Ω—Ç 1: —Å–ª–æ–≤–∞—Ä—å –º–∞—Å—Å–∏–≤–æ–≤
        if isinstance(data, dict):
            states = data.get('states') or data.get('state')
            actions = data.get('actions') or data.get('action')
            rewards = data.get('rewards') or data.get('reward')
            next_states = data.get('next_states') or data.get('next_state')
            dones = data.get('dones') or data.get('done')
            if states is not None and actions is not None and rewards is not None and next_states is not None and dones is not None:
                n = min(len(states), len(actions), len(rewards), len(next_states), len(dones))
                imported = 0
                for i in range(n):
                    try:
                        s = states[i]
                        a = int(actions[i])
                        r = float(rewards[i])
                        sn = next_states[i]
                        d = bool(dones[i])
                        buf.add(s, a, r, d, sn, {})
                        imported += 1
                    except Exception:
                        continue
                if imported > 0:
                    print(f"‚ôªÔ∏è  –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –∏–∑ legacy replay: {imported}")
                    return True
        # –í–∞—Ä–∏–∞–Ω—Ç 2: —Å–ø–∏—Å–æ–∫ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (s,a,r,sn,d)
        if isinstance(data, list):
            imported = 0
            for item in data:
                try:
                    if isinstance(item, (list, tuple)) and len(item) >= 5:
                        s, a, r, sn, d = item[:5]
                        buf.add(s, int(a), float(r), bool(d), sn, {})
                        imported += 1
                except Exception:
                    continue
            if imported > 0:
                print(f"‚ôªÔ∏è  –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –∏–∑ legacy —Å–ø–∏—Å–∫–∞: {imported}")
                return True
    except Exception as e:
        print(f"‚ö†Ô∏è –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä legacy replay: {e}")
    return False


def _is_multi_crypto(dfs: Dict) -> bool:
    try:
        if dfs and isinstance(dfs, dict):
            k = list(dfs.keys())[0]
            return isinstance(k, str) and k.endswith('USDT')
    except Exception:
        return False
    return False


def make_env_fn(
    dfs: Dict,
    episode_length: Optional[int],
    gym_override: Optional[GymConfig] = None,
    *,
    enable_extension: bool = True,
) -> Callable[[], CryptoTradingEnvOptimized]:
    # –û–ø—Ä–µ–¥–µ–ª–∏–º —Å–∏–º–≤–æ–ª (–µ—Å–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
    symbol = None
    try:
        if isinstance(dfs, dict):
            symbol = dfs.get('symbol') or dfs.get('SYMBOL')
    except Exception:
        symbol = None

    # –ü–æ–ª—É—á–∏–º overrides –ø–æ —Å–∏–º–≤–æ–ª—É
    override = get_symbol_override(symbol) if symbol else None
    indicators_config = override.get('indicators_config') if (override and 'indicators_config' in override) else None

    def _thunk():
        gym_cfg = gym_override or GymConfig()
        # –í—ã—Ä–æ–≤–Ω—è–µ–º –¥–ª–∏–Ω—É —ç–ø–∏–∑–æ–¥–∞ –≤ cfg —Å –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º, —á—Ç–æ–±—ã done —Å—Ä–∞–±–∞—Ç—ã–≤–∞–ª –ø–æ –æ–∂–∏–¥–∞–µ–º–æ–π –¥–ª–∏–Ω–µ
        try:
            if episode_length is not None:
                gym_cfg.episode_length = int(episode_length)
        except Exception:
            pass
        if _is_multi_crypto(dfs):
            # Multi-crypto env –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç episode_length –Ω–∞–ø—Ä—è–º—É—é
            env = MultiCryptoTradingEnv(dfs=dfs, cfg=gym_cfg)
        else:
            env = CryptoTradingEnvOptimized(
                dfs=dfs,
                cfg=gym_cfg,
                lookback_window=(override.get('gym_config', {}).get('lookback_window', gym_cfg.lookback_window) if override else gym_cfg.lookback_window),
                indicators_config=indicators_config,
                episode_length=episode_length or gym_cfg.episode_length,
            )
        # –°–Ω–∞—á–∞–ª–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å API: –Ω–∞—à wrapper –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 5 –∑–Ω–∞—á–µ–Ω–∏–π
        try:
            env = TradingEnvWrapper(env)
        except Exception:
            pass
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º –ø—Ä–æ–¥–ª–µ–Ω–∏–µ —ç–ø–∏–∑–æ–¥–∞ –¥–ª—è train-–æ–∫—Ä—É–∂–µ–Ω–∏–π; –¥–ª—è test ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º TimeLimit
        if enable_extension:
            try:
                sym_key = None
                try:
                    if _is_multi_crypto(dfs):
                        sym_key = 'MULTI'
                    else:
                        sym_key = (symbol or '').upper() if isinstance(symbol, str) else None
                except Exception:
                    sym_key = None
                cfg_ext = DEFAULT_EXTENSION_CONFIG
                if isinstance(sym_key, str) and sym_key in SYMBOL_EXTENSION_CONFIG:
                    cfg_ext = SYMBOL_EXTENSION_CONFIG[sym_key]
                env = PositionAwareEpisodeWrapper(
                    env,
                    max_extension=int(cfg_ext.get('max_extension', 20)),
                    extension_steps=int(cfg_ext.get('extension_steps', 100)),
                )
            except Exception:
                # –§–æ–ª–±—ç–∫: –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å –≤—Ä–∞–ø–ø–µ—Ä ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º TimeLimit
                try:
                    max_steps = int(episode_length or gym_cfg.episode_length or 0)
                    if max_steps and max_steps > 0:
                        env = TimeLimit(env, max_episode_steps=max_steps)
                except Exception:
                    pass
        else:
            # –î–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏–π –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º TimeLimit, —á—Ç–æ–±—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
            try:
                max_steps = int(episode_length or gym_cfg.episode_length or 0)
                if max_steps and max_steps > 0:
                    env = TimeLimit(env, max_episode_steps=max_steps)
            except Exception:
                pass
        # –ü—Ä–∏–º–µ–Ω–∏–º risk-management overrides –≤ env
        try:
            if override and 'risk_management' in override:
                rm = override['risk_management']
                for field_name, env_attr in [
                    ('STOP_LOSS_PCT', 'STOP_LOSS_PCT'),
                    ('TAKE_PROFIT_PCT', 'TAKE_PROFIT_PCT'),
                    ('min_hold_steps', 'min_hold_steps'),
                    ('volume_threshold', 'volume_threshold'),
                ]:
                    if field_name in rm:
                        setattr(env, env_attr, rm[field_name])
        except Exception:
            pass
        return env

    return _thunk


def train_tianshou_dqn(
    dfs: Dict,
    episodes: int = 2000,
    n_envs: int = 4,
    batch_size: int = 256,
    lr: float = 1e-3,
    gamma: float = 0.99,
    n_step: int = 1,
    target_update_freq: int = 500,
    memory_size: int = 500_000,
    episode_length: Optional[int] = None,
    run_id: Optional[str] = None,
    symbol_hint: Optional[str] = None,
    # –î–æ–ø. –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    parent_run_id: Optional[str] = None,
    root_id: Optional[str] = None,
    load_model_path: Optional[str] = None,
    load_buffer_path: Optional[str] = None,
    save_frequency: int = 50,
    buffer_save_frequency: Optional[int] = None,
    save_replay_on_improvement: bool = True,
    seed: Optional[int] = None,
) -> str:
    # –ñ—ë—Å—Ç–∫–æ –æ–≥—Ä–∞–Ω–∏—á–∏–º –ø–æ—Ç–æ–∫–∏ BLAS/Torch, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –æ–≤–µ—Ä—Å–∞–±—Å–∫—Ä–∏–ø—à–Ω–∞ –ø—Ä–∏ n_envs > 1
    os.environ.setdefault("OMP_NUM_THREADS", "1")
    os.environ.setdefault("MKL_NUM_THREADS", "1")
    os.environ.setdefault("NUMEXPR_NUM_THREADS", "1")
    os.environ.setdefault("TORCH_NUM_THREADS", "1")
    try:
        torch.set_num_threads(1)
    except Exception:
        pass

    # Seed / –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º (–Ω–∞—Å–∫–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω–æ)
    # –ê–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è seed, –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω
    if not isinstance(seed, int):
        try:
            seed = int.from_bytes(os.urandom(4), 'little')
        except Exception:
            try:
                seed = int(time.time()) % (2**31)
            except Exception:
                seed = 42
        try:
            print(f"üé≤ –ò—Å–ø–æ–ª—å–∑—É–µ–º seed: {seed}")
        except Exception:
            pass
    try:
        if isinstance(seed, int):
            random.seed(seed)
            np.random.seed(seed)
            torch.manual_seed(seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed_all(seed)
    except Exception:
        pass
    # –í—Ä–µ–º—è —Å—Ç–∞—Ä—Ç–∞ –æ–±—É—á–µ–Ω–∏—è
    training_start_time = time.time()

    # –í–∫–ª—é—á–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–º–ø –∏—Å–∫–ª—é—á–µ–Ω–∏–π –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ —Ö—É–∫–∏
    try:
        import faulthandler, sys, traceback, threading as _threading
        try:
            faulthandler.enable()
            # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –¥–∞–º–ø–∞ —Ç—Ä–µ–π—Å–±–µ–∫–æ–≤
            for sig in (signal.SIGTERM, signal.SIGINT, signal.SIGSEGV, signal.SIGABRT):
                try:
                    faulthandler.register(sig, chain=True)
                except Exception:
                    pass
        except Exception:
            pass
        try:
            def _global_excepthook(exc_type, exc, tb):
                try:
                    print("UNCAUGHT:", "".join(traceback.format_exception(exc_type, exc, tb)), flush=True)
                except Exception:
                    pass
            sys.excepthook = _global_excepthook
        except Exception:
            pass
        try:
            # –î–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏–π –≤ –ø–æ—Ç–æ–∫–∞—Ö Python>=3.8
            def _thread_excepthook(args):
                try:
                    print("THREAD EXC:", "".join(traceback.format_exception(args.exc_type, args.exc_value, args.exc_traceback)), flush=True)
                except Exception:
                    pass
            if hasattr(_threading, 'excepthook'):
                _threading.excepthook = _thread_excepthook
        except Exception:
            pass
    except Exception:
        pass

    single_env = make_env_fn(dfs, episode_length)()
    obs_dim = getattr(single_env, 'observation_space_shape', None)
    if obs_dim is None and hasattr(single_env, 'observation_space') and hasattr(single_env.observation_space, 'shape'):
        obs_dim = int(single_env.observation_space.shape[0])
    if obs_dim is None:
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä –Ω–∞–±–ª—é–¥–µ–Ω–∏—è (obs_dim)")

    act_dim = single_env.action_space.n
    action_space_gym = getattr(single_env, 'action_space', None)
    if _is_multi_crypto(dfs):
        symbol = '–ú–£–õ–¨–¢–ò–í–ê–õ–Æ–¢–ê'
    else:
        symbol = getattr(single_env, 'symbol', symbol_hint or 'UNKNOWN')
    symbol_dir = _symbol_code(symbol).upper()
    # –ü—Ä–∏–∫–∏–Ω–µ–º –±—é–¥–∂–µ—Ç –ø–∞–º—è—Ç–∏ –¥–ª—è –±—É—Ñ–µ—Ä–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤: –æ–≥—Ä–∞–Ω–∏—á–∏–º –ø–æ TS_REPLAY_MEM_MB
    try:
        replay_mem_mb_cfg = int(str(get_config_value('TS_REPLAY_MEM_MB', '1024')))
    except Exception:
        replay_mem_mb_cfg = 1024
    try:
        # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: –¥–≤–∞ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –ø–æ obs_dim float32 + –∑–∞–ø–∞—Å 1 KB –Ω–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        bytes_per_sample = (int(obs_dim) * 4) * 2 + 1024
        max_samples_by_budget = max(10_000, (replay_mem_mb_cfg * 1024 * 1024) // max(1, bytes_per_sample))
        print(f"üßÆ Replay budget: obs_dim={obs_dim} ~{bytes_per_sample/1024:.1f} KB/transition, budget={replay_mem_mb_cfg} MB ‚Üí max_samples‚âà{max_samples_by_budget}")
    except Exception:
        max_samples_by_budget = None
    # –ö—ç—à–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
    norm_stats_cached = None
    try:
        if hasattr(single_env, 'export_normalization_stats'):
            norm_stats_cached = single_env.export_normalization_stats()
    except Exception:
        norm_stats_cached = None
    min_valid_start_step = getattr(single_env, 'min_valid_start_step', None)
    start_step_snapshot = getattr(single_env, 'start_step', None)
    actual_episode_length = getattr(single_env, 'episode_length', episode_length)
    if actual_episode_length is None:
        actual_episode_length = episode_length
    # –°–Ω–∏–º–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤ single_env –¥–æ —É–¥–∞–ª–µ–Ω–∏—è, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–∑–∂–µ
    try:
        single_env_snapshot = {
            'symbol': getattr(single_env, 'symbol', None),
            'lookback_window': getattr(single_env, 'lookback_window', None),
            'indicators_config': getattr(single_env, 'indicators_config', None),
            'cfg_reward_scale': (getattr(single_env.cfg, 'reward_scale', 1.0) if hasattr(single_env, 'cfg') else 1.0),
            'episode_length': getattr(single_env, 'episode_length', None),
            'position_sizing': {
                'base_position_fraction': getattr(single_env, 'base_position_fraction', None),
                'position_fraction': getattr(single_env, 'position_fraction', None),
                'position_confidence_threshold': getattr(single_env, 'position_confidence_threshold', None),
            },
            'risk_management': {
                'STOP_LOSS_PCT': getattr(single_env, 'STOP_LOSS_PCT', None),
                'TAKE_PROFIT_PCT': getattr(single_env, 'TAKE_PROFIT_PCT', None),
                'min_hold_steps': getattr(single_env, 'min_hold_steps', None),
                'volume_threshold': getattr(single_env, 'volume_threshold', None),
            },
            'observation_space_shape': getattr(single_env, 'observation_space_shape', None),
            'step_minutes': (getattr(single_env.cfg, 'step_minutes', 5) if hasattr(single_env, 'cfg') else 5),
        }
    except Exception:
        single_env_snapshot = None
    del single_env

    this_run_id = run_id or str(uuid.uuid4())[:4].lower()
    run_dir = Path("result") / "dqn" / symbol_dir / "runs" / this_run_id
    run_dir.mkdir(parents=True, exist_ok=True)
    model_path = run_dir / "model.pth"
    replay_path = run_dir / "replay.pkl"

    # –§–ª–∞–≥–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è/–æ—Ç–ª–∞–¥–∫–∏ —á–∏—Ç–∞–µ–º –î–û manifest.json
    force_dummy = False
    force_single = False
    debug_exploration = False
    debug_run = False
    try:
        v = str(get_config_value('TS_FORCE_DUMMY', '0'))
        force_dummy = v.lower() in ('1', 'true', 'yes', 'y')
    except Exception:
        force_dummy = False
    try:
        v = str(get_config_value('TS_FORCE_SINGLE', '0'))
        force_single = v.lower() in ('1', 'true', 'yes', 'y')
    except Exception:
        force_single = False
    try:
        v = str(get_config_value('TS_DEBUG_EXPLORATION', '0'))
        debug_exploration = v.lower() in ('1', 'true', 'yes', 'y')
    except Exception:
        debug_exploration = False
    try:
        v = str(get_config_value('TS_DEBUG_RUN', '0'))
        debug_run = v.lower() in ('1', 'true', 'yes', 'y')
    except Exception:
        debug_run = False

    # Initial manifest.json (–±–µ–∑—É—Å–ª–æ–≤–Ω–æ, —á—Ç–æ–±—ã –æ–Ω —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª –¥–∞–∂–µ –ø—Ä–∏ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—É—Å–∫–∞—Ö)
    try:
        initial_manifest = {
            'run_id': this_run_id,
            'parent_run_id': parent_run_id,
            'root_id': root_id or this_run_id,
            'symbol': symbol_dir,
            'seed': (int(seed) if isinstance(seed, int) else None),
            'episodes_start': 0,
            'episodes_end': 0,
            'episodes_added': 0,
            'episodes_last': 0,
            'episodes_best': None,
            'created_at': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'debug': bool(debug_run or debug_exploration),
            'debug_flags': [
                f for f, on in (
                    ('TS_DEBUG_RUN', debug_run),
                    ('TS_DEBUG_EXPLORATION', debug_exploration),
                    ('TS_FORCE_SINGLE', force_single),
                    ('TS_FORCE_DUMMY', force_dummy),
                ) if on
            ],
            'artifacts': {
                'model': 'model.pth',
                'replay': None,
                'result': 'train_result.pkl',
                'best_model': 'best_model.pth' if (run_dir / 'best_model.pth').exists() else None,
                'last_model': 'last_model.pth' if (run_dir / 'last_model.pth').exists() else None,
                'encoder_only': 'encoder_only.pth' if (run_dir / 'encoder_only.pth').exists() else None,
                'all_trades': 'all_trades.json',
            },
            'best_metrics': {
                'winrate': None,
                'reward': None,
            }
        }
        print(f"üí°[Init] –°–æ—Ö—Ä–∞–Ω—è–µ–º manifest.json –≤ {run_dir / 'manifest.json'}")
        with open(run_dir / 'manifest.json', 'w', encoding='utf-8') as mf:
            _json.dump(initial_manifest, mf, ensure_ascii=False, indent=2)
            try:
                mf.flush(); os.fsync(mf.fileno())
            except Exception:
                pass
    except Exception as me_init:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å initial manifest.json: {me_init}")
        import traceback; traceback.print_exc()

    # Tee –≤—Å–µ print –≤ —Ñ–∞–π–ª run_dir/train.log
    _orig_stdout = None
    _orig_stderr = None
    _log_fp = None
    try:
        _log_fp = open(run_dir / 'train.log', 'a', encoding='utf-8')
        class _TeeIO(io.TextIOBase):
            def __init__(self, a, b):
                self.a = a; self.b = b
            def write(self, s):
                try:
                    self.a.write(s); self.a.flush()
                except Exception:
                    pass
                try:
                    self.b.write(s); self.b.flush()
                except Exception:
                    pass
                return len(s)
            def flush(self):
                try:
                    self.a.flush()
                except Exception:
                    pass
                try:
                    self.b.flush()
                except Exception:
                    pass
        import sys as _sys
        _orig_stdout, _orig_stderr = _sys.stdout, _sys.stderr
        _sys.stdout = _TeeIO(_sys.stdout, _log_fp)
        _sys.stderr = _TeeIO(_sys.stderr, _log_fp)
    except Exception:
        pass

    # Env —É–∂–µ –æ–±—ë—Ä–Ω—É—Ç –≤ TradingEnvWrapper –≤–Ω—É—Ç—Ä–∏ make_env_fn
    def wrapped_env_fn_train():
        return make_env_fn(dfs, episode_length, enable_extension=True)()

    def wrapped_env_fn_test():
        return make_env_fn(dfs, episode_length, enable_extension=False)()
    # –§–ª–∞–≥–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è —É–∂–µ –ø—Ä–æ—á–∏—Ç–∞–Ω—ã –≤—ã—à–µ (force_dummy/force_single/debug_*)

    # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å subprocess-–≤–µ–∫—Ç–æ—Ä—ã; –ø—Ä–∏ –æ—à–∏–±–∫–µ –∏–ª–∏ —Ñ–ª–∞–≥–µ –æ—Ç–∫–∞—Ç—ã–≤–∞–µ–º—Å—è –∫ DummyVectorEnv/–æ–¥–∏–Ω–æ—á–Ω—ã–º env
    # –ü—Ä–µ—Ñ–ª–∞–π—Ç: –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –æ–¥–∏–Ω–æ—á–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ reset/step (—Ä–∞–Ω–Ω–∏–π —Ñ–µ–π–ª, –µ—Å–ª–∏ –∑–∞–≤–∏—Å–∞–Ω–∏–µ)
    try:
        _pre_env = wrapped_env_fn_train()
        try:
            _obs, _info = _pre_env.reset()
            print(f"üß™ preflight: reset ok, obs type={type(_obs)}")
            _a = _pre_env.action_space.sample()
            _res = _pre_env.step(_a)
            print("üß™ preflight: step ok")
        except Exception as _pe:
            print(f"‚ùå preflight failed: {_pe}")
            raise
        finally:
            try:
                if hasattr(_pre_env, 'close'):
                    _pre_env.close()
            except Exception:
                pass
    except Exception as _fatal_pe:
        print("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è (preflight)")
        raise

    try:
        if force_single:
            train_envs = [wrapped_env_fn_train()]
            test_envs = [wrapped_env_fn_test()]
            print("‚ÑπÔ∏è –§–æ—Ä—Å–∏—Ä–æ–≤–∞–Ω –æ–¥–∏–Ω–æ—á–Ω—ã–π Env (TS_FORCE_SINGLE)")
        elif not force_dummy:
            train_envs = SubprocVectorEnv([wrapped_env_fn_train for _ in range(n_envs)])
            test_envs = SubprocVectorEnv([wrapped_env_fn_test for _ in range(max(1, n_envs // 2))])
        else:
            from tianshou.env import DummyVectorEnv
            train_envs = DummyVectorEnv([wrapped_env_fn_train for _ in range(max(1, n_envs))])
            test_envs = DummyVectorEnv([wrapped_env_fn_test for _ in range(max(1, n_envs // 2))])
            print("‚ÑπÔ∏è –§–æ—Ä—Å–∏—Ä–æ–≤–∞–Ω DummyVectorEnv (TS_FORCE_DUMMY)")
    except Exception as e:
        print(f"‚ö†Ô∏è SubprocVectorEnv –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å, –æ—Ç–∫–∞—Ç—ã–≤–∞—é—Å—å –∫ DummyVectorEnv: {e}")
        try:
            from tianshou.env import DummyVectorEnv
            train_envs = DummyVectorEnv([wrapped_env_fn_train for _ in range(max(1, n_envs))])
            test_envs = DummyVectorEnv([wrapped_env_fn_test for _ in range(max(1, n_envs // 2))])
        except Exception as e2:
            # –§–∏–Ω–∞–ª—å–Ω—ã–π —à–∞–Ω—Å: –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            print(f"‚ö†Ô∏è DummyVectorEnv —Ç–æ–∂–µ –Ω–µ —Å–æ–∑–¥–∞–ª—Å—è, –ø—Ä–æ–±—É—é –æ–¥–∏–Ω–æ—á–Ω—ã–µ env: {e2}")
            train_envs = [wrapped_env_fn_train()]
            test_envs = [wrapped_env_fn_test()]
    try:
        # –í—ã—á–∏—Å–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —á–∏—Å–ª–æ env –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –±—É—Ñ–µ—Ä–∞/—Å–±–æ—Ä–∫–∏
        env_count = (len(train_envs) if isinstance(train_envs, (list, tuple)) else getattr(train_envs, 'env_num', n_envs))
    except Exception:
        env_count = max(1, n_envs)
    try:
        print(f"üß© Tianshou envs: train={env_count}, test={len(test_envs) if isinstance(test_envs, (list, tuple)) else getattr(test_envs, 'env_num', max(1, env_count // 2))}")
    except Exception:
        pass

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # –î–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ (–º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å)
    if torch.cuda.is_available():
        try:
            torch.backends.cudnn.benchmark = False
            torch.backends.cudnn.deterministic = True
            if hasattr(torch.backends.cuda, 'matmul') and hasattr(torch.backends.cuda.matmul, 'allow_tf32'):
                torch.backends.cuda.matmul.allow_tf32 = False
            if hasattr(torch.backends.cudnn, 'allow_tf32'):
                torch.backends.cudnn.allow_tf32 = False
        except Exception:
            pass
    # –ü—Ä–∏–º–µ–Ω–∏–º training_params overrides (lr, batch_size, eps, repeats, target_freq, memory)
    # 1) –ü—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏ –ø–æ —Å–∏–º–≤–æ–ª—É
    override = None
    try:
        if isinstance(symbol, str):
            symu = symbol.upper()
            if 'TON' in symu:
                from agents.vdqn.hyperparameter.ton_optimized_config import TON_OPTIMIZED_CONFIG as _SYM_CFG
                override = _SYM_CFG
                print("‚öôÔ∏è –ü—Ä–∏–º–µ–Ω—è—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è TON (hyperparameter/ton_optimized_config.py)")
            elif 'BNB' in symu:
                from agents.vdqn.hyperparameter.bnb_optimized_config import BNB_OPTIMIZED_CONFIG as _SYM_CFG
                override = _SYM_CFG
                print("‚öôÔ∏è –ü—Ä–∏–º–µ–Ω—è—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è BNB (hyperparameter/bnb_optimized_config.py)")
            elif 'BTC' in symu:
                from agents.vdqn.hyperparameter.btc_optimized_config import BTC_OPTIMIZED_CONFIG as _SYM_CFG
                override = _SYM_CFG
                print("‚öôÔ∏è –ü—Ä–∏–º–µ–Ω—è—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è BTC (hyperparameter/btc_optimized_config.py)")
    except Exception as _e:
        print(f"‚ÑπÔ∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –ø–æ —Å–∏–º–≤–æ–ª—É: {_e}")
        override = None
    # 2) –ï—Å–ª–∏ –µ—Å—Ç—å –≤–Ω–µ—à–Ω–∏–π override –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ —Å–∏–º–≤–æ–ª–∞ ‚Äî –æ–Ω –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–µ–µ
    try:
        ext_override = get_symbol_override(symbol if not _is_multi_crypto(dfs) else None) if isinstance(dfs, dict) else None
        if ext_override:
            override = ext_override
            print("‚öôÔ∏è –ü—Ä–∏–º–µ–Ω—è—é –≤–Ω–µ—à–Ω–∏–π override –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–∏–º–≤–æ–ª–∞ (get_symbol_override)")
    except Exception:
        pass
    if override and 'training_params' in override:
        tp = override['training_params']
        # GPU-owned –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ù–ï –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å per-symbol.
        GPU_OWNED_KEYS = {'batch_size', 'memory_size', 'train_repeats'}
        try:
            lr = tp.get('lr', lr)
            gamma = tp.get('gamma', gamma)
        except Exception:
            pass
        try:
            if 'batch_size' in tp and 'batch_size' in GPU_OWNED_KEYS:
                print(f"‚ö†Ô∏è SYMBOL OVERRIDE –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç GPU-owned –ø–∞—Ä–∞–º–µ—Ç—Ä: batch_size={tp.get('batch_size')}")
            else:
                batch_size = tp.get('batch_size', batch_size)
        except Exception:
            pass
        try:
            # epsilon —Å—Ö–µ–º–∞
            eps_start_override = tp.get('eps_start', None)
            eps_final_override = tp.get('eps_final', None)
            eps_decay_steps_override = tp.get('eps_decay_steps', None)
        except Exception:
            eps_start_override = None; eps_final_override = None; eps_decay_steps_override = None
        try:
            target_update_freq = tp.get('target_update_freq', target_update_freq)
            try:
                if 'memory_size' in tp and 'memory_size' in GPU_OWNED_KEYS:
                    print(f"‚ö†Ô∏è SYMBOL OVERRIDE –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç GPU-owned –ø–∞—Ä–∞–º–µ—Ç—Ä: memory_size={tp.get('memory_size')}")
                else:
                    memory_size = tp.get('memory_size', memory_size)
            except Exception:
                pass
            try:
                if 'train_repeats' in tp and 'train_repeats' in GPU_OWNED_KEYS:
                    print(f"‚ö†Ô∏è SYMBOL OVERRIDE –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç GPU-owned –ø–∞—Ä–∞–º–µ—Ç—Ä: train_repeats={tp.get('train_repeats')}")
                    train_repeats = train_repeats
                else:
                    train_repeats = tp.get('train_repeats', 1)
            except Exception:
                train_repeats = 1
        except Exception:
            train_repeats = 1
    else:
        eps_start_override = None; eps_final_override = None; eps_decay_steps_override = None; train_repeats = 1

    # –°–ø–µ—Ü-–ª–æ–≥–∏–∫–∞ –¥–ª—è BNB: –º—è–≥–∫–∏–µ –æ–≤–µ—Ä—Ä–∞–π–¥—ã –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    try:
        if (not _is_multi_crypto(dfs)) and isinstance(symbol, str) and ('BNB' in symbol.upper()):
            # –°–Ω–∏–∂–∞–µ–º exploration –∏ lr, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º batch
            try:
                eps_start_override = eps_start_override if eps_start_override is not None else 0.20
                eps_final_override = eps_final_override if eps_final_override is not None else 0.02
                eps_decay_steps_override = eps_decay_steps_override if eps_decay_steps_override is not None else int(1_000_000 * 0.75)
            except Exception:
                pass
            try:
                batch_size = max(192, int(batch_size))
                lr = min(float(lr), 2e-4)
            except Exception:
                pass
            # –ß—É—Ç—å —á–∞—â–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –±—É—Ñ–µ—Ä
            try:
                buffer_save_frequency = max(400, int(buffer_save_frequency or 0) or 800)
            except Exception:
                pass
    except Exception:
        pass

    net = DQNN(
        obs_dim=obs_dim,
        act_dim=act_dim,
        hidden_sizes=(512, 512, 256),
        dropout_rate=0.1,
        layer_norm=True,
        dueling=True,
        activation='relu',
        use_residual=True,
        use_swiglu=False,
    ).to(device)

    try:
        should_compile = False
        source = 'default'
        # 1) –ü—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –∏–∑ GPU-–∫–æ–Ω—Ñ–∏–≥–∞
        try:
            from agents.vdqn.cfg.gpu_configs import get_optimal_config
            _gpu_cfg = get_optimal_config()
            if hasattr(_gpu_cfg, 'use_torch_compile'):
                should_compile = bool(getattr(_gpu_cfg, 'use_torch_compile'))
                source = 'gpu_config'
        except Exception:
            pass
        # 2) –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä–∞ (gcc/clang); –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –æ—Ç–∫–ª—é—á–∏–º compile
        try:
            import shutil
            has_cc = bool(shutil.which('cc') or shutil.which('gcc') or shutil.which('clang'))
            if should_compile and not has_cc:
                print("‚ö†Ô∏è torch.compile –æ—Ç–∫–ª—é—á–µ–Ω: –Ω–µ –Ω–∞–π–¥–µ–Ω C-–∫–æ–º–ø–∏–ª—è—Ç–æ—Ä (cc/gcc/clang)")
                should_compile = False
                source = f"{source}+no_cc"
        except Exception:
            pass
        if should_compile and torch.cuda.is_available() and hasattr(torch, 'compile'):
            # –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π os
            # –°–Ω–∏–∑–∏–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫—Ä—ç—à–µ–π –∏–Ω–¥—É–∫—Ç–æ—Ä–∞ –≤ —Å–∞–±–ø—Ä–æ—Ü–µ—Å—Å–∞—Ö
            os.environ.setdefault('TORCHINDUCTOR_COMPILE_THREADS', '1')
            # –í—ã–±–µ—Ä–µ–º backend: Ampere+ (cc>=8.0) ‚Üí inductor, –∏–Ω–∞—á–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π aot_eager
            backend = 'inductor'
            try:
                cc_major, cc_minor = torch.cuda.get_device_capability(0)
                if int(cc_major) < 8:
                    backend = 'aot_eager'
            except Exception:
                backend = 'aot_eager'
            print(f"‚öôÔ∏è torch.compile: enabled ({source}), backend={backend}, TORCHINDUCTOR_COMPILE_THREADS={os.environ.get('TORCHINDUCTOR_COMPILE_THREADS')}")
            compiled_net = torch.compile(net, backend=backend)
            # –¢—ë–ø–ª—ã–π –ø—Ä–æ–≥–æ–Ω –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ –≤—ã—è–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Ñ–æ–ª–±—ç–∫–∞
            try:
                with torch.no_grad():
                    dummy = torch.zeros(1, int(obs_dim), dtype=torch.float32, device=device)
                    _ = compiled_net(dummy)
                net = compiled_net
            except Exception as ce:
                print(f"‚ö†Ô∏è torch.compile warmup failed: {ce}; falling back to eager")
                source = f"{source}+warmup_fail"
        else:
            print(f"‚öôÔ∏è torch.compile: disabled ({source})")
    except Exception:
        pass

    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∫–∞–∫ –≤ legacy DQN: AdamW
    optim = torch.optim.AdamW(net.parameters(), lr=lr)
    policy = MaskedDQNPolicy(
        model=net,
        optim=optim,
        action_space=action_space_gym,
        discount_factor=gamma,
        estimation_step=n_step,
        target_update_freq=target_update_freq,
        is_double=True,
    )
    try:
        print(f"üéØ target_update_freq={target_update_freq}")
    except Exception:
        pass
    # –ù–∞—á–∞–ª—å–Ω—ã–π epsilon –∏ –ø–ª–∞–≤–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ ‚Äî –∞–Ω–∞–ª–æ–≥ —Ç–≤–æ–µ–π —Å—Ö–µ–º—ã
    try:
        # –ú–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –∏–∑–≤–Ω–µ –∑–Ω–∞—á–µ–Ω–∏—è, –∑–¥–µ—Å—å ‚Äî –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç—ã
        eps_start = eps_start_override if eps_start_override is not None else 0.3
        eps_final = eps_final_override if eps_final_override is not None else 0.05
        # –†–µ–∂–∏–º —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        if debug_exploration:
            try:
                print("üß™ [DEBUG] Exploration override –∞–∫—Ç–∏–≤–µ–Ω: eps_start=1.0, eps_final=0.05, eps_decay_steps=100000")
            except Exception:
                pass
            eps_start = 1.0
            eps_final = 0.05
            eps_decay_steps_override = 100_000
        # –£—Å—Ç–∞–Ω–æ–≤–∏–º —Å—Ç–∞—Ä—Ç–æ–≤—ã–π eps
        policy.set_eps(eps_start)
    except Exception:
        pass

    try:
        effective_total = int(memory_size)
        if max_samples_by_budget is not None:
            effective_total = min(effective_total, int(max_samples_by_budget))
    except Exception:
        effective_total = int(memory_size)
    # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞ –∫ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–º—É —á–∏—Å–ª—É env (–±–µ–∑ —É–º–Ω–æ–∂–µ–Ω–∏—è –ø—Ä–∏ –æ–¥–∏–Ω–æ—á–Ω–æ–º env)
    try:
        env_count = (len(train_envs) if isinstance(train_envs, (list, tuple)) else getattr(train_envs, 'env_num', n_envs))
    except Exception:
        env_count = max(1, n_envs)
    buf = VectorReplayBuffer(total_size=int(effective_total), buffer_num=int(env_count))
    # –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è policy.eps; —à—É–º –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–∞ –æ—Ç–∫–ª—é—á–∞–µ–º
    train_collector = Collector(policy, train_envs, buf, exploration_noise=False)
    test_collector = Collector(policy, test_envs, exploration_noise=False)
    # Warmup –±—É—Ñ–µ—Ä–∞: —É—Å–∫–æ—Ä—è–µ—Ç –ø–æ—è–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
    try:
        warmup_steps = 0
        try:
            warmup_steps = int(str(get_config_value('TS_WARMUP_STEPS', '0')))
        except Exception:
            warmup_steps = 0
        if debug_exploration and warmup_steps <= 0:
            warmup_steps = 10_000
        if warmup_steps and warmup_steps > 0:
            _prev_eps = getattr(policy, 'eps', None)
            try:
                policy.set_eps(1.0)
            except Exception:
                pass
            try:
                print(f"üß™ Warmup: collect {warmup_steps} steps (eps=1.0)")
                _res = train_collector.collect(n_step=warmup_steps)
                try:
                    _buf_size = getattr(train_collector.buffer, 'size', None)
                    print(f"üß™ Warmup –∑–∞–≤–µ—Ä—à—ë–Ω: buffer_size={_buf_size} result={_res}")
                except Exception:
                    pass
            finally:
                try:
                    if _prev_eps is not None:
                        policy.set_eps(_prev_eps)
                except Exception:
                    pass
    except Exception:
        pass
    # Warm-start –±—É—Ñ–µ—Ä–∞ (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ Tianshou/legacy —Ñ–æ—Ä–º–∞—Ç–æ–≤)
    try:
        if load_buffer_path and os.path.isfile(load_buffer_path):
            import pickle
            with open(load_buffer_path, 'rb') as f:
                loaded_buf = pickle.load(f)
            if hasattr(loaded_buf, 'add') and hasattr(loaded_buf, '__len__'):
                train_collector.buffer = loaded_buf
                buf = loaded_buf
                print(f"‚ôªÔ∏è  –ó–∞–≥—Ä—É–∂–µ–Ω Tianshou replay buffer –∏–∑ {load_buffer_path}")
            else:
                # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å legacy —Ñ–æ—Ä–º–∞—Ç –≤ —Ç–µ–∫—É—â–∏–π buf
                if _try_load_legacy_replay(load_buffer_path, buf):
                    print(f"‚ôªÔ∏è  –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω legacy replay –≤ —Ç–µ–∫—É—â–∏–π –±—É—Ñ–µ—Ä")
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±—É—Ñ–µ—Ä: {e}")

    steps_per_episode = episode_length or 2000
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–æ–≤–Ω–æ UI-–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑ –∂—ë—Å—Ç–∫–∏—Ö –º–∏–Ω–∏–º—É–º–æ–≤
    train_steps = max(1, episodes * steps_per_episode)

    # Early stopping –∏ best-–º–æ–¥–µ–ª—å –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É —Ç–µ—Å—Ç-–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—é
    best_reward = None
    best_epoch = -1
    recent_test_rewards: deque = deque(maxlen=60)
    stopped_by_trend = False
    # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è train_result (–ø—Ä–æ–∫—Å–∏—Ä—É–µ–º winrate –∫–∞–∫ —Å—Ä–µ–¥–Ω—é—é —Ç–µ—Å—Ç-–Ω–∞–≥—Ä–∞–¥—É –ø–æ —ç–ø–æ—Ö–∞–º)
    epoch_test_rewards: list[float] = []

    def save_checkpoint_fn(epoch: int, env_step: int, gradient_step: int, **kwargs):
        nonlocal best_reward, best_epoch
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º best_model –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏
        try:
            cur_best = kwargs.get('best_reward', None)
            if cur_best is None:
                return
            if best_reward is None or cur_best > best_reward:
                best_reward = cur_best
                best_epoch = epoch
                import shutil as _sh
                _sh.copy2(model_path, run_dir / 'best_model.pth')
                # –ü—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ ‚Äî –ø–æ —Ñ–ª–∞–≥—É —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º replay
                if save_replay_on_improvement:
                    import pickle
                    with open(replay_path, 'wb') as f:
                        pickle.dump(buf, f)
        except Exception:
            pass
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã model/last –∏ replay
        try:
            if save_frequency and epoch > 0 and (epoch % save_frequency == 0):
                # –ü–µ—Ä–µ—ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –º–µ–Ω—è–ª–∞—Å—å)
                try:
                    latest_norm = _export_norm_stats_safe(dfs, episode_length)
                except Exception:
                    latest_norm = None
                torch.save({'model': net.state_dict(), 'normalization_stats': latest_norm or norm_stats_cached}, model_path)
                import shutil as _sh
                if model_path.exists():
                    _sh.copy2(model_path, run_dir / 'last_model.pth')
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º encoder_only
                if hasattr(net, 'get_feature_extractor'):
                    encoder = net.get_feature_extractor()
                    if encoder is not None:
                        enc_path = run_dir / 'encoder_only.pth'
                        torch.save({'encoder': encoder.state_dict()}, enc_path)
            freq_buf = buffer_save_frequency if buffer_save_frequency is not None else max(200, save_frequency * 4)
            if epoch > 0 and (epoch % freq_buf == 0):
                import pickle
                with open(replay_path, 'wb') as f:
                    pickle.dump(buf, f)
            # –û–±–Ω–æ–≤–ª—è–µ–º manifest.json —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
            try:
                approx_episodes = int(env_step / float(steps_per_episode)) if steps_per_episode else None
                manifest = {
                    'run_id': this_run_id,
                    'parent_run_id': parent_run_id,
                    'root_id': root_id or this_run_id,
                    'symbol': symbol_dir,
                    'seed': (int(seed) if isinstance(seed, int) else None),
                    'episodes_start': 0,
                    'episodes_end': approx_episodes,
                    'episodes_added': approx_episodes,
                    'episodes_last': approx_episodes,
                    'episodes_best': (best_epoch if best_epoch >= 0 else None),
                    'created_at': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
                    'debug': bool(debug_run or debug_exploration),
                    'debug_flags': [
                        f for f, on in (
                            ('TS_DEBUG_RUN', debug_run),
                            ('TS_DEBUG_EXPLORATION', debug_exploration),
                            ('TS_FORCE_SINGLE', force_single),
                            ('TS_FORCE_DUMMY', force_dummy),
                        ) if on
                    ],
                    'artifacts': {
                        'model': 'model.pth',
                        'replay': 'replay.pkl' if Path(replay_path).exists() else None,
                        'result': 'train_result.pkl',
                        'best_model': 'best_model.pth' if (run_dir / 'best_model.pth').exists() else None,
                        'last_model': 'last_model.pth' if (run_dir / 'last_model.pth').exists() else None,
                        'encoder_only': 'encoder_only.pth' if (run_dir / 'encoder_only.pth').exists() else None,
                        'all_trades': 'all_trades.json' if (run_dir / 'all_trades.json').exists() else None,
                    },
                    'best_metrics': {
                        'winrate': (winrate_from_trades if (winrate_from_trades is not None) else (max(epoch_test_rewards) if epoch_test_rewards else None)),
                        'reward': (best_reward if best_reward is not None else (max(epoch_test_rewards) if epoch_test_rewards else None))
                    }
                }
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é (progress)
                print(f"üí°[Progress] –°–æ—Ö—Ä–∞–Ω—è–µ–º manifest.json –≤ {run_dir / 'manifest.json'}")
                print(manifest)
                with open(run_dir / 'manifest.json', 'w', encoding='utf-8') as mf:
                    _json.dump(manifest, mf, ensure_ascii=False, indent=2)
                    try:
                        mf.flush(); os.fsync(mf.fileno())
                    except Exception:
                        pass
            except Exception as me_prog:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å manifest.json (progress): {me_prog}")
                import traceback; traceback.print_exc()
        except Exception:
            pass

# –¢—Ä–µ–Ω–¥–æ–≤—ã–π stop_fn —Å –º–∏–Ω–∏–º—É–º–æ–º "—ç–ø–∏–∑–æ–¥–æ–≤"
    min_episodes_before_stopping = max(4000, episodes // 3)
    patience_limit = max(8000, episodes // 2)

    def stop_fn(mean_rewards: float) -> bool:
        # –°–æ–±–∏—Ä–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è —Ç—Ä–µ–Ω–¥–∞
        try:
            recent_test_rewards.append(mean_rewards)
            epoch_test_rewards.append(float(mean_rewards))
            # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫ (< 50 —ç–ø–∏–∑–æ–¥–æ–≤) –æ—Ç–∫–ª—é—á–∞–µ–º early stopping
            if episodes < 50:
                return False
            if len(recent_test_rewards) < 60:
                return False
            recent_avg = float(np.mean(list(recent_test_rewards)[-30:]))
            older_avg = float(np.mean(list(recent_test_rewards)[:-30]))
            declining = recent_avg + 0.05 < older_avg
            # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ "—ç–ø–∏–∑–æ–¥–æ–≤" –ø–æ —à–∞–≥–∞–º
            approx_episodes = int((train_collector.buffer.size / max(1, steps_per_episode)))
            if approx_episodes < min_episodes_before_stopping:
                return False
            should_stop = declining and approx_episodes >= patience_limit
            if should_stop:
                nonlocal stopped_by_trend
                stopped_by_trend = True
            return should_stop
        except Exception:
            return False

    # –õ–∏–Ω–µ–π–Ω—ã–π —à–µ–¥—É–ª–µ—Ä epsilon –ø–æ —à–∞–≥–∞–º (train_fn): —Å—Ç—Ä–æ–≥–æ –∫–∞–∫ legacy DQN
    eps_decay_steps = int(eps_decay_steps_override) if (isinstance(eps_decay_steps_override, (int, float)) and eps_decay_steps_override) else train_steps

    # Heartbeat: –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –ª–æ–≥ —Ä–∞–∑ –≤ N —Å–µ–∫—É–Ω–¥
    try:
        heartbeat_interval_sec = int(get_config_value('TS_HEARTBEAT_SEC', '60'))
    except Exception:
        heartbeat_interval_sec = 60
    last_heartbeat_ts = time.time()
    last_heartbeat_env_step = 0

    def train_fn(epoch: int, env_step: int):
        # –õ–æ–≥ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–∏ train_fn
        #print(f"‚öôÔ∏è train_fn: –í—ã–∑–≤–∞–Ω. epoch={epoch}, env_step={env_step}")
        try:
            frac = min(1.0, env_step / float(max(1, eps_decay_steps)))
            cur_eps = max(eps_final, eps_start + (eps_final - eps_start) * frac)
            policy.set_eps(cur_eps)
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –ª–æ–≥ —Ä–µ—Å—É—Ä—Å–æ–≤
            if env_step % (n_envs * 1_000) == 0:
                _log_resource_usage(tag="ts-train", extra=f"env_step={env_step} eps={cur_eps:.3f}")
            # –í—Ä–µ–º–µ–Ω–Ω—ã–π –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 50 —à–∞–≥–æ–≤
            if env_step % 200 == 0:
                try:
                    buf_size = getattr(train_collector.buffer, 'size', None)
                    print(f"üß™ train_fn (debug): env_step={env_step} eps={cur_eps:.3f} buffer_size={buf_size}")
                except Exception:
                    pass
            # Heartbeat —Ä–∞–∑ –≤ N —Å–µ–∫—É–Ω–¥ —Å –æ—Ü–µ–Ω–∫–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
            nonlocal last_heartbeat_ts, last_heartbeat_env_step
            now = time.time()
            # –ü–µ—Ä–≤—ã–π heartbeat —Å—Ä–∞–∑—É –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —ç–ø–æ—Ö–∏
            if env_step == 0 and last_heartbeat_env_step == 0:
                print(f"üöÄ –ù–∞—á–∞–ª–æ —ç–ø–æ—Ö–∏ {epoch}/{num_epochs}. –¢–µ–∫—É—â–∏–π —à–∞–≥: {env_step}, eps={cur_eps:.3f}")
                last_heartbeat_ts = now
                last_heartbeat_env_step = env_step
            if now - last_heartbeat_ts >= heartbeat_interval_sec:
                dt = max(1e-6, now - last_heartbeat_ts)
                dsteps = max(0, env_step - last_heartbeat_env_step)
                sps = dsteps / dt  # steps per second
                print(f"‚è±Ô∏è heartbeat (time): epoch={epoch}/{num_epochs} env_step={env_step} eps={cur_eps:.3f} speed={sps:.1f} steps/s")
                last_heartbeat_ts = now
                last_heartbeat_env_step = env_step
            # Fallback: –µ—Å–ª–∏ —Å–µ–∫—É–Ω–¥–Ω—ã–π —Ç–∞–π–º–µ—Ä –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø–µ—á–∞—Ç–∞–µ–º –ø–æ —à–∞–≥–∞–º
            fallback_step_interval = max(50, n_envs * 50)
            if env_step - last_heartbeat_env_step >= fallback_step_interval:
                # –æ–±–Ω–æ–≤–∏–º –∏ –≤—ã–≤–µ–¥–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ —à–∞–≥–∞–º
                dt = max(1e-6, now - last_heartbeat_ts)
                dsteps = max(0, env_step - last_heartbeat_env_step)
                sps = dsteps / dt if dt > 0 else 0.0
                #print(f"‚è±Ô∏è heartbeat (step): epoch={epoch}/{num_epochs} env_step={env_step} eps={cur_eps:.3f} speed={sps:.1f} steps/s")
                last_heartbeat_ts = now
                last_heartbeat_env_step = env_step
            # –ò–∑—Ä–µ–¥–∫–∞ —á–∏—Å—Ç–∏–º CUDA-–∫—ç—à
            if torch.cuda.is_available() and (env_step % (n_envs * 50_000) == 0):
                try:
                    torch.cuda.empty_cache()
                except Exception:
                    pass
        except Exception:
            pass

    episodes_since_best = 0
    lr_min = 1e-5
    lr_plateau_patience = 1000

    def test_fn(epoch: int, env_step: int):
        # –õ–æ–≥ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–∏ test_fn
        print(f"üß™ test_fn: –í—ã–∑–≤–∞–Ω. epoch={epoch}, env_step={env_step}")
        try:
            policy.eval()
            collector = test_collector
            result = collector.collect(n_episode=1) # Changed from episode_per_test to 1
            try:
                # Tianshou 1.x: CollectStats –∏–º–µ–µ—Ç returns/lens (+ returns_stat/lens_stat)
                rets = getattr(result, 'returns', None)
                lens = getattr(result, 'lens', None)
                if rets is None:
                    # –°—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏: rews/lens –≤ dict
                    rets = getattr(result, 'rews', None)
                if rets is None or lens is None:
                    # Fallback –Ω–∞ dict-–¥–æ—Å—Ç—É–ø
                    try:
                        rets = result["returns"] if "returns" in result else result["rews"]
                        lens = result["lens"]
                    except Exception:
                        # –ï—Å–ª–∏ –∏ —ç—Ç–æ –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–ª—è –≤–Ω–µ—à–Ω–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                        raise
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã (Tianshou 1.x)
                rew_mean = None; rew_std = None
                len_mean = None; len_std = None
                try:
                    rs = getattr(result, 'returns_stat', None)
                    if rs is not None:
                        rew_mean = float(getattr(rs, 'mean', None)) if getattr(rs, 'mean', None) is not None else None
                        rew_std = float(getattr(rs, 'std', None)) if getattr(rs, 'std', None) is not None else None
                except Exception:
                    pass
                try:
                    ls = getattr(result, 'lens_stat', None)
                    if ls is not None:
                        len_mean = float(getattr(ls, 'mean', None)) if getattr(ls, 'mean', None) is not None else None
                        len_std = float(getattr(ls, 'std', None)) if getattr(ls, 'std', None) is not None else None
                except Exception:
                    pass
                # –ï—Å–ª–∏ –Ω–µ—Ç –≥–æ—Ç–æ–≤—ã—Ö —Å—Ç–∞—Ç, —Å—á–∏—Ç–∞–µ–º –æ—Ç –º–∞—Å—Å–∏–≤–æ–≤
                if rew_mean is None:
                    try:
                        rew_mean = float(rets.mean())
                    except Exception:
                        rew_mean = float(sum(rets) / max(1, len(rets)))
                if rew_std is None:
                    try:
                        rew_std = float(rets.std())
                    except Exception:
                        rew_std = 0.0
                if len_mean is None:
                    try:
                        len_mean = float(lens.mean())
                    except Exception:
                        len_mean = float(sum(lens) / max(1, len(lens)))
                if len_std is None:
                    try:
                        len_std = float(lens.std())
                    except Exception:
                        len_std = 0.0
                print(f"üéØ Test: epoch={epoch} env_step={env_step} avg_reward={rew_mean:.2f} (std={rew_std:.2f}) avg_len={len_mean:.1f} (std={len_std:.1f})")
            except Exception as se:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤ test_fn(stat): {se}; result={result}")
            finally:
                policy.train() # –í–µ—Ä–Ω—É—Ç—å—Å—è –≤ —Ä–µ–∂–∏–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ test_fn: {e}")

    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç—Ä–µ–Ω–∏–Ω–≥ –Ω–∞ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —ç–ø–æ—Ö–∏
    progress_step_per_epoch = steps_per_episode
    num_epochs = max(1, int(train_steps / float(progress_step_per_epoch)))
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º step_per_collect
    try:
        _spc = int(str(get_config_value('TS_STEP_PER_COLLECT', '0')))
    except Exception:
        _spc = 0
    step_per_collect_value = _spc if _spc > 0 else (n_envs * 32)
    if debug_run:
        step_per_collect_value = max(step_per_collect_value, 256)

    # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ train_repeats ‚Üí update_per_step
    try:
        update_per_step_value = float(train_repeats) if isinstance(train_repeats, (int, float)) and float(train_repeats) > 0 else 1.0
    except Exception:
        update_per_step_value = 1.0
    try:
        print(f"üîÑ update_per_step={update_per_step_value} (train_repeats={train_repeats})")
    except Exception:
        pass

    # –ì–ª–æ–±–∞–ª—å–Ω—ã–π heartbeat: –ø–µ—á–∞—Ç–∞–µ–º —Ä–∞–∑ –≤ N —Å–µ–∫—É–Ω–¥ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç train_fn
    try:
        global_hb_interval = int(get_config_value('TS_HEARTBEAT_SEC', '60'))
    except Exception:
        global_hb_interval = 60
    _hb_stop = {'flag': False}

    def _global_heartbeat():
        last_ts = time.time()
        last_env_step = 0
        while not _hb_stop.get('flag', False):
            time.sleep(max(5, min( global_hb_interval, 60)))
            try:
                # –ü–µ—á–∞—Ç–∞–µ–º –º–∏–Ω–∏–º—É–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∏ –ø—Ä–∏–º–µ—Ä–Ω—ã–π —à–∞–≥
                _log_resource_usage(tag="ts-global")
                # –ï—Å–ª–∏ –µ—Å—Ç—å train_collector, –≤—ã–≤–µ–¥–µ–º —Ä–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞ –∏ env_step
                try:
                    buf_size = getattr(train_collector.buffer, 'size', None)
                    print(f"ü´Ä global-heartbeat: buffer_size={buf_size} (env_step={last_env_step})")
                except Exception:
                    print(f"ü´Ä global-heartbeat: alive")
            except Exception:
                pass

    _hb_thread = Thread(target=_global_heartbeat, daemon=True)
    _hb_thread.start()

    # ==========================================================================================
    #  –ó–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ Tianshou
    # ==========================================================================================
    print(f"üóìÔ∏è Trainer: epochs={num_epochs}, step_per_epoch={progress_step_per_epoch}, step_per_collect={step_per_collect_value}")
    print(f"‚ÑπÔ∏è CryptoTradingEnv reset snapshot: requested_episode_length={episode_length}, env_episode_length={actual_episode_length}, min_start={min_valid_start_step if min_valid_start_step is not None else 'n/a'}, start_step={start_step_snapshot if start_step_snapshot is not None else 'n/a'}")
    test_collector.reset()
    train_collector.reset()
    # print(f"üìä –°—Ç–∞—Ä—Ç —Ç—Ä–µ–Ω–µ—Ä–∞: env_step={train_collector.env_step} buffer_size={train_collector.buffer.size}")
    print(f"üèÅ –ì–æ—Ç–æ–≤ –∫ –∑–∞–ø—É—Å–∫—É Tianshou offpolicy_trainer –¥–ª—è {num_epochs} —ç–ø–æ—Ö.")
    # –õ–æ–≥–≥–µ—Ä —Ç—Ä–µ–Ω–µ—Ä–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º CSVLogger –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏–Ω–∞—á–µ –±–µ–∑ –ª–æ–≥–≥–µ—Ä–∞ (—É –Ω–∞—Å –µ—Å—Ç—å train.log tee)
    try:
        logger = CSVLogger(output_dir=str(run_dir / 'logs')) if CSVLogger is not None else None
    except Exception:
        logger = None
    try:
        result = offpolicy_trainer(
            policy=policy,
            train_collector=train_collector,
            test_collector=test_collector,
            max_epoch=num_epochs,
            step_per_epoch=progress_step_per_epoch,
            step_per_collect=step_per_collect_value,
            episode_per_test=1,
            batch_size=batch_size,
            # –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –Ω–∞ —à–∞–≥ —Å—Ä–µ–¥—ã = train_repeats –∏–∑ legacy
            update_per_step=float(update_per_step_value),
            test_in_train=False,
            train_fn=train_fn,
            test_fn=test_fn,
            save_checkpoint_fn=save_checkpoint_fn,
            stop_fn=stop_fn,
            logger=logger,
            show_progress=False,
        )
    except Exception as e:
        import traceback
        print("‚ùå Exception in offpolicy_trainer:")
        traceback.print_exc()
        raise

    # –û—Å—Ç–∞–Ω–æ–≤–∏–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π heartbeat
    try:
        _hb_stop['flag'] = True
    except Exception:
        pass

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (+ encoder_only –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏)
    print(f"‚úÖ Tianshou offpolicy_trainer –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.")
    # –°—Ç–∞—Ç—É—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    saved_train_result = False
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    all_trades = []
    collected_trades = []
    # –ö—Ä–∞—Ç–∫–∏–π –∏—Ç–æ–≥ –≤—Ä–µ–º–µ–Ω–∏ –∏ —Å—Ä–µ–¥–Ω–∏—Ö –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    try:
        total_training_time = time.time() - training_start_time
        def _fmt_duration(sec: float) -> str:
            try:
                sec = float(sec)
            except Exception:
                return str(sec)
            if sec < 60:
                return f"{sec:.1f} —Å–µ–∫"
            mins = sec / 60.0
            if mins < 60:
                return f"{mins:.1f} –º–∏–Ω"
            hours = mins / 60.0
            return f"{hours:.1f} —á"
        try:
            env_steps_total = int(result.get('env_step', 0)) if isinstance(result, dict) else 0
        except Exception:
            env_steps_total = 0
        steps_per_ep = episode_length or 2000
        approx_env_episodes = (env_steps_total // max(1, steps_per_ep)) if env_steps_total > 0 else num_epochs
        avg_per_env_episode = total_training_time / max(1, approx_env_episodes)
        avg_per_epoch = total_training_time / max(1, num_epochs)
        print(
            f"‚è±Ô∏è –ò—Ç–æ–≥: –æ–±—â–µ–µ –≤—Ä–µ–º—è={_fmt_duration(total_training_time)}, "
            f"—Å—Ä. –Ω–∞ —ç–ø–∏–∑–æ–¥‚âà{_fmt_duration(avg_per_env_episode)}, "
            f"—Å—Ä. –Ω–∞ —ç–ø–æ—Ö—É‚âà{_fmt_duration(avg_per_epoch)}"
        )
    except Exception:
        pass
    payload = {'model': net.state_dict(), 'normalization_stats': norm_stats_cached}
    try:
        if hasattr(net, 'get_feature_extractor'):
            encoder = net.get_feature_extractor()
            if encoder is not None:
                enc_path = run_dir / 'encoder_only.pth'
                torch.save({'encoder': encoder.state_dict()}, enc_path)
    except Exception:
        pass
    torch.save(payload, model_path)
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–∏–ª –∏—Ç–æ–≥–æ–≤—É—é –º–æ–¥–µ–ª—å –≤ {model_path}")
    last_model_path = run_dir / 'last_model.pth'
    try:
        import shutil as _sh
        if model_path.exists():
            _sh.copy2(model_path, last_model_path)
    except Exception:
        pass

    try:
        import pickle
        with open(replay_path, 'wb') as f:
            pickle.dump(buf, f)
    except Exception:
        pass

    # –°–æ–±–µ—Ä—ë–º –∞–≥—Ä–µ–≥–∞—Ç—ã –ø—Ä–æ–¥–ª–µ–Ω–∏—è —ç–ø–∏–∑–æ–¥–æ–≤ –∏–∑ train_envs (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ –ª–æ–∫–∞–ª—å–Ω–æ)
    try:
        def _collect_extension_stats(env_container):
            total_ext = 0
            total_steps_ext = 0
            try:
                # –î–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö env (—Å–ø–∏—Å–æ–∫ –∏–ª–∏ DummyVectorEnv)
                env_list = []
                if hasattr(env_container, 'envs'):
                    env_list = getattr(env_container, 'envs') or []
                elif isinstance(env_container, (list, tuple)):
                    env_list = env_container
                for _env in env_list:
                    try:
                        cur = _env
                        # –†–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –æ–±—ë—Ä—Ç–∫–∏
                        for _ in range(6):
                            if hasattr(cur, 'env'):
                                cur = getattr(cur, 'env')
                            else:
                                break
                        te = getattr(cur, 'total_episode_extensions', 0)
                        ts = getattr(cur, 'total_extension_steps', 0)
                        total_ext += int(te or 0)
                        total_steps_ext += int(ts or 0)
                    except Exception:
                        pass
            except Exception:
                pass
            return total_ext, total_steps_ext

        total_ext_count, total_ext_steps = _collect_extension_stats(train_envs)
    except Exception:
        total_ext_count, total_ext_steps = 0, 0

    # –û–±–Ω–æ–≤–ª—è–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç-–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (manifest, best_model –∏ —Ç.–¥.)
    try:
        save_checkpoint_fn(
            epoch=num_epochs,
            env_step=int(result.get('env_step', 0)) if isinstance(result, dict) else 0,
            gradient_step=int(result.get('gradient_step', 0)) if isinstance(result, dict) else 0,
            best_reward=result.get('best_reward', best_reward) if isinstance(result, dict) else best_reward,
        )
    except Exception:
        pass

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ train_result.pkl –≤ —Ñ–æ—Ä–º–∞—Ç–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–º
    print("‚Äî> –ù–∞—á–∞–ª–æ –æ–±—â–µ–≥–æ –±–ª–æ–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ train_result.pkl")
    try:
        total_training_time = time.time() - training_start_time
        print("‚Äî> total_training_time –≤—ã—á–∏—Å–ª–µ–Ω–æ: ", total_training_time)

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (—Å–Ω–∏–º–æ–∫ —Å single_env)
        try:
            # Funding features presence from dfs
            try:
                df5_cols = list(dfs.get('df_5min').columns) if isinstance(dfs, dict) and hasattr(dfs.get('df_5min'), 'columns') else []
            except Exception:
                df5_cols = []
            funding_cols = ['funding_rate_bp', 'funding_rate_ema', 'funding_rate_change', 'funding_sign']
            funding_present = [c for c in funding_cols if c in df5_cols]

            gym_snapshot = {}
            if single_env_snapshot is not None:
                gym_snapshot = {
                    'symbol': single_env_snapshot.get('symbol'),
                    'lookback_window': single_env_snapshot.get('lookback_window'),
                    'indicators_config': single_env_snapshot.get('indicators_config'),
                    'reward_scale': single_env_snapshot.get('cfg_reward_scale', 1.0),
                    'episode_length': single_env_snapshot.get('episode_length'),
                    'position_sizing': single_env_snapshot.get('position_sizing', {}),
                    'risk_management': single_env_snapshot.get('risk_management', {}),
                    'observation_space_shape': single_env_snapshot.get('observation_space_shape'),
                    'step_minutes': single_env_snapshot.get('step_minutes', 5),
                    'funding_features': {
                        'present_in_input_df': funding_present,
                        'included': bool(funding_present),
                    },
                }
            else:
                gym_snapshot = {
                    'symbol': None,
                    'lookback_window': None,
                    'indicators_config': None,
                    'reward_scale': 1.0,
                    'episode_length': None,
                    'position_sizing': {},
                    'risk_management': {},
                    'observation_space_shape': None,
                    'step_minutes': 5,
                    'funding_features': {
                        'present_in_input_df': funding_present,
                        'included': bool(funding_present),
                    },
                }
        except Exception:
            gym_snapshot = {}

        # –°–Ω–∏–º–æ–∫ —Å–∏—Å—Ç–µ–º—ã
        train_metadata = {
            'created_at_utc': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'hostname': platform.node(),
            'platform': platform.platform(),
            'python_version': platform.python_version(),
            'pytorch_version': torch.__version__,
            'cuda_available': torch.cuda.is_available(),
            'gpu_name': (torch.cuda.get_device_name(0) if torch.cuda.is_available() else None),
        }

        # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤
        steps_per_episode = episode_length or 2000
        approx_actual_episodes = int(train_steps * n_envs / steps_per_episode)
        # –¢–æ—á–Ω—ã–µ —à–∞–≥–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        try:
            if isinstance(result, dict) and 'env_step' in result:
                env_steps_total = int(result['env_step'])
            else:
                env_steps_total = int(train_steps * n_envs)
        except Exception:
            env_steps_total = int(train_steps * n_envs)

        cfg_like = {
            'model_path': str(model_path),
            'replay_buffer_path': str(replay_path),
            'run_id': this_run_id,
        }

        weights_info = {
            'model_path': str(model_path),
            'buffer_path': str(replay_path),
            'model_sha256': _sha256_of_file(str(model_path)) if model_path.exists() else None,
            'buffer_sha256': _sha256_of_file(str(replay_path)) if Path(replay_path).exists() else None,
        }

        # –ê–≥—Ä–µ–≥–∞—Ç—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è (–ø–æ –±—É—Ñ–µ—Ä—É): action_counts –∏ —ç–ø–∏–∑–æ–¥—ã —Å —Ç—Ä–µ–π–¥–æ–º
        action_counts_total = {0: 0, 1: 0, 2: 0}
        episodes_with_trade_count = 0
        buy_attempts_total = 0
        buy_rejected_vol_total = 0
        buy_rejected_roi_total = 0
        try:
            acts = getattr(buf, 'act', None)
            dones = getattr(buf, 'done', None)
            infos = getattr(buf, 'info', None)
            if acts is not None:
                arr = np.array(acts).reshape(-1)
                for a in (0, 1, 2):
                    action_counts_total[a] = int(np.sum(arr == a))
                if dones is not None:
                    d = np.array(dones).reshape(-1)
                    # –ü—Ä–æ–±–µ–∂–∏–º—Å—è –ø–æ —ç–ø–∏–∑–æ–¥–∞–º: —Å—á–∏—Ç–∞–µ–º —ç–ø–∏–∑–æ–¥ —Å–æ–¥–µ—Ä–∂–∞—â–∏–º —Ç—Ä–µ–π–¥, –µ—Å–ª–∏ –µ—Å—Ç—å act!=0
                    ep_has_trade = False
                    for i, a in enumerate(arr):
                        if a != 0:
                            ep_has_trade = True
                        if i < len(d) and d[i]:
                            if ep_has_trade:
                                episodes_with_trade_count += 1
                            ep_has_trade = False
            # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–æ–±—Ä–∞—Ç—å buy-* –º–µ—Ç—Ä–∏–∫–∏ –∏ —Ç—Ä–µ–π–¥—ã –∏–∑ info
            if infos is not None:
                try:
                    flat_infos = np.array(infos, dtype=object).reshape(-1)
                    collected_trades = []
                    for it in flat_infos:
                        if isinstance(it, dict):
                            buy_attempts_total += int(it.get('buy_attempts', 0) or 0)
                            buy_rejected_vol_total += int(it.get('buy_rejected_vol', 0) or 0)
                            buy_rejected_roi_total += int(it.get('buy_rejected_roi', 0) or 0)
                            if 'trades_episode' in it and isinstance(it['trades_episode'], list):
                                collected_trades.extend(it['trades_episode'])
                    if collected_trades:
                        # –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ —É—Å–µ—á—å –¥–æ —Ä–∞–∑—É–º–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                        all_trades = collected_trades
                except Exception:
                    pass
        except Exception:
            pass

        # Adaptive normalization snapshot (single or multi)
        adaptive_snapshot = {}
        try:
            if _is_multi_crypto(dfs):
                per_symbol = {}
                for sym, data in (dfs.items() if isinstance(dfs, dict) else []):
                    try:
                        df5s = data.get('df_5min') if isinstance(data, dict) else None
                        if df5s is None:
                            continue
                        base_profile = adaptive_normalizer.get_crypto_profile(sym)
                        market = adaptive_normalizer.analyze_market_conditions(df5s)
                        adapted = adaptive_normalizer.adapt_parameters(sym, df5s)
                        per_symbol[sym] = {
                            'base_profile': base_profile,
                            'market_conditions': market,
                            'adapted_params': adapted,
                        }
                    except Exception:
                        continue
                adaptive_snapshot = {'per_symbol': per_symbol}
            else:
                df5 = dfs.get('df_5min') if isinstance(dfs, dict) else None
                sym = symbol
                if df5 is not None and isinstance(sym, str):
                    base_profile = adaptive_normalizer.get_crypto_profile(sym)
                    market = adaptive_normalizer.analyze_market_conditions(df5)
                    adapted = adaptive_normalizer.adapt_parameters(sym, df5)
                    adaptive_snapshot = {
                        'symbol': sym,
                        'base_profile': base_profile,
                        'market_conditions': market,
                        'adapted_params': adapted,
                    }
        except Exception:
            adaptive_snapshot = {}

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–¥–µ–ª–∫–∞–º
        try:
            winrate_from_trades = None
            avg_roi = None
            num_trades = len(all_trades) if isinstance(all_trades, list) else 0
            total_profit = None
            total_loss = None
            avg_duration = None
            if num_trades > 0:
                rois = [float(t.get('roi', 0.0)) for t in all_trades if isinstance(t, dict)]
                if rois:
                    wins = sum(1 for r in rois if r > 0)
                    winrate_from_trades = wins / len(rois)
                    avg_roi = float(np.mean(rois))
                    total_profit = float(sum(r for r in rois if r > 0))
                    total_loss = float(abs(sum(r for r in rois if r < 0)))
                try:
                    durations = [float(t.get('duration', 0.0)) for t in all_trades if isinstance(t, dict) and t.get('duration') is not None]
                    if durations:
                        avg_duration = float(np.mean(durations))
                except Exception:
                    avg_duration = None
        except Exception:
            winrate_from_trades = None
            avg_roi = None
            total_profit = None
            total_loss = None
            avg_duration = None

        # –§–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è epsilon –∏ lr
        try:
            epsilon_final_value = getattr(policy, 'eps', None)
        except Exception:
            epsilon_final_value = None
        try:
            current_lr = None
            for g in optim.param_groups:
                current_lr = g.get('lr', None)
                break
            learning_rate_final_value = float(current_lr) if current_lr is not None else None
        except Exception:
            learning_rate_final_value = None

        # –°–±–æ—Ä –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –ø—Ä–∏—á–∏–Ω –ø—Ä–æ–¥–∞–∂ —á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ API (—É—Å—Ç–æ–π—á–∏–≤–æ –¥–ª—è Subproc/Dummy)
        sell_types_agg = {}
        try:
            # 1) –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å —ç–∫—Å–ø–æ—Ä—Ç –ø—Ä—è–º–æ –∏–∑ —Å—Ä–µ–¥ (—Ä–∞–±–æ—Ç–∞–µ—Ç –≤ SubprocVectorEnv —á–µ—Ä–µ–∑ call)
            export_list = None
            try:
                if hasattr(train_envs, 'call'):
                    export_list = train_envs.call('export_cumulative_sell_types')
                elif hasattr(train_envs, 'get_attr'):
                    export_list = train_envs.get_attr('export_cumulative_sell_types')
            except Exception:
                export_list = None
            if isinstance(export_list, list) and export_list:
                for st in export_list:
                    try:
                        if callable(st):
                            st = st()
                        if isinstance(st, dict):
                            for k, v in st.items():
                                sell_types_agg[k] = sell_types_agg.get(k, 0) + int(v or 0)
                    except Exception:
                        pass
            # 2) –§–æ–ª–±—ç–∫: –∏–∑ –≤—Ä–∞–ø–ø–µ—Ä–æ–≤ (snapshot –ø—Ä–∏ done)
            if not sell_types_agg:
                env_list = []
                if hasattr(train_envs, 'envs'):
                    env_list = getattr(train_envs, 'envs') or []
                elif isinstance(train_envs, (list, tuple)):
                    env_list = train_envs
                for _env in env_list:
                    try:
                        snap = getattr(_env, 'cumulative_sell_stats', None)
                        if isinstance(snap, dict) and snap:
                            for k, v in snap.items():
                                sell_types_agg[k] = sell_types_agg.get(k, 0) + int(v or 0)
                    except Exception:
                        pass
            # 3) –§–æ–ª–±—ç–∫: –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –±–∞–∑–æ–≤—ã—Ö env (cumulative_sell_types / sell_types)
            if not sell_types_agg:
                env_list = []
                if hasattr(train_envs, 'envs'):
                    env_list = getattr(train_envs, 'envs') or []
                elif isinstance(train_envs, (list, tuple)):
                    env_list = train_envs
                for _env in env_list:
                    try:
                        cur = _env
                        for _ in range(10):
                            if hasattr(cur, 'env'):
                                cur = getattr(cur, 'env')
                            else:
                                break
                        st = getattr(cur, 'cumulative_sell_types', None)
                        if not isinstance(st, dict):
                            st = getattr(cur, 'sell_types', None)
                        if isinstance(st, dict):
                            for k, v in st.items():
                                sell_types_agg[k] = sell_types_agg.get(k, 0) + int(v or 0)
                    except Exception:
                        pass
        except Exception:
            sell_types_agg = {}

        training_results = {
            'episodes': episodes,
            'actual_episodes': approx_actual_episodes,
            'total_training_time': total_training_time,
            'episode_winrates': epoch_test_rewards,  # –ø—Ä–æ–∫—Å–∏ –ø–æ —Ç–µ—Å—Ç-–Ω–∞–≥—Ä–∞–¥–∞–º
            'all_trades': all_trades,
            'bad_trades': [],
            'bad_trades_count': 0,
            'bad_trades_percentage': 0.0,
            'best_winrate': (max(epoch_test_rewards) if epoch_test_rewards else winrate_from_trades),
            'final_stats': {
                'num_trades': num_trades,
                'winrate_from_trades': winrate_from_trades,
                'avg_roi': avg_roi,
                'total_profit': total_profit,
                'total_loss': total_loss,
                'avg_duration': avg_duration,
            },
            'training_date': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'model_path': str(model_path),
            'buffer_path': str(replay_path),
            'symbol': symbol,
            'model_id': this_run_id,
            'early_stopping_triggered': bool(stopped_by_trend),
            'reward_scale': float(single_env_snapshot.get('cfg_reward_scale', 1.0)) if isinstance(single_env_snapshot, dict) else 1.0,
            'total_steps_processed': env_steps_total,
            'episode_length': episode_length,
            'action_counts_total': action_counts_total,
            'episodes_with_trade_count': episodes_with_trade_count,
            'episodes_with_trade_ratio': (episodes_with_trade_count / float(approx_actual_episodes)) if approx_actual_episodes > 0 else 0.0,
            'buy_attempts_total': buy_attempts_total or 0,
            'buy_rejected_vol_total': buy_rejected_vol_total or 0,
            'buy_rejected_roi_total': buy_rejected_roi_total or 0,
            'epsilon_final_value': epsilon_final_value,
            'learning_rate_final_value': learning_rate_final_value,
            'buy_accept_rate': ((action_counts_total.get(1, 0) or 0) / float(buy_attempts_total) if (buy_attempts_total or 0) > 0 else 0.0),
            'avg_minutes_between_buys': (
                ((env_steps_total * float(gym_snapshot.get('step_minutes', 5))) / float(action_counts_total.get(1, 0)))
                if (action_counts_total.get(1, 0) or 0) > 0 else None
            ),
            'best_episode_idx': (best_epoch if isinstance(best_epoch, int) and best_epoch >= 0 else None),
            # –ü—Ä–æ–¥–ª–µ–Ω–∏—è —ç–ø–∏–∑–æ–¥–æ–≤ (–∞–≥—Ä–µ–≥–∞—Ç—ã —Å train_envs)
            'episode_extensions_total': int(total_ext_count),
            'episode_extension_steps_total': int(total_ext_steps),
            'sell_types_total': sell_types_agg,
        }
        print(f"training_results train_result.pkl {training_results}")
        enriched_results = {
            **training_results,
            'train_metadata': train_metadata,
            'cfg_snapshot': cfg_like,
            'gym_snapshot': gym_snapshot,
            'adaptive_normalization': adaptive_snapshot,
            'hyperparameters': {
                'lr': lr,
                'gamma': gamma,
                'batch_size': batch_size,
                'target_update_freq': target_update_freq,
                'eps_start': (eps_start_override if 'eps_start_override' in locals() and eps_start_override is not None else None),
                'eps_final': (eps_final_override if 'eps_final_override' in locals() and eps_final_override is not None else None),
                'eps_decay_steps': (eps_decay_steps_override if 'eps_decay_steps_override' in locals() and eps_decay_steps_override is not None else None),
                'memory_size': memory_size,
                'train_repeats': train_repeats,
            },
            'architecture': {
                'main': {'model_class': net.__class__.__name__},
                'target': {},
            },
            'weights': weights_info,
        }

        print("‚Äî> –í—Ö–æ–∂—É –≤ –±–ª–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è train_result.pkl")
        results_file = run_dir / 'train_result.pkl'
        import pickle
        try:
            with open(results_file, 'wb') as f:
                pickle.dump(enriched_results, f)
            saved_train_result = True
            print(f"üíæ train_result.pkl —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {results_file}")
        except Exception as pe:
            import traceback
            traceback.print_exc()
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å train_result.pkl ({pe})")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–¥–µ–ª–æ–∫ –∑–∞ —Ä–∞–Ω –≤ all_trades.json (–µ—Å–ª–∏ –µ—Å—Ç—å)
        try:
            if isinstance(all_trades, list) and len(all_trades) > 0:
                trades_json_path = run_dir / 'all_trades.json'
                try:
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–¥–µ–ª–∫–∏ –∫ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º–æ–º—É –≤–∏–¥—É
                    def _norm_trade(t):
                        if isinstance(t, dict):
                            return {
                                k: v for k, v in t.items()
                                if isinstance(k, str) and isinstance(v, (int, float, str, bool, type(None)))
                            }
                        return t
                    safe_trades = [_norm_trade(t) for t in all_trades]
                    with open(trades_json_path, 'w', encoding='utf-8') as tf:
                        _json.dump(safe_trades, tf, ensure_ascii=False)
                    print(f"üíæ all_trades.json —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {trades_json_path} (count={len(safe_trades)})")
                except Exception as te:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å all_trades.json: {te}")
        except Exception:
            pass

        # –ü–æ–¥—Ä–æ–±–Ω—ã–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ (–∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–º —Ç—Ä–µ–Ω–µ—Ä–µ)
        try:
            print("\n" + "="*60)
            training_name = symbol
            print(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–£–ß–ï–ù–ò–Ø –¥–ª—è {training_name}")
            print("="*60)
            print(f"‚è±Ô∏è –í–†–ï–ú–Ø –û–ë–£–ß–ï–ù–ò–Ø:")
            print(f"  ‚Ä¢ –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_training_time:.2f} —Å–µ–∫—É–Ω–¥ ({total_training_time/60:.1f} –º–∏–Ω—É—Ç)")
            planned = episodes
            actual = approx_actual_episodes
            if actual and actual > 0:
                print(f"  ‚Ä¢ –í—Ä–µ–º—è –Ω–∞ —ç–ø–∏–∑–æ–¥: {total_training_time/max(1,actual):.2f} —Å–µ–∫—É–Ω–¥")
                print(f"  ‚Ä¢ –≠–ø–∏–∑–æ–¥–æ–≤ –≤ –º–∏–Ω—É—Ç—É: {actual/(total_training_time/60):.1f}")
            print(f"\nüìà –≠–ü–ò–ó–û–î–´:")
            print(f"  ‚Ä¢ –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ —ç–ø–∏–∑–æ–¥—ã: {planned}")
            print(f"  ‚Ä¢ –†–µ–∞–ª—å–Ω—ã–µ —ç–ø–∏–∑–æ–¥—ã (–æ—Ü–µ–Ω–∫–∞): {actual}")
            print(f"  ‚Ä¢ Early Stopping: {'–°—Ä–∞–±–æ—Ç–∞–ª' if stopped_by_trend else '–ù–µ —Å—Ä–∞–±–æ—Ç–∞–ª'}")
            try:
                print(f"  ‚Ä¢ –ü—Ä–æ–¥–ª–µ–Ω–∏—è —ç–ø–∏–∑–æ–¥–æ–≤: {int(total_ext_count)} —Ä–∞–∑ (+{int(total_ext_steps)} —à–∞–≥–æ–≤)")
            except Exception:
                pass
            if epoch_test_rewards:
                try:
                    avg_wr = float(np.mean(epoch_test_rewards))
                    print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π winrate (–ø–æ —Ç–µ—Å—Ç-–Ω–∞–≥—Ä–∞–¥–µ): {avg_wr:.3f}")
                except Exception:
                    pass
            if isinstance(all_trades, list) and len(all_trades) > 0:
                print(f"\nüí∞ –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–¥–µ–ª–∫–∞–º:")
                if total_profit is not None:
                    print(f"  ‚Ä¢ –û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: {total_profit:.4f}")
                if total_loss is not None:
                    print(f"  ‚Ä¢ –û–±—â–∏–π —É–±—ã—Ç–æ–∫: {total_loss:.4f}")
                if avg_duration is not None:
                    print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–¥–µ–ª–∫–∏: {avg_duration:.1f} –º–∏–Ω—É—Ç")
            # –ü–µ—á–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –ø—Ä–∏—á–∏–Ω –ø—Ä–æ–¥–∞–∂
            if isinstance(sell_types_agg, dict) and sell_types_agg:
                print(f"\nüßæ –ü—Ä–∏—á–∏–Ω—ã –ø—Ä–æ–¥–∞–∂ (–∞–≥—Ä–µ–≥–∞—Ç):")
                for k, v in sell_types_agg.items():
                    print(f"  ‚Ä¢ {k}: {int(v)}")
            else:
                print(f"\n‚ö†Ô∏è –ù–µ—Ç —Å–¥–µ–ª–æ–∫ (–ø–æ —Å–æ–±—Ä–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ)")
        except Exception as se:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–≤–µ—Å—Ç–∏ —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É: {se}")

        # manifest.json —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π
        try:
            manifest = {
                'run_id': this_run_id,
                'parent_run_id': parent_run_id,
                'root_id': root_id or this_run_id,
                'symbol': symbol_dir,
                'seed': (int(seed) if isinstance(seed, int) else None),
                'episodes_start': 0,
                'episodes_end': approx_actual_episodes,
                'episodes_added': approx_actual_episodes,
                'episodes_last': approx_actual_episodes,
                'episodes_best': (best_epoch if best_epoch >= 0 else None),
                'created_at': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
                'debug': bool(debug_run or debug_exploration),
                'debug_flags': [
                    f for f, on in (
                        ('TS_DEBUG_RUN', debug_run),
                        ('TS_DEBUG_EXPLORATION', debug_exploration),
                        ('TS_FORCE_SINGLE', force_single),
                        ('TS_FORCE_DUMMY', force_dummy),
                    ) if on
                ],
                'artifacts': {
                    'model': 'model.pth',
                    'replay': 'replay.pkl' if Path(replay_path).exists() else None,
                    'result': 'train_result.pkl',
                    'best_model': 'best_model.pth' if (run_dir / 'best_model.pth').exists() else None,
                    'last_model': 'last_model.pth' if (run_dir / 'last_model.pth').exists() else None,
                },
                'best_metrics': {
                    'winrate': (winrate_from_trades if (winrate_from_trades is not None) else (max(epoch_test_rewards) if epoch_test_rewards else None)),
                    'reward': (best_reward if best_reward is not None else (max(epoch_test_rewards) if epoch_test_rewards else None))
                }
            }
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é (final)
            print(f"üí°[Final] –°–æ—Ö—Ä–∞–Ω—è–µ–º manifest.json –≤ {run_dir / 'manifest.json'}")
            print(manifest)
            with open(run_dir / 'manifest.json', 'w', encoding='utf-8') as mf:
                _json.dump(manifest, mf, ensure_ascii=False, indent=2)
            print(f"üíæ manifest.json —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {run_dir / 'manifest.json'}")
            try:
                with open(run_dir / 'manifest.json', 'r', encoding='utf-8') as _mf_check:
                    _mf_check.flush(); os.fsync(_mf_check.fileno())
            except Exception:
                pass
        except Exception as me:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å manifest.json: {me}")
            import traceback; traceback.print_exc()
    except Exception as e:
        import traceback
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–ª–æ–∫–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ train_result.pkl: {e}")
        traceback.print_exc()

    print(f"‚úÖ Tianshou DQN: –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_path}")
    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º stdout/stderr –∏ –∑–∞–∫—Ä–æ–µ–º –ª–æ–≥
    try:
        import sys as _sys
        if _orig_stdout is not None:
            _sys.stdout = _orig_stdout
        if _orig_stderr is not None:
            _sys.stderr = _orig_stderr
        if _log_fp is not None:
            _log_fp.close()
    except Exception:
        pass

    # –ü—Ä–æ–±—Ä–æ—Å seed –≤ –æ–∫—Ä—É–∂–µ–Ω–∏—è (VectorEnv / Dummy / —Å–ø–∏—Å–∫–∏)
    try:
        if isinstance(seed, int):
            # train envs
            try:
                if hasattr(train_envs, 'seed'):
                    train_envs.seed(seed)
                else:
                    for i, env in enumerate(train_envs):
                        try:
                            env.reset(seed=seed + i)
                        except Exception:
                            pass
            except Exception:
                pass
            # test envs (—Å–¥–≤–∏–≥, —á—Ç–æ–±—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞–ª–∏)
            try:
                seed_test = seed + 1000
                if hasattr(test_envs, 'seed'):
                    test_envs.seed(seed_test)
                else:
                    for i, env in enumerate(test_envs):
                        try:
                            env.reset(seed=seed_test + i)
                        except Exception:
                            pass
            except Exception:
                pass
    except Exception as final_e:
        import traceback
        print(f"‚ùå –§–∞—Ç–∞–ª—å–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏: {final_e}")
        traceback.print_exc()
        raise

    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ train_result.pkl (–ø–æ–≤—Ç–æ—Ä) ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞–Ω–µ–µ –Ω–µ —É–¥–∞–ª–æ—Å—å
    if (not saved_train_result) and ('enriched_results' in locals()):
        print("‚Äî> –í—ã–ø–æ–ª–Ω—è—é —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ train_result.pkl (–ø–æ–≤—Ç–æ—Ä)")
        try:
            import pickle, traceback
            results_path = run_dir / 'train_result.pkl'
            with open(results_path, 'wb') as _f:
                pickle.dump(enriched_results, _f)
            saved_train_result = True
            print(f"üíæ —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ train_result.pkl —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {results_path}")
        except Exception as _err:
            traceback.print_exc()
    return str(run_dir)


def _sanitize_info_for_tianshou(info: dict) -> dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ–º –¢–û–õ–¨–ö–û —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä —Å–∫–∞–ª—è—Ä–Ω—ã—Ö –ø–æ–ª–µ–π.
    –ù–∏–∫–∞–∫–∏—Ö —Å–ø–∏—Å–∫–æ–≤/–º–∞—Å—Å–∏–≤–æ–≤, —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –∫–ª—é—á–µ–π –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ,
    —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å shape mismatch –≤ –±—É—Ñ–µ—Ä–µ Tianshou.
    """
    # –ù–∞–±–æ—Ä –∫–ª—é—á–µ–π, –∫–æ—Ç–æ—Ä—ã–π –≤—Å–µ–≥–¥–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç
    sanitized = {
        'current_balance': 0.0,
        'current_price': 0.0,
        'total_profit': 0.0,
        'reward': 0.0,
        'action_counts_0': 0,
        'action_counts_1': 0,
        'action_counts_2': 0,
        'trades_count': 0,
        'market_state': 0,
        'mask_0': 1,
        'mask_1': 1,
        'mask_2': 1,
    }
    if not isinstance(info, dict):
        return sanitized

    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º —Å–∫–∞–ª—è—Ä—ã
    try:
        v = info.get('current_balance')
        if isinstance(v, (int, float)):
            sanitized['current_balance'] = float(v)
    except Exception:
        pass
    try:
        v = info.get('current_price')
        if isinstance(v, (int, float)):
            sanitized['current_price'] = float(v)
    except Exception:
        pass
    try:
        v = info.get('total_profit')
        if isinstance(v, (int, float)):
            sanitized['total_profit'] = float(v)
    except Exception:
        pass
    try:
        v = info.get('reward')
        if isinstance(v, (int, float)):
            sanitized['reward'] = float(v)
    except Exception:
        pass

    # action_counts -> —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏
    try:
        ac = info.get('action_counts')
        if isinstance(ac, dict):
            sanitized['action_counts_0'] = int(ac.get(0, 0))
            sanitized['action_counts_1'] = int(ac.get(1, 0))
            sanitized['action_counts_2'] = int(ac.get(2, 0))
    except Exception:
        pass

    # trades_episode -> —Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    try:
        te = info.get('trades_episode')
        if isinstance(te, (list, tuple)):
            sanitized['trades_count'] = int(len(te))
    except Exception:
        pass

    # market_state and mask fields (must be scalars)
    try:
        v = info.get('market_state')
        if isinstance(v, (int, float)):
            sanitized['market_state'] = int(v)
    except Exception:
        pass
    for k in ('mask_0', 'mask_1', 'mask_2'):
        try:
            v = info.get(k)
            if isinstance(v, (int, float)):
                sanitized[k] = int(v)
        except Exception:
            pass

    return sanitized
