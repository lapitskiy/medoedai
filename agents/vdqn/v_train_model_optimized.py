import os
import re
import sys
import tempfile
import logging
import numpy as np
import torch
import wandb
import time
import psutil
from typing import Any, Dict, List, Optional
import pickle
from pickle import HIGHEST_PROTOCOL
import hashlib
import platform
from datetime import datetime
import subprocess
from utils.adaptive_normalization import adaptive_normalizer
import json as _json

from train.infrastructure.logging.tee import TailTruncatingTee
# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from agents.vdqn.dqnsolver import DQNSolver
from agents.vdqn.cfg.vconfig import vDqnConfig
from envs.dqn_model.gym.crypto_trading_env_optimized import CryptoTradingEnvOptimized
from train.infrastructure.gym.position_aware_wrapper import PositionAwareEpisodeWrapper
from train.domain.episode.extension_policy import EpisodeExtensionPolicy
from envs.dqn_model.gym.gconfig import GymConfig
from agents.vdqn.hyperparameter.symbol_overrides import get_symbol_override


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def _format_bytes(num_bytes: int) -> str:
    try:
        gb = num_bytes / (1024 ** 3)
        if gb >= 1:
            return f"{gb:.1f} GB"
        mb = num_bytes / (1024 ** 2)
        return f"{mb:.0f} MB"
    except Exception:
        return str(num_bytes)


def log_resource_usage(tag: str = "train", extra: str = "") -> None:
    try:
        process = psutil.Process(os.getpid())
        total_cpus = os.cpu_count() or 1
        cpu_total_pct = psutil.cpu_percent(interval=0.0)
        cpu_proc_pct = process.cpu_percent(interval=0.0)
        mem = psutil.virtual_memory()
        mem_total_pct = mem.percent
        mem_proc = process.memory_info().rss
        try:
            load1, _load5, _load15 = os.getloadavg()
            load_str = f"{load1:.1f}/{total_cpus}"
        except Exception:
            load_str = "n/a"
        omp = os.environ.get('OMP_NUM_THREADS')
        mkl = os.environ.get('MKL_NUM_THREADS')
        tor = os.environ.get('TORCH_NUM_THREADS')
        frac = os.environ.get('TRAIN_CPU_FRACTION')
        line = (
            f"[RES-{tag}] CPU {cpu_total_pct:.0f}% (proc {cpu_proc_pct:.0f}%), load {load_str}, "
            f"mem {mem_total_pct:.0f}% (proc {_format_bytes(mem_proc)}), "
            f"OMP/MKL/TORCH={omp}/{mkl}/{tor}"
            + (f", FRACTION={frac}" if frac else "")
            + (f" | {extra}" if extra else "")
        )
        print(line, flush=True)
    except Exception:
        pass


def _sha256_of_file(path: str) -> Optional[str]:
    try:
        h = hashlib.sha256()
        with open(path, 'rb') as f:
            for chunk in iter(lambda: f.read(1024 * 1024), b''):
                h.update(chunk)
        return h.hexdigest()
    except Exception:
        return None


def _atomic_write_json(path: str, data: Dict) -> None:
    try:
        dir_path = os.path.dirname(path) or "."
        fd, tmp_path = tempfile.mkstemp(dir=dir_path, prefix=".tmp_", suffix=".json")
        try:
            with os.fdopen(fd, 'w', encoding='utf-8') as f:
                _json.dump(data, f, ensure_ascii=False, indent=2)
            os.replace(tmp_path, path)
        except Exception:
            try:
                if os.path.exists(tmp_path):
                    os.remove(tmp_path)
            except Exception:
                pass
            raise
    except Exception:
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–±–æ–π –∑–∞–ø–∏—Å–∏ (–Ω–µ –ª–æ–º–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ)
        pass


def _safe_read_json(path: str) -> Any:
    try:
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                return _json.load(f)
    except Exception:
        return None
    return None


def _safe_cfg_snapshot(cfg_obj) -> Dict:
    try:
        snap = {}
        for k, v in (cfg_obj.__dict__.items() if hasattr(cfg_obj, '__dict__') else []):
            try:
                if str(type(v)).endswith("torch.device'>"):
                    snap[k] = str(v)
                elif hasattr(v, 'tolist'):
                    snap[k] = v.tolist()
                else:
                    snap[k] = v
            except Exception:
                snap[k] = str(v)
        return snap
    except Exception:
        return {}


def _architecture_summary(model: torch.nn.Module) -> Dict:
    try:
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        sample_keys = []
        try:
            sd = model.state_dict()
            for i, k in enumerate(sd.keys()):
                if i >= 10:
                    break
                sample_keys.append(k)
        except Exception:
            pass
        return {
            'model_class': model.__class__.__name__,
            'total_params': int(total_params),
            'trainable_params': int(trainable_params),
            'state_dict_keys_sample': sample_keys,
        }
    except Exception:
        return {}


def get_env_attr_safe(env, name: str, default=None):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —á–∏—Ç–∞–µ—Ç –∞—Ç—Ä–∏–±—É—Ç —Å—Ä–µ–¥—ã –±–µ–∑ –≤–∞—Ä–Ω–∏–Ω–≥–æ–≤ Gym.
    1) –ü—ã—Ç–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ get_wrapper_attr (–¥–ª—è –æ–±—ë—Ä—Ç–æ–∫)
    2) –ó–∞—Ç–µ–º –∏–∑ env.unwrapped
    3) –ó–∞—Ç–µ–º –Ω–∞–ø—Ä—è–º—É—é –∏–∑ env
    """
    try:
        if hasattr(env, 'get_wrapper_attr'):
            try:
                val = env.get_wrapper_attr(name)
                if val is not None:
                    return val
            except Exception:
                pass
    except Exception:
        pass
    try:
        base = getattr(env, 'unwrapped', None)
        if base is not None and hasattr(base, name):
            return getattr(base, name)
    except Exception:
        pass
    return default


def set_env_attr_safe(env, name: str, value) -> bool:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∞—Ç—Ä–∏–±—É—Ç –±–∞–∑–æ–≤–æ–π —Å—Ä–µ–¥—ã (unwrapped),
    –ø—Ä–∏ –Ω–µ—É–¥–∞—á–µ ‚Äî –ø—Ä—è–º–æ –Ω–∞ env. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ.
    """
    try:
        base = getattr(env, 'unwrapped', None)
        if base is not None:
            setattr(base, name, value)
            return True
    except Exception:
        pass
    try:
        setattr(env, name, value)
        return True
    except Exception:
        return False

def prepare_data_for_training(dfs: Dict) -> Dict:
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—è DataFrame –≤ numpy –º–∞—Å—Å–∏–≤—ã
    
    Args:
        dfs: —Å–ª–æ–≤–∞—Ä—å —Å DataFrame –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        
    Returns:
        Dict: —Å–ª–æ–≤–∞—Ä—å —Å numpy –º–∞—Å—Å–∏–≤–∞–º–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
    """
    print(f"üìä –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    required_keys = ['df_5min', 'df_15min', 'df_1h']
    for key in required_keys:
        if key not in dfs:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {key} –≤ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        if dfs[key] is None or dfs[key].empty:
            raise ValueError(f"{key} –ø—É—Å—Ç–æ–π –∏–ª–∏ None")
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã: 5min={len(dfs['df_5min'])}, 15min={len(dfs['df_15min'])}, 1h={len(dfs['df_1h'])}")
    
    return dfs

def _save_training_results(
    run_dir: str,
    cfg, # vDqnConfig
    training_name: str,
    current_episode: int, # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π —ç–ø–∏–∑–æ–¥ –∏–ª–∏ —Ç–µ–∫—É—â–∏–π –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    total_episodes_planned: int, # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤
    all_trades: list,
    episode_winrates: list,
    best_winrate: float,
    best_episode_idx: int,
    action_counts_total: dict,
    buy_attempts_total: int,
    buy_rejected_vol_total: int,
    buy_rejected_roi_total: int,
    episodes_with_trade_count: int,
    total_steps_processed: int,
    episode_length: Optional[int],
    seed: Optional[int],
    dqn_solver, # DQNSolver instance
    env, # CryptoTradingEnvOptimized or MultiCryptoTradingEnv instance
    is_multi_crypto: bool,
    parent_run_id: Optional[str],
    root_id: Optional[str],
    training_start_time: float,
    current_total_training_time: float, # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π
    dfs: Optional[Dict] = None,
):
    try:
        total_training_time = current_total_training_time

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫ (—É–±—ã—Ç–æ—á–Ω—ã–µ —Å–¥–µ–ª–∫–∏)
        bad_trades_list = []
        try:
            if all_trades:
                bad_trades_list = [t for t in all_trades if t.get('roi', 0) < 0]
        except Exception:
            bad_trades_list = []

        bad_trades_count = len(bad_trades_list)
        total_trades_count = len(all_trades) if all_trades else 0
        bad_trades_percentage = (bad_trades_count / total_trades_count * 100.0) if total_trades_count > 0 else 0.0

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, –µ—Å–ª–∏ –µ—Å—Ç—å —Å–¥–µ–ª–∫–∏, –∏–Ω–∞—á–µ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
        stats_all = dqn_solver.print_trade_stats(all_trades) if all_trades and dqn_solver is not None else {}

        training_results = {
            'episodes': total_episodes_planned,  # –ü–ª–∞–Ω–∏—Ä—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤
            'actual_episodes': current_episode,  # –†–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤ (—Ç–µ–∫—É—â–∏–π —ç–ø–∏–∑–æ–¥)
            'total_training_time': total_training_time,
            'episode_winrates': episode_winrates,
            'all_trades': all_trades,
            'bad_trades': bad_trades_list,
            'bad_trades_count': bad_trades_count,
            'bad_trades_percentage': bad_trades_percentage,
            'best_winrate': best_winrate,
            'final_stats': stats_all,
            'training_date': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'model_path': cfg.model_path,
            'buffer_path': getattr(cfg, 'replay_buffer_path', getattr(cfg, 'buffer_path', None)),
            'symbol': training_name,
            'model_id': getattr(cfg, 'run_id', None) or (run_dir.split(os.sep)[-1] if run_dir else None), # –ò—Å–ø–æ–ª—å–∑—É–µ–º run_id –∏–∑ cfg –∏–ª–∏ –∏–∑ run_dir
            'early_stopping_triggered': current_episode < total_episodes_planned,  # True –µ—Å–ª–∏ early stopping —Å—Ä–∞–±–æ—Ç–∞–ª
            'reward_scale': float(getattr(get_env_attr_safe(env, 'cfg'), 'reward_scale', 1.0)),
            # --- –ù–æ–≤—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è ---
            'action_counts_total': action_counts_total,
            'buy_attempts_total': buy_attempts_total,
            'buy_rejected_vol_total': buy_rejected_vol_total,
            'buy_rejected_roi_total': buy_rejected_roi_total,
            'buy_accept_rate': ( (action_counts_total.get(1, 0) or 0) / float(buy_attempts_total) ) if buy_attempts_total > 0 else 0.0,
            'episodes_with_trade_count': episodes_with_trade_count,
            'episodes_with_trade_ratio': (episodes_with_trade_count / float(current_episode)) if current_episode > 0 else 0.0,
            'avg_minutes_between_buys': ( (total_steps_processed * 5.0) / float(action_counts_total.get(1, 0) or 1) ) if (action_counts_total.get(1, 0) or 0) > 0 else None,
            'total_steps_processed': total_steps_processed,
            'episode_length': episode_length, # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª–∏–Ω—É —ç–ø–∏–∑–æ–¥–∞
            # –ü—Ä–æ–¥–∞–∂–∏ –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º (–∫—É–º—É–ª—è—Ç–∏–≤–Ω–æ –∏–∑ env)
            'sell_types_total': (get_env_attr_safe(env, 'cumulative_sell_types', {})),
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ dqn_solver
            'epsilon_final_value': dqn_solver.epsilon if dqn_solver is not None else None,
            'learning_rate_final_value': dqn_solver.optimizer.param_groups[0]['lr'] if dqn_solver and dqn_solver.optimizer and dqn_solver.optimizer.param_groups else None,
             # BUY/HOLD –∞–≥—Ä–µ–≥–∞—Ç—ã
             'buy_stats_total': (get_env_attr_safe(env, 'buy_stats_total', {})),
             'hold_stats_total': (get_env_attr_safe(env, 'hold_stats_total', {})),
        }
        
        # –ü–µ—á–∞—Ç—å BUY/HOLD —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        try:
            buy_total = get_env_attr_safe(env, 'buy_stats_total', {})
            hold_total = get_env_attr_safe(env, 'hold_stats_total', {})
            if isinstance(buy_total, dict) and buy_total:
                print("\nüìä –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è BUY:")
                for k, v in buy_total.items():
                    print(f"  ‚Ä¢ {k}: {int(v)}")
            if isinstance(hold_total, dict) and hold_total:
                print("\nüìä –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è HOLD:")
                for k, v in hold_total.items():
                    print(f"  ‚Ä¢ {k}: {int(v)}")
        except Exception:
            pass
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –∑–∞–ø—É—Å–∫–∞
        git_commit = None
        try:
            git_commit = subprocess.check_output(['git','rev-parse','--short','HEAD'], stderr=subprocess.DEVNULL).decode().strip()
        except Exception:
            pass
        train_seed = seed if isinstance(seed, int) else None
        train_metadata = {
            'created_at_utc': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'hostname': platform.node(),
            'platform': platform.platform(),
            'python_version': platform.python_version(),
            'pytorch_version': torch.__version__,
            'cuda_available': torch.cuda.is_available(),
            'gpu_name': (torch.cuda.get_device_name(0) if torch.cuda.is_available() else None),
            'omp_threads': os.environ.get('OMP_NUM_THREADS'),
            'mkl_threads': os.environ.get('MKL_NUM_THREADS'),
            'torch_threads': os.environ.get('TORCH_NUM_THREADS'),
            'train_cpu_fraction': os.environ.get('TRAIN_CPU_FRACTION'),
            'git_commit': git_commit,
            'script': os.path.basename(__file__),
            'seed': train_seed,
        }

        # –°–Ω–∏–º–æ–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        cfg_snapshot = _safe_cfg_snapshot(cfg)
        arch_main = _architecture_summary(dqn_solver.model) if dqn_solver and hasattr(dqn_solver, 'model') else {}
        arch_target = _architecture_summary(dqn_solver.target_model) if dqn_solver and hasattr(dqn_solver, 'target_model') else {}
        
        # –°–Ω–∏–º–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏) ---
        gym_snapshot = {}
        try:
            cfg_obj = get_env_attr_safe(env, 'cfg')
            gym_snapshot = {
                'symbol': get_env_attr_safe(env, 'symbol'),
                'lookback_window': get_env_attr_safe(env, 'lookback_window'),
                'indicators_config': get_env_attr_safe(env, 'indicators_config'),
                'reward_scale': getattr(cfg_obj, 'reward_scale', 1.0),
                'episode_length': get_env_attr_safe(env, 'episode_length'),
                'funding_features': {
                    'present_in_input_df': [], # Not directly available from env, needs to be passed
                    'included': False,
                },
                'risk_management': {
                    'STOP_LOSS_PCT': get_env_attr_safe(env, 'STOP_LOSS_PCT'),
                    'TAKE_PROFIT_PCT': get_env_attr_safe(env, 'TAKE_PROFIT_PCT'),
                    'min_hold_steps': get_env_attr_safe(env, 'min_hold_steps'),
                    'volume_threshold': get_env_attr_safe(env, 'volume_threshold'),
                    'base_stop_loss': get_env_attr_safe(env, 'base_stop_loss'),
                    'base_take_profit': get_env_attr_safe(env, 'base_take_profit'),
                    'base_min_hold': get_env_attr_safe(env, 'base_min_hold'),
                },
                'position_sizing': {
                    'base_position_fraction': get_env_attr_safe(env, 'base_position_fraction'),
                    'position_fraction': get_env_attr_safe(env, 'position_fraction'),
                    'position_confidence_threshold': get_env_attr_safe(env, 'position_confidence_threshold'),
                },
                'observation_space_shape': get_env_attr_safe(env, 'observation_space_shape'),
                'step_minutes': getattr(cfg_obj, 'step_minutes', 5),
            }
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ gym_snapshot: {e}")
            gym_snapshot = {}

        # --- –°–Ω–∏–º–æ–∫ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (–ø–æ —Å–∏–º–≤–æ–ª–∞–º) ---
        adaptive_snapshot = {}
        try:
            if is_multi_crypto:
                per_symbol = {}
                # –î–ª—è –º—É–ª—å—Ç–∏-—Ä–µ–∂–∏–º–∞ –ª—É—á—à–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å–Ω–∞–ø—à–æ—Ç –≤ —Å—Ä–µ–¥–µ –∏ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Å—é–¥–∞ —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.
                adaptive_snapshot = {'per_symbol': per_symbol}
            else:
                # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–ª–∏ dfs, —Ñ–∏–∫—Å–∏—Ä—É–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ—Ä–µ–π–º–∞—Ö
                if dfs:
                    adaptive_snapshot = {
                        'frames': {
                            key: {
                                'rows': len(value) if hasattr(value, '__len__') else None
                            }
                            for key, value in dfs.items()
                        }
                    }
                else:
                    adaptive_snapshot = {}
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ adaptive_snapshot: {e}")
            adaptive_snapshot = {}
            
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ—Å–∞—Ö (–ø—É—Ç–∏ –∏ —Ö—ç—à–∏)
        weights_info = {
            'model_path': cfg.model_path,
            'buffer_path': getattr(cfg, 'replay_buffer_path', getattr(cfg, 'buffer_path', None)),
            'model_sha256': _sha256_of_file(cfg.model_path) if cfg and getattr(cfg, 'model_path', None) and os.path.exists(cfg.model_path) else None,
            'buffer_sha256': _sha256_of_file(getattr(cfg, 'replay_buffer_path', getattr(cfg, 'buffer_path', None))) if cfg and getattr(cfg, 'replay_buffer_path', getattr(cfg, 'buffer_path', None)) and os.path.exists(getattr(cfg, 'replay_buffer_path', getattr(cfg, 'buffer_path', None))) else None,
            'encoder_path': getattr(cfg, 'encoder_path', None),
            'encoder_sha256': _sha256_of_file(getattr(cfg, 'encoder_path', None)) if cfg and getattr(cfg, 'encoder_path', None) and os.path.exists(getattr(cfg, 'encoder_path', None)) else None,
        }

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º
        enriched_results = {
            **training_results,
            'train_metadata': train_metadata,
            'cfg_snapshot': cfg_snapshot,
            'gym_snapshot': gym_snapshot,
            'adaptive_normalization': adaptive_snapshot,
            'architecture': {
                'main': arch_main,
                'target': arch_target,
            },
            'weights': weights_info,
        }

        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(run_dir, exist_ok=True)
        results_file = os.path.join(run_dir, 'train_result.pkl')

        with open(results_file, 'wb') as f:
            pickle.dump(enriched_results, f, protocol=HIGHEST_PROTOCOL)
        
        logger.info(f"üìä –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_file}")

        # === –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ result/<SYMBOL>/runs/<run_id>/ ===
        # –ö–æ–ø–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ –ø–∞–ø–∫—É –∑–∞–ø—É—Å–∫–∞ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏
        try:
            import shutil as _sh
            # –ú–æ–¥–µ–ª—å
            if cfg and getattr(cfg, 'model_path', None) and os.path.exists(cfg.model_path):
                _dst_m = os.path.join(run_dir, 'model.pth')
                if os.path.abspath(cfg.model_path) != os.path.abspath(_dst_m):
                    _sh.copy2(cfg.model_path, _dst_m)
            # –ë—É—Ñ–µ—Ä
            buffer_path = getattr(cfg, 'replay_buffer_path', getattr(cfg, 'buffer_path', None))
            if cfg and buffer_path and os.path.exists(buffer_path):
                _dst_b = os.path.join(run_dir, 'replay.pkl')
                if os.path.abspath(buffer_path) != os.path.abspath(_dst_b):
                    _sh.copy2(buffer_path, _dst_b)
            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if os.path.exists(results_file):
                _dst_r = os.path.join(run_dir, 'train_result.pkl')
                if os.path.abspath(results_file) != os.path.abspath(_dst_r):
                    _sh.copy2(results_file, _dst_r)
        except Exception as _copy_err:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ {run_dir}: {_copy_err}")

        # –ü–∏—à–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç (–º–∏–Ω–∏–º—É–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö; –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ —É–∂–µ –≤ train_result.pkl)
        symbol_dir_name = training_name # –ò—Å–ø–æ–ª—å–∑—É–µ–º training_name, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω
        manifest = {
            'run_id': getattr(cfg, 'run_id', None) or (run_dir.split(os.sep)[-1] if run_dir else None),
            'parent_run_id': parent_run_id,
            'root_id': root_id,
            'symbol': symbol_dir_name,
            'seed': int(seed) if isinstance(seed, int) else None,
            'episodes_start': 0 if not (getattr(cfg, 'load_model_path', None) or getattr(cfg, 'load_buffer_path', None)) else None, # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –∏–ª–∏ –±—É—Ñ–µ—Ä –∑–∞–≥—Ä—É–∂–∞–ª–∏—Å—å
            'episodes_end': int(current_episode),
            'episodes_added': int(current_episode) if not (getattr(cfg, 'load_model_path', None) or getattr(cfg, 'load_buffer_path', None)) else int(current_episode - (getattr(cfg, 'start_episode', 0))), # –°—á–∏—Ç–∞–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ —ç–ø–∏–∑–æ–¥—ã
            'episodes_last': int(current_episode),
            'episodes_best': int(best_episode_idx) if best_episode_idx is not None and best_episode_idx >= 0 else None,
            'created_at': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'artifacts': {
                'model': 'model.pth',
                'replay': 'replay.pkl' if (dqn_solver and getattr(dqn_solver, 'cfg', None) and getattr(dqn_solver.cfg, 'buffer_path', None)) else None,
                'result': 'train_result.pkl',
                'best_model': 'best_model.pth' if os.path.exists(os.path.join(run_dir, 'best_model.pth')) else None,
                'last_model': 'last_model.pth' if os.path.exists(os.path.join(run_dir, 'last_model.pth')) else None,
                'encoder': getattr(cfg, 'encoder_path', None)
            },
            'best_metrics': {
                'winrate': float(best_winrate) if isinstance(best_winrate, (int, float)) else None
            }
        }
        try:
            with open(os.path.join(run_dir, 'manifest.json'), 'w', encoding='utf-8') as mf:
                _json.dump(manifest, mf, ensure_ascii=False, indent=2)
        except Exception as _mf_err:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å manifest.json: {_mf_err}")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è: {e}", exc_info=True)


def train_model_optimized(
    dfs: Dict,
    cfg: Optional[vDqnConfig] = None,
    episodes: int = 10,
    patience_limit: int = 3000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 2000 –¥–æ 3000 –¥–ª—è –±–æ–ª–µ–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    use_wandb: bool = False,
    load_model_path: Optional[str] = None,
    load_buffer_path: Optional[str] = None,
    seed: Optional[int] = None,
    run_id: Optional[str] = None,
    parent_run_id: Optional[str] = None,
    root_id: Optional[str] = None,
    episode_length: Optional[int] = None,
) -> str:
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª–∏ –±–µ–∑ pandas –≤ hot-path
    
    Args:
        dfs: —Å–ª–æ–≤–∞—Ä—å —Å DataFrame –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ (df_5min, df_15min, df_1h)
        cfg: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        episodes: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        patience_limit: –ª–∏–º–∏—Ç —Ç–µ—Ä–ø–µ–Ω–∏—è –¥–ª—è early stopping (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 2000 —ç–ø–∏–∑–æ–¥–æ–≤)
        use_wandb: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ Weights & Biases
        
    Returns:
        str: —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
    """
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è wandb
    wandb_run = None
    if use_wandb:
        try:
            run_name = getattr(cfg, 'run_name', 'default') if cfg else 'default'
            config_dict = cfg.__dict__ if cfg else {}
            
            wandb_run = wandb.init(
                project="medoedai-optimized",
                name=f"vDQN-optimized-{run_name}",
                config=config_dict
            )
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å wandb: {e}")
            use_wandb = False
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª–æ–≤—ã–π –ª–æ–≥ —Å —Ç—Ä–∏–º–º–∏–Ω–≥–æ–º (DDD infra)
        run_dir = None
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if cfg is None:
            cfg = vDqnConfig()
            print("‚ö†Ô∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö: –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω—ã–µ –∏–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã–µ
        is_multi_crypto = False
        if dfs and isinstance(dfs, dict):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–ª—é—á–∏ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç
            first_key = list(dfs.keys())[0]
            if isinstance(first_key, str) and first_key.endswith('USDT'):
                # –≠—Ç–æ –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                is_multi_crypto = True
                print(f"üåç –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {len(dfs)} –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç")
                for symbol, data in dfs.items():
                    print(f"  ‚Ä¢ {symbol}: {data.get('candle_count', 'N/A')} —Å–≤–µ—á–µ–π")
        
        if is_multi_crypto:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
            from envs.dqn_model.gym.crypto_trading_env_multi import MultiCryptoTradingEnv
            env = MultiCryptoTradingEnv(dfs=dfs, cfg=cfg, episode_length=episode_length)
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è {len(dfs)} –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç")
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–π –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã
            dfs = prepare_data_for_training(dfs)
            # --- SYMBOL-SPECIFIC OVERRIDES ---
            crypto_symbol = None
            try:
                if isinstance(dfs, dict):
                    crypto_symbol = dfs.get('symbol') or dfs.get('SYMBOL')
                if not crypto_symbol:
                    # –ø–æ–ø—ã—Ç–∫–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
                    crypto_symbol = 'TONUSDT' if 'TON' in str(dfs).upper() else None
            except Exception:
                crypto_symbol = None

            override = get_symbol_override(crypto_symbol) if crypto_symbol else None
            # –ø—Ä–∏–º–µ–Ω—è–µ–º training_params –∫ cfg
            if override and 'training_params' in override:
                for k, v in override['training_params'].items():
                    if hasattr(cfg, k):
                        try:
                            setattr(cfg, k, v)
                        except Exception:
                            pass
                try:
                    print(f"üîß SYMBOL OVERRIDE[{crypto_symbol}] | lr={getattr(cfg,'lr',None)} | eps=({getattr(cfg,'eps_start',None)}‚Üí{getattr(cfg,'eps_final',None)}) | decay={getattr(cfg,'eps_decay_steps',None)} | batch={getattr(cfg,'batch_size',None)} | mem={getattr(cfg,'memory_size',None)} | repeats={getattr(cfg,'train_repeats',None)} | soft_every={getattr(cfg,'soft_update_every',None)} | target_freq={getattr(cfg,'target_update_freq',None)}")
                except Exception:
                    pass

            # indicators_config –¥–ª—è env
            indicators_config = None
            if override and 'indicators_config' in override:
                indicators_config = override['indicators_config']

            # –°–æ–∑–¥–∞–µ–º GymConfig –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            gym_cfg = GymConfig()
            base_env = CryptoTradingEnvOptimized(
                dfs=dfs,
                cfg=gym_cfg,
                lookback_window=override.get('gym_config', {}).get('lookback_window', gym_cfg.lookback_window) if override else gym_cfg.lookback_window,
                indicators_config=indicators_config,
                episode_length=episode_length or gym_cfg.episode_length
            )
            # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º env –ø—Ä–æ–¥–ª–µ–Ω–∏–µ–º —ç–ø–∏–∑–æ–¥–∞ –Ω–∞ +100 —à–∞–≥–æ–≤ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏
            policy = EpisodeExtensionPolicy(max_extension=20, extension_steps=100)
            env = PositionAwareEpisodeWrapper(base_env, policy=policy)

            # risk_management –≤ env
            if override and 'risk_management' in override:
                rm = override['risk_management']
                for field_name, env_attr in [
                    ('STOP_LOSS_PCT', 'STOP_LOSS_PCT'),
                    ('TAKE_PROFIT_PCT', 'TAKE_PROFIT_PCT'),
                    ('min_hold_steps', 'min_hold_steps'),
                    ('volume_threshold', 'volume_threshold'),
                ]:
                    if field_name in rm:
                        set_env_attr_safe(env, env_attr, rm[field_name])
                try:
                    print(f"üîß RISK OVERRIDE[{crypto_symbol}] | SL={get_env_attr_safe(env,'STOP_LOSS_PCT')} | TP={get_env_attr_safe(env,'TAKE_PROFIT_PCT')} | minHold={get_env_attr_safe(env,'min_hold_steps')} | volThr={get_env_attr_safe(env,'volume_threshold')}")
                except Exception:
                    pass
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –æ–±—ã—á–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–π –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã")
        
        # –ù–∞—á–∏–Ω–∞–µ–º –æ—Ç—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        training_start_time = time.time()

        # --- –°–Ω–∏–º–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏) ---
        gym_snapshot = {}
        try:
            df5 = dfs.get('df_5min') if isinstance(dfs, dict) else None
            funding_cols = ['funding_rate_bp', 'funding_rate_ema', 'funding_rate_change', 'funding_sign']
            funding_present = []
            try:
                if df5 is not None and hasattr(df5, 'columns'):
                    funding_present = [c for c in funding_cols if c in df5.columns]
            except Exception:
                funding_present = []

            # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞
            cfg_obj2 = get_env_attr_safe(env, 'cfg')
            gym_snapshot = {
                'symbol': get_env_attr_safe(env, 'symbol'),
                'lookback_window': get_env_attr_safe(env, 'lookback_window'),
                'indicators_config': get_env_attr_safe(env, 'indicators_config'),
                'reward_scale': getattr(cfg_obj2, 'reward_scale', 1.0),
                'episode_length': get_env_attr_safe(env, 'episode_length'),
                'funding_features': {
                    'present_in_input_df': funding_present,
                    'included': bool(funding_present),
                },
                'risk_management': {
                    'STOP_LOSS_PCT': get_env_attr_safe(env, 'STOP_LOSS_PCT'),
                    'TAKE_PROFIT_PCT': get_env_attr_safe(env, 'TAKE_PROFIT_PCT'),
                    'min_hold_steps': get_env_attr_safe(env, 'min_hold_steps'),
                    'volume_threshold': get_env_attr_safe(env, 'volume_threshold'),
                    'base_stop_loss': get_env_attr_safe(env, 'base_stop_loss'),
                    'base_take_profit': get_env_attr_safe(env, 'base_take_profit'),
                    'base_min_hold': get_env_attr_safe(env, 'base_min_hold'),
                },
                'position_sizing': {
                    'base_position_fraction': get_env_attr_safe(env, 'base_position_fraction'),
                    'position_fraction': get_env_attr_safe(env, 'position_fraction'),
                    'position_confidence_threshold': get_env_attr_safe(env, 'position_confidence_threshold'),
                },
                'observation_space_shape': get_env_attr_safe(env, 'observation_space_shape'),
                'step_minutes': getattr(cfg_obj2, 'step_minutes', 5),
            }
        except Exception:
            gym_snapshot = {}

        # --- –°–Ω–∏–º–æ–∫ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (–ø–æ —Å–∏–º–≤–æ–ª–∞–º) ---
        adaptive_snapshot = {}
        try:
            if is_multi_crypto:
                per_symbol = {}
                for sym, data in dfs.items():
                    try:
                        df5s = data.get('df_5min') if isinstance(data, dict) else None
                        if df5s is None:
                            continue
                        base_profile = adaptive_normalizer.get_crypto_profile(sym)
                        market = adaptive_normalizer.analyze_market_conditions(df5s)
                        adapted = adaptive_normalizer.adapt_parameters(sym, df5s)
                        per_symbol[sym] = {
                            'base_profile': base_profile,
                            'market_conditions': market,
                            'adapted_params': adapted,
                        }
                    except Exception:
                        continue
                adaptive_snapshot = {'per_symbol': per_symbol}
            else:
                df5s = dfs.get('df_5min') if isinstance(dfs, dict) else None
                sym = crypto_symbol
                if df5s is not None and isinstance(sym, str):
                    base_profile = adaptive_normalizer.get_crypto_profile(sym)
                    market = adaptive_normalizer.analyze_market_conditions(df5s)
                    adapted = adaptive_normalizer.adapt_parameters(sym, df5s)
                    adaptive_snapshot = {
                        'symbol': sym,
                        'base_profile': base_profile,
                        'market_conditions': market,
                        'adapted_params': adapted,
                    }
        except Exception:
            adaptive_snapshot = {}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ
        if not hasattr(getattr(env, 'unwrapped', env), 'observation_space_shape'):
            # –ü–æ–ø—Ä–æ–±—É–µ–º –≤—ã—á–∏—Å–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏–∑ observation_space
            if hasattr(env, 'observation_space') and hasattr(env.observation_space, 'shape'):
                set_env_attr_safe(env, 'observation_space_shape', env.observation_space.shape[0])
                print(f"‚ö†Ô∏è –í—ã—á–∏—Å–ª–µ–Ω —Ä–∞–∑–º–µ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏–∑ observation_space: {get_env_attr_safe(env,'observation_space_shape')}")
            else:
                raise ValueError("–û–∫—Ä—É–∂–µ–Ω–∏–µ –Ω–µ –∏–º–µ–µ—Ç observation_space_shape –∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–∏–º–≤–æ–ª –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        if is_multi_crypto:
            crypto_symbol = "–ú–£–õ–¨–¢–ò–í–ê–õ–Æ–¢–ê"  # –î–ª—è –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            print(f"‚úÖ –ú—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ, —Ä–∞–∑–º–µ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è: {get_env_attr_safe(env,'observation_space_shape')}")
        else:
            crypto_symbol = get_env_attr_safe(env, 'symbol', 'UNKNOWN')
            print(f"‚úÖ –û–∫—Ä—É–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ –¥–ª—è {crypto_symbol}, —Ä–∞–∑–º–µ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è: {get_env_attr_safe(env,'observation_space_shape')}")

        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤—ã–≤–æ–¥–∞ –∏ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ–¥ —Å–∏–º–≤–æ–ª
        def _symbol_code(sym: str) -> str:
            if not isinstance(sym, str) or not sym:
                return "model"
            s = sym.upper().replace('/', '')
            for suffix in ["USDT", "USD", "USDC", "BUSD", "USDP"]:
                if s.endswith(suffix):
                    s = s[:-len(suffix)]
                    break
            s = s.lower() if s else "model"
            if s in ("–º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–∞", "multi", "multicrypto"):
                s = "multi"
            return s

        result_dir = os.path.join("result", "dqn")
        os.makedirs(result_dir, exist_ok=True)
        symbol_code = _symbol_code(crypto_symbol)
        # –ö–æ—Ä–æ—Ç–∫–∏–π UUID –¥–ª—è –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        import uuid
        short_id = str(uuid.uuid4())[:4].lower()

        # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: result/dqn/<SYMBOL>/runs/<run_id>/
        # –ü–∞–ø–∫–∞ —Å–∏–º–≤–æ–ª–∞ –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ (TON, BTC, BNB...) –≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        symbol_dir_name = _symbol_code(crypto_symbol).upper() if crypto_symbol else "UNKNOWN"
        # –ö–æ—Ä–æ—Ç–∫–∏–π run_id (4 —Å–∏–º–≤–æ–ª–∞) –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω
        this_run_id = run_id or str(uuid.uuid4())[:4]
        this_root_id = root_id or this_run_id
        run_dir = os.path.join("result", "dqn", symbol_dir_name, "runs", this_run_id)
        os.makedirs(run_dir, exist_ok=True)

        # –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º stdout –≤ —Ñ–∞–π–ª train.log —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º 100 –ú–ë (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ö–≤–æ—Å—Ç)
        try:
            log_path = os.path.join(run_dir, 'train.log')
            sys.stdout = TailTruncatingTee(log_path, max_bytes=100*1024*1024)
        except Exception:
            pass

        # –ö–æ–¥ –¥–ª—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        artifacts_code = f"{symbol_code}_{short_id}"

        # –ï—Å–ª–∏ —ç—Ç–æ –¥–æ–æ–±—É—á–µ–Ω–∏–µ (–µ—Å—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å –∫ –≤–µ—Å–∞–º) ‚Äî –¥–æ–±–∞–≤–∏–º —Å—É—Ñ—Ñ–∏–∫—Å _update[<n>]
        try:
            if load_model_path and isinstance(load_model_path, str):
                base_name = os.path.basename(load_model_path)
                m = re.match(r"^dqn_model_(.+)\.pth$", base_name)
                if m:
                    base_code = m.group(1)
                    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π next-—Å—É—Ñ—Ñ–∏–∫—Å: _update, _update_2, _update_3, ...
                    # –ò–∑–±–µ–≥–∞–µ–º _update_update –∏ —Ñ–æ—Ä–º–∞—Ç–∞ –±–µ–∑ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è
                    mm = re.match(r"^(.*?)(?:_update(?:_(\d+))?)?$", base_code)
                    if mm:
                        root = mm.group(1) or base_code
                        n_str = mm.group(2)
                        if base_code.endswith('_update') and not n_str:
                            # –ë—ã–ª–æ ..._update ‚Üí —Å—Ç–∞–Ω–µ—Ç ..._update_2
                            next_code = f"{root}_update_2"
                        elif n_str is not None:
                            next_code = f"{root}_update_{int(n_str)+1}"
                        else:
                            # –ü–µ—Ä–≤—ã–π –¥–æ–æ–±—É—á–µ–Ω–Ω—ã–π –∞—Ä—Ç–µ—Ñ–∞–∫—Ç
                            next_code = f"{base_code}_update"
                    else:
                        next_code = f"{base_code}_update"

                    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å, –ø—Ä–∏ –∫–æ–ª–ª–∏–∑–∏–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É–µ–º –Ω–æ–º–µ—Ä
                    candidate = next_code
                    while (
                        os.path.exists(os.path.join(result_dir, f"dqn_model_{candidate}.pth")) or
                        os.path.exists(os.path.join(result_dir, f"replay_buffer_{candidate}.pkl")) or
                        os.path.exists(os.path.join(result_dir, f"train_result_{candidate}.pkl"))
                    ):
                        mm2 = re.match(r"^(.*?)(?:_update(?:_(\d+))?)?$", candidate)
                        if mm2:
                            root2 = mm2.group(1) or candidate
                            n2 = mm2.group(2)
                            if n2 is None:
                                candidate = f"{root2}_update_2"
                            else:
                                candidate = f"{root2}_update_{int(n2)+1}"
                        else:
                            candidate = candidate + "_update_2"

                    artifacts_code = candidate
        except Exception:
            pass

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ù–û–í–´–ï –ø—É—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: —Å—Ä–∞–∑—É –≤ run_dir
        new_model_path = os.path.join(run_dir, 'model.pth')
        new_buffer_path = os.path.join(run_dir, 'replay.pkl')

        # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞ –∏–∑ dfs ---
        encoder_cfg = dfs.get('encoder') if isinstance(dfs, dict) else {}
        selected_encoder_id = None
        train_encoder_flag = True
        try:
            if isinstance(encoder_cfg, dict):
                val = encoder_cfg.get('id')
                selected_encoder_id = str(val).strip() if val else None
                train_encoder_flag = bool(encoder_cfg.get('train_encoder', True))
        except Exception:
            selected_encoder_id = None
            train_encoder_flag = True

        # freeze_encoder = not train_encoder
        try:
            setattr(cfg, 'freeze_encoder', not train_encoder_flag)
        except Exception:
            pass

        # –ì–¥–µ –∏—Å–∫–∞—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π —ç–Ω–∫–æ–¥–µ—Ä (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω):
        base_encoder_path = None
        base_encoder_root = None
        if selected_encoder_id:
            try:
                # result/dqn/<SYMBOL>/encoder/unfrozen/vN/encoder_only.pth
                cand1 = os.path.join("result", "dqn", symbol_dir_name, "encoder", "unfrozen", selected_encoder_id, "encoder_only.pth")
                # models/<symbol>/encoder/unfrozen/vN/encoder_only.pth
                cand2 = os.path.join("models", symbol_dir_name.lower(), "encoder", "unfrozen", selected_encoder_id, "encoder_only.pth")
                for pth in (cand1, cand2):
                    if os.path.exists(pth):
                        base_encoder_path = pth
                        base_encoder_root = 'result' if pth.startswith(os.path.join('result', 'dqn')) else 'models'
                        break
            except Exception:
                base_encoder_path = None
                base_encoder_root = None

        # –¢–∏–ø —ç–Ω–∫–æ–¥–µ—Ä–∞ –¥–ª—è –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏/–∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        encoder_base = os.path.join("result", "dqn", symbol_dir_name, "encoder")
        encoder_type = "frozen" if getattr(cfg, 'freeze_encoder', False) else "unfrozen"
        encoder_type_dir = os.path.join(encoder_base, encoder_type)
        try:
            os.makedirs(encoder_type_dir, exist_ok=True)
        except Exception:
            pass

        # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç—Ä–µ–Ω–∏—Ä—É–µ–º —ç–Ω–∫–æ–¥–µ—Ä –∏–ª–∏ —ç–Ω–∫–æ–¥–µ—Ä –Ω–µ –≤—ã–±—Ä–∞–Ω (–Ω–æ–≤—ã–π)
        create_new_encoder = bool(train_encoder_flag or not selected_encoder_id)
        created_encoder_version = None
        new_encoder_path = None
        version_dir = None
        if create_new_encoder:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–µ–¥—É—é—â—É—é –≤–µ—Ä—Å–∏—é vN (–æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞ –∑–∞–ø—É—Å–∫)
            version = 1
            try:
                existing_versions = []
                for _d in os.listdir(encoder_type_dir):
                    _p = os.path.join(encoder_type_dir, _d)
                    if os.path.isdir(_p) and _d.startswith('v'):
                        try:
                            existing_versions.append(int(_d[1:]))
                        except Exception:
                            continue
                version = (max(existing_versions) + 1) if existing_versions else 1
            except Exception:
                version = 1
            version_dir = os.path.join(encoder_type_dir, f"v{version}")
            try:
                os.makedirs(version_dir, exist_ok=True)
            except Exception:
                pass
            new_encoder_path = os.path.join(version_dir, 'encoder_only.pth')
            created_encoder_version = version
            # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            try:
                setattr(cfg, 'encoder_path', new_encoder_path)
                setattr(cfg, 'encoder_version', version)
                setattr(cfg, 'encoder_type', encoder_type)
            except Exception:
                pass
            try:
                print(f"üéØ Encoder target path: {new_encoder_path}")
            except Exception:
                pass
            # –ï—Å–ª–∏ –µ—Å—Ç—å –±–∞–∑–æ–≤—ã–π —ç–Ω–∫–æ–¥–µ—Ä (fine-tune) ‚Äî —Å–∫–æ–ø–∏—Ä—É–µ–º –∫–∞–∫ —Å—Ç–∞—Ä—Ç–æ–≤—É—é —Ç–æ—á–∫—É
            try:
                if base_encoder_path and os.path.exists(base_encoder_path):
                    import shutil as _sh
                    _sh.copy2(base_encoder_path, new_encoder_path)
            except Exception:
                pass
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–π –º–∞–Ω–∏—Ñ–µ—Å—Ç (–±—É–¥–µ—Ç –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω –∞—Ç–æ–º–∞—Ä–Ω–æ –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤)
            try:
                _atomic_write_json(os.path.join(version_dir, 'encoder_manifest.json'), {'status': 'pending'})
            except Exception:
                pass
        else:
            # –ù–µ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —ç–Ω–∫–æ–¥–µ—Ä –∫–∞–∫ –µ—Å—Ç—å (frozen head)
            try:
                if base_encoder_path:
                    setattr(cfg, 'encoder_path', base_encoder_path)
                    setattr(cfg, 'encoder_version', None)
                    setattr(cfg, 'encoder_type', 'unfrozen')
            except Exception:
                pass

        # –ï—Å–ª–∏ –¥–æ–æ–±—É—á–∞–µ–º –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏ runs/... –∏ parent/root –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã ‚Äî –∞–≤—Ç–æ‚Äë–¥–µ—Ç–µ–∫—Ç
        try:
            if (not parent_run_id) and load_model_path and isinstance(load_model_path, str):
                norm_path = load_model_path.replace('\\', '/')
                parts = norm_path.split('/')
                if len(parts) >= 4 and parts[-1] == 'model.pth' and 'runs' in parts:
                    runs_idx = parts.index('runs')
                    if runs_idx + 1 < len(parts):
                        parent_run_id = parts[runs_idx + 1]
                        # –ü—Ä–æ—á–∏—Ç–∞–µ–º root –∏–∑ manifest.json —Ä–æ–¥–∏—Ç–µ–ª—è, –µ—Å–ª–∏ –µ—Å—Ç—å
                        try:
                            parent_dir = os.path.dirname(load_model_path)
                            mf_path = os.path.join(parent_dir, 'manifest.json')
                            if os.path.exists(mf_path):
                                import json as _json
                                with open(mf_path, 'r', encoding='utf-8') as mf:
                                    mf_data = _json.load(mf)
                                root_id = root_id or mf_data.get('root_id') or parent_run_id
                            else:
                                root_id = root_id or parent_run_id
                        except Exception:
                            root_id = root_id or parent_run_id
        except Exception:
            pass

        # –ï—Å–ª–∏ —Å–∏–º–≤–æ–ª BNB ‚Äî –º—è–≥–∫–∏–µ –æ–≤–µ—Ä—Ä–∞–π–¥—ã –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        try:
            if not is_multi_crypto and isinstance(crypto_symbol, str) and 'BNB' in crypto_symbol.upper():
                # –°–Ω–∏–∂–∞–µ–º exploration –∏ lr, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º batch
                cfg.eps_start = min(getattr(cfg, 'eps_start', 1.0), 0.20)
                cfg.eps_final = max(getattr(cfg, 'eps_final', 0.01), 0.02)
                cfg.eps_decay_steps = int(getattr(cfg, 'eps_decay_steps', 1_000_000) * 0.75)
                cfg.batch_size = max(192, getattr(cfg, 'batch_size', 128))
                cfg.lr = min(getattr(cfg, 'lr', 1e-3), 2e-4)
                # –ß—É—Ç—å —Ä–µ–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±—É—Ñ–µ—Ä, —á—Ç–æ–±—ã –Ω–µ —Ç–æ—Ä–º–æ–∑–∏—Ç—å I/O
                cfg.buffer_save_frequency = max(
                    400,
                    int(getattr(cfg, 'buffer_save_frequency', 800))
                )
                print(
                    f"üîß BNB overrides: eps_start={cfg.eps_start}, eps_final={cfg.eps_final}, "
                    f"eps_decay_steps={cfg.eps_decay_steps}, batch_size={cfg.batch_size}, lr={cfg.lr}, "
                    f"buffer_save_frequency={getattr(cfg, 'buffer_save_frequency', 'n/a')}"
                )
        except Exception as _e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å BNB-–æ–≤–µ—Ä—Ä–∞–π–¥—ã: {_e}")

        # –°–æ–∑–¥–∞–µ–º DQN solver
        print(f"üöÄ –°–æ–∑–¥–∞—é DQN solver")
        
        dqn_solver = DQNSolver(
            observation_space=get_env_attr_safe(env, 'observation_space_shape'),
            action_space=env.action_space.n
        )
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏/–±—É—Ñ–µ—Ä–∞ ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ–º —Å–Ω–∞—á–∞–ª–∞
        if load_model_path and isinstance(load_model_path, str):
            try:
                dqn_solver.cfg.model_path = load_model_path
            except Exception:
                pass
        if load_buffer_path and isinstance(load_buffer_path, str):
            try:
                dqn_solver.cfg.replay_buffer_path = load_buffer_path
            except Exception:
                pass
        # –ï—Å–ª–∏ –≤–Ω–µ—à–Ω—è—è cfg –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥ –∏–∑ dqn_solver
        if cfg is None:
            cfg = dqn_solver.cfg
        
        # üöÄ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è PyTorch 2.x
        if torch.cuda.is_available():
            # –í–∫–ª—é—á–∞–µ–º cudnn benchmark –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —É—Å–∫–æ—Ä–µ–Ω–∏—è
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            
            # –í–∫–ª—é—á–∞–µ–º TF32 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –Ω–∞ Ampere+ GPU
            if hasattr(torch.backends.cuda, 'matmul.allow_tf32'):
                torch.backends.cuda.matmul.allow_tf32 = True
            if hasattr(torch.backends.cudnn, 'allow_tf32'):
                torch.backends.cudnn.allow_tf32 = True
                
            print("üöÄ CUDA –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–∫–ª—é—á–µ–Ω—ã: cudnn.benchmark, TF32")
        
        # –ê–≤—Ç–æ–ø–æ–¥–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π/–±—É—Ñ–µ—Ä–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞: —Å—Ç–∞—Ä—Ç –≤—Å–µ–≥–¥–∞ —Å –Ω—É–ª—è.
        print("üõë –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Å–æ–≤ –∏ replay buffer –æ—Ç–∫–ª—é—á–µ–Ω–∞ ‚Äî –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω—É–ª—è")

        # –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–µ–Ω–∞–∑–Ω–∞—á–∞–µ–º –ø—É—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞ –ù–û–í–´–ï –≤ result/<symbol>_<id>
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–ª–∏—á–∏—è –≤–Ω–µ—à–Ω–µ–π cfg
        try:
            dqn_solver.cfg.model_path = new_model_path
            dqn_solver.cfg.replay_buffer_path = new_buffer_path
            if hasattr(dqn_solver.cfg, 'encoder_path'):
                dqn_solver.cfg.encoder_path = new_encoder_path
        except Exception:
            pass
        try:
            if cfg is not None:
                cfg.model_path = dqn_solver.cfg.model_path
                cfg.replay_buffer_path = dqn_solver.cfg.replay_buffer_path
                if hasattr(cfg, 'encoder_path'):
                    cfg.encoder_path = dqn_solver.cfg.encoder_path
        except Exception:
            pass
        
        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        all_trades = []
        episode_winrates = []
        best_winrate = 0.0
        best_episode_idx = -1
         # Reduce-on-plateau –∏ warmup –¥–ª—è best
        lr_plateau_patience = int(getattr(cfg, 'lr_plateau_patience', 1000))
        lr_min = float(getattr(cfg, 'lr_min', 1e-5))
        best_warmup_episodes = int(getattr(cfg, 'best_warmup_episodes', 1500))
        reduce_plateau_only_for_retrain = bool(getattr(cfg, 'reduce_on_plateau_only_for_retrain', True))
        episodes_since_best = 0
        patience_counter = 0
        global_step = 0
        grad_steps = 0
        actual_episodes = episodes  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–∏–∑–æ–¥–æ–≤
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ exploration –≤ –Ω–∞—á–∞–ª–µ –¥–ª—è Noisy Networks
        if getattr(cfg, 'use_noisy_networks', True):
            dqn_solver.epsilon = 0.3  # –ù–∞—á–∏–Ω–∞–µ–º —Å 30% exploration
            #print(f"üîÄ Noisy Networks: –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ exploration —Å epsilon={dqn_solver.epsilon}")
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è early stopping (–£–õ–£–ß–®–ï–ù–û)
        min_episodes_before_stopping = getattr(cfg, 'min_episodes_before_stopping', max(4000, episodes // 3))  # –£–≤–µ–ª–∏—á–∏–ª —Å 3000 –¥–æ 4000 –∏ —Å 1/4 –¥–æ 1/3
        winrate_history = []  # –ò—Å—Ç–æ—Ä–∏—è winrate –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤
        recent_improvement_threshold = 0.002  # –£–≤–µ–ª–∏—á–∏–ª —Å 0.001 –¥–æ 0.002 –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        
        # --- –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è ---
        action_counts_total = {0: 0, 1: 0, 2: 0}
        buy_attempts_total = 0
        buy_rejected_vol_total = 0
        buy_rejected_roi_total = 0
        episodes_with_trade_count = 0
        total_steps_processed = 0
        # --- –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è freeze‚Äë—Ä–µ—à–µ–Ω–∏–π (–ª—ë–≥–∫–∏–µ –ø–æ —Ä–µ—Å—É—Ä—Å—É) ---
        q_loss_history: list[float] = []  # –∏—Å—Ç–æ—Ä–∏—è Q‚Äëloss –∏–∑ experience_replay
        probe_states: list[np.ndarray] = []  # —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        probe_size: int = int(getattr(cfg, 'probe_size', 64))
        probe_collect_episodes: int = int(getattr(cfg, 'probe_collect_episodes', 3))
        probe_collect_stride: int = int(getattr(cfg, 'probe_collect_stride', 100))  # –±—Ä–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–∞–∑ –≤ N —à–∞–≥–æ–≤
        probe_interval_episodes: int = int(getattr(cfg, 'probe_interval_episodes', 10))  # –∫–∞–∫ —á–∞—Å—Ç–æ –¥–µ–ª–∞—Ç—å —Å–Ω—ç–ø—à–æ—Ç—ã
        drift_cosine_history: list[float] = []  # —Å—Ä–µ–¥–Ω—è—è –∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å –∫ –±–∞–∑–æ–≤–æ–π –ø—Ä–æ–µ–∫—Ü–∏–∏
        drift_snapshot_episodes: list[int] = []
        q_values_history: list[np.ndarray] = []  # —Å—Ä–µ–¥–Ω–∏–µ Q –ø–æ –¥–µ–π—Å—Ç–≤–∏—è–º –¥–ª—è probe‚Äë—Å–æ—Å—Ç–æ—è–Ω–∏–π
        probe_embeddings_baseline: np.ndarray | None = None
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π patience_limit –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–∏–∑–æ–¥–æ–≤
        if episodes >= 10000:
            patience_limit = max(patience_limit, episodes // 3)  # –î–ª—è –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫ - –º–∏–Ω–∏–º—É–º 1/3 (–±—ã–ª–æ 1/2)
        elif episodes >= 5000:
            patience_limit = max(patience_limit, episodes // 4)  # –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫ - –º–∏–Ω–∏–º—É–º 1/4 (–±—ã–ª–æ 1/3)
        elif episodes >= 2000:
            patience_limit = max(patience_limit, episodes // 3)  # –î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫ - –º–∏–Ω–∏–º—É–º 1/3 (–±—ã–ª–æ 1/2)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º patience –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫
        patience_limit = max(patience_limit, 8000)  # –ú–∏–Ω–∏–º—É–º 8000 —ç–ø–∏–∑–æ–¥–æ–≤ (–±—ã–ª–æ 5000)
        
        long_term_patience = int(patience_limit * getattr(cfg, 'long_term_patience_multiplier', 2.5))
        trend_threshold = getattr(cfg, 'early_stopping_trend_threshold', 0.05)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–æ—Ä–æ–≥ —Ç—Ä–µ–Ω–¥–∞ —Å 0.03 –¥–æ 0.05
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        training_name = "–ú–£–õ–¨–¢–ò–í–ê–õ–Æ–¢–ê" if is_multi_crypto else crypto_symbol
        print(f"üéØ –ù–∞—á–∏–Ω–∞—é —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É –Ω–∞ {episodes} —ç–ø–∏–∑–æ–¥–æ–≤ –¥–ª—è {training_name}")
        print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Early Stopping:")
        print(f"  ‚Ä¢ min_episodes_before_stopping: {min_episodes_before_stopping}")
        print(f"  ‚Ä¢ patience_limit: {patience_limit}")
        print(f"  ‚Ä¢ long_term_patience: {long_term_patience}")
        print(f"  ‚Ä¢ trend_threshold: {trend_threshold}")
        print(f"  ‚Ä¢ –°–∞–º—ã–π —Ä–∞–Ω–Ω–∏–π stopping: {min_episodes_before_stopping + patience_limit} —ç–ø–∏–∑–æ–¥–æ–≤")            
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        save_frequency = getattr(cfg, 'save_frequency', 50)
        save_only_on_improvement = getattr(cfg, 'save_only_on_improvement', False)

        # –ß–∞—Å—Ç–æ—Ç–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤ (–∫–∞–∂–¥—ã–µ N —ç–ø–∏–∑–æ–¥–æ–≤)
        try:
            resource_log_every = int(os.getenv('TRAIN_LOG_EVERY_EPISODES', '100'))
        except Exception:
            resource_log_every = 100

        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        for episode in range(episodes):
            # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ —á–∞—Å—Ç–æ—Ç–µ
            if resource_log_every > 0 and (episode % resource_log_every == 0):
                log_resource_usage(tag="episode", extra=f"episode={episode}/{episodes}")

            state = env.reset()            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ state —è–≤–ª—è–µ—Ç—Å—è numpy –º–∞—Å—Å–∏–≤–æ–º
            if isinstance(state, (list, tuple)):
                state = np.array(state, dtype=np.float32)
            elif not isinstance(state, np.ndarray):
                state = np.array(state, dtype=np.float32)

            episode_reward = 0
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—É –¥–ª—è –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            current_crypto = crypto_symbol
            if is_multi_crypto and hasattr(env, 'current_symbol'):
                current_crypto = env.current_symbol
            
            print(f"  üéØ –≠–ø–∏–∑–æ–¥ {episode} –¥–ª—è {current_crypto} –Ω–∞—á–∞—Ç, reward={episode_reward}")
            
            # –≠–ø–∏–∑–æ–¥
            step_count = 0
            failed_train_attempts = 0
            while True:
                step_count += 1
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                if step_count % 10000 == 0:
                    print(f"    üîÑ Step {step_count} –≤ —ç–ø–∏–∑–æ–¥–µ {episode}")
                
                env.epsilon = dqn_solver.epsilon
                
                action = dqn_solver.act(state)
                state_next, reward, terminal, info = env.step(action)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º next_state –Ω–∞ NaN
                if isinstance(state_next, (list, tuple)):
                    state_next = np.array(state_next, dtype=np.float32)
                elif not isinstance(state_next, np.ndarray):
                    state_next = np.array(state_next, dtype=np.float32)
                
                # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
                try:
                    if np.isnan(state_next).any():
                        state_next = np.nan_to_num(state_next, nan=0.0)
                except (TypeError, ValueError):
                    # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ NaN, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy –∏ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞ (–±–µ–∑ —Å–ø–∞–º–∞ –≤ –ª–æ–≥)
                    state_next = np.array(state_next, dtype=np.float32)
                    if np.isnan(state_next).any():
                        state_next = np.nan_to_num(state_next, nan=0.0)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –≤ replay buffer
                dqn_solver.store_transition(state, action, reward, state_next, terminal)
                
                # –ü–æ–ª—É—á–∞–µ–º n-step transitions –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –≤ replay buffer
                # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç–ø–∏–∑–æ–¥ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω (–Ω–µ terminal)
                if not terminal:
                    n_step_transitions = env.get_n_step_return()
                    if n_step_transitions:
                        dqn_solver.memory.push_n_step(n_step_transitions)
                

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                state = state_next
                
                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π state —è–≤–ª—è–µ—Ç—Å—è numpy –º–∞—Å—Å–∏–≤–æ–º
                if isinstance(state, (list, tuple)):
                    state = np.array(state, dtype=np.float32)
                elif not isinstance(state, np.ndarray):
                    state = np.array(state, dtype=np.float32)
                
                episode_reward += reward
                global_step += 1
                total_steps_processed += 1
                
                # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —á–∞—â–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è (–£–õ–£–ß–®–ï–ù–û)
                soft_update_every = getattr(cfg, 'soft_update_every', 50)   # —á–∞—Å—Ç–æ—Ç–∞ –ø–æ–ø—ã—Ç–æ–∫ –æ–±—É—á–µ–Ω–∏—è
                batch_size = getattr(cfg, 'batch_size', 128)
                target_update_freq = getattr(cfg, 'target_update_freq', 500)
                train_repeats = max(1, int(getattr(cfg, 'train_repeats', 1)))
                
                if global_step % soft_update_every == 0 and len(dqn_solver.memory) >= batch_size:
                    # –í—ã–ø–æ–ª–Ω–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã—Ö —à–∞–≥–æ–≤ –ø–æ–¥—Ä—è–¥ –¥–ª—è –ª—É—á—à–µ–π –∑–∞–≥—Ä—É–∑–∫–∏ CPU
                    for _ in range(train_repeats):
                        success, loss, abs_q, q_gap = dqn_solver.experience_replay(need_metrics=True)
                        if success:
                            grad_steps += 1
                            # –ö–æ–ø–∏–º –∏—Å—Ç–æ—Ä–∏—é Q‚Äëloss –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è
                            try:
                                if loss is not None:
                                    q_loss_history.append(float(loss))
                            except Exception:
                                pass
                        else:
                            failed_train_attempts += 1
                            break
                    # –û–±–Ω–æ–≤–ª—è–µ–º target network –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
                    if global_step % target_update_freq == 0:
                        dqn_solver.update_target_model()

                if terminal:
                    break
                # –°–±–æ—Ä probe‚Äë—Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–ª—ë–≥–∫–∏–π, —Ä–µ–¥–∫–∏–π)
                try:
                    if (len(probe_states) < probe_size) and (episode < probe_collect_episodes) and (step_count % max(1, probe_collect_stride) == 1):
                        if isinstance(state, np.ndarray):
                            probe_states.append(state.copy())
                        else:
                            probe_states.append(np.array(state, dtype=np.float32))
                except Exception:
                    pass
            
            # –û–±–Ω–æ–≤–ª—è–µ–º epsilon (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º Noisy Networks)
            if not getattr(cfg, 'use_noisy_networks', True):
                eps_final = getattr(cfg, 'eps_final', 0.01)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π epsilon 0.01
                dqn_solver.epsilon = max(eps_final, dqn_solver.epsilon * dqn_solver._eps_decay_rate)
            else:
                # –ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ Noisy Networks –æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π epsilon –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                dqn_solver.epsilon = max(0.05, dqn_solver.epsilon * 0.999)  # –ú–∏–Ω–∏–º—É–º 5%
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —ç–ø–∏–∑–æ–¥–∞
            # –†–ê–î–ò–ö–ê–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º env.all_trades –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ winrate
            trades_before = len(all_trades)
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–æ–ª—É—á–∞–µ–º —Å–¥–µ–ª–∫–∏ —á–µ—Ä–µ–∑ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–æ—Å—Ç—É–ø
            _all_trades = get_env_attr_safe(env, 'all_trades') or []
            if _all_trades:
                episode_trades = _all_trades
            else:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º env.trades
                episode_trades = get_env_attr_safe(env, 'trades', []) or []
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º episode_winrate –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            episode_winrate = 0.0
            
            if _all_trades:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —Å–¥–µ–ª–∫–∏ –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ winrate
                all_profitable = [t for t in _all_trades if t.get('roi', 0) > 0]
                episode_winrate = len(all_profitable) / len(_all_trades) if _all_trades else 0
                episode_winrates.append(episode_winrate)
                
                # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–ø–∏–∑–æ–¥–∞
                episode_stats = dqn_solver.print_trade_stats(_all_trades, failed_attempts=failed_train_attempts)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–¥–µ–ª–∫–∏ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –µ—Å–ª–∏ –∏—Ö —Ç–∞–º –Ω–µ—Ç
                if len(all_trades) < len(_all_trades):
                    all_trades.extend(_all_trades[len(all_trades):])
                    
            elif episode_trades:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º env.trades
                all_trades.extend(episode_trades)
                
                # –í—ã—á–∏—Å–ª—è–µ–º winrate –¥–ª—è —ç–ø–∏–∑–æ–¥–∞
                profitable_trades = [t for t in episode_trades if t.get('roi', 0) > 0]
                episode_winrate = len(profitable_trades) / len(episode_trades) if episode_trades else 0
                episode_winrates.append(episode_winrate)
                
                # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–ø–∏–∑–æ–¥–∞
                episode_stats = dqn_solver.print_trade_stats(episode_trades, failed_attempts=failed_train_attempts)
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç —Å–¥–µ–ª–æ–∫ –≤–æ–æ–±—â–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–¥–µ–ª–∫–∏ –∏–∑ all_trades
                if len(all_trades) > 0:
                    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–¥–µ–ª–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ winrate
                    recent_trades = all_trades[-min(10, len(all_trades)):]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–¥–µ–ª–æ–∫
                    profitable_trades = [t for t in recent_trades if t.get('roi', 0) > 0]
                    episode_winrate = len(profitable_trades) / len(recent_trades) if recent_trades else 0
                    episode_winrates.append(episode_winrate)
                    episode_stats = dqn_solver.print_trade_stats(recent_trades, failed_attempts=failed_train_attempts)
                else:
                    # –ù–µ—Ç —Å–¥–µ–ª–æ–∫ –≤–æ–≤—Å–µ ‚Äî –≤—ã–≤–æ–¥–∏–º –∞–≥—Ä–µ–≥–∞—Ç–Ω—É—é —Å—Ç—Ä–æ–∫—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å Failed train
                    episode_winrate = 0.0
                    episode_winrates.append(episode_winrate)
                    episode_stats = dqn_solver.print_trade_stats([], failed_attempts=failed_train_attempts)
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —ç–ø–∏–∑–æ–¥–∞ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
                action_stats = ""
                _ac = get_env_attr_safe(env, 'action_counts')
                if isinstance(_ac, dict):
                    action_stats = f" | HOLD={_ac.get(0, 0)}, BUY={_ac.get(1, 0)}, SELL={_ac.get(2, 0)}"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                time_stats = ""
                _est = get_env_attr_safe(env, 'episode_start_time')
                _esc = get_env_attr_safe(env, 'episode_step_count', 0)
                if _est is not None:
                    episode_duration = time.time() - _est
                    steps_per_second = _esc / episode_duration if episode_duration > 0 else 0
                    time_stats = f" | {episode_duration:.2f}—Å, {_esc} —à–∞–≥–æ–≤, {steps_per_second:.1f} —à–∞–≥/—Å"
                
                print(f"  üèÅ –≠–ø–∏–∑–æ–¥ {episode} –¥–ª—è {current_crypto} –∑–∞–≤–µ—Ä—à–µ–Ω | reward={episode_reward:.4f}{action_stats}{time_stats} | {episode_stats}")

                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π —Å–Ω—ç–ø—à–æ—Ç feature drift –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ Q –Ω–∞ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º probe‚Äë–Ω–∞–±–æ—Ä–µ
                try:
                    if (len(probe_states) > 0) and (episode % max(1, probe_interval_episodes) == 0):
                        dqn_solver.model.eval()
                        with torch.no_grad():
                            st = torch.from_numpy(np.stack(probe_states)).float().to(dqn_solver.cfg.device)
                            # Q‚Äëvalues snapshot
                            q_vals = dqn_solver.model(st)
                            if isinstance(q_vals, torch.Tensor):
                                q_avg = q_vals.mean(dim=1).detach().float().cpu().numpy()
                                q_values_history.append(q_avg)
                            # Feature embeddings snapshot (–µ—Å–ª–∏ –µ—Å—Ç—å extractor)
                            cos_sim_mean = None
                            if hasattr(dqn_solver.model, 'get_feature_extractor'):
                                fe = dqn_solver.model.get_feature_extractor()
                                if fe is not None:
                                    try:
                                        z = fe(st)
                                        if isinstance(z, torch.Tensor):
                                            z_np = z.detach().float().cpu().numpy()
                                            # –ù–æ—Ä–º–∏—Ä—É–µ–º
                                            def _l2norm(x: np.ndarray) -> np.ndarray:
                                                n = np.linalg.norm(x, axis=1, keepdims=True) + 1e-8
                                                return x / n
                                            z_np = _l2norm(z_np)
                                            if probe_embeddings_baseline is None:
                                                probe_embeddings_baseline = z_np.copy()
                                                cos_sim_mean = 1.0
                                            else:
                                                base = _l2norm(probe_embeddings_baseline)
                                                # –ö–æ—Å–∏–Ω—É—Å–Ω–∞—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å –ø–æ –±–∞—Ç—á—É –∏ —Å—Ä–µ–¥–Ω–µ–µ
                                                cos = np.sum(z_np * base, axis=1)
                                                cos_sim_mean = float(np.mean(cos))
                                    except Exception:
                                        pass
                            if cos_sim_mean is not None:
                                drift_cosine_history.append(cos_sim_mean)
                                drift_snapshot_episodes.append(int(episode))
                except Exception:
                    pass
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —É–ª—É—á—à–µ–Ω–∏–µ —Å –±–æ–ª–µ–µ —É–º–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
                # –°—á–∏—Ç–∞–µ–º —É–ª—É—á—à–µ–Ω–∏–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ warmup
                is_improvement = (episode >= best_warmup_episodes) and (episode_winrate > best_winrate)
                if is_improvement:
                    best_winrate = episode_winrate
                    patience_counter = 0
                    episodes_since_best = 0
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å, –∞ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ ‚Äî –∏ replay buffer –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏
                    save_replay_on_improvement = getattr(cfg, 'save_replay_on_improvement', True)
                    if save_replay_on_improvement:
                        dqn_solver.save()
                        logger.info("[INFO] New best winrate: %.3f, saving model + replay buffer", best_winrate)
                    else:
                        dqn_solver.save_model()
                        logger.info("[INFO] New best winrate: %.3f, saving model", best_winrate)
                    # –î—É–±–ª–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –∫–∞–∫ best_model.pth –∏ —Ñ–∏–∫—Å–∏—Ä—É–µ–º —ç–ø–∏–∑–æ–¥
                    try:
                        import shutil as _sh
                        if os.path.exists(cfg.model_path):
                            _sh.copy2(cfg.model_path, os.path.join(run_dir, 'best_model.pth'))
                            best_episode_idx = int(episode)
                    except Exception:
                        pass
                else:
                    # –ú—è–≥–∫–∞—è –ª–æ–≥–∏–∫–∞ patience - —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —è–≤–Ω–æ–º —É—Ö—É–¥—à–µ–Ω–∏–∏
                    if episode >= min_episodes_before_stopping:
                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥ winrate
                        if len(episode_winrates) >= 30:  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 20 –¥–æ 30 –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                            recent_avg = np.mean(episode_winrates[-30:])  # –£–≤–µ–ª–∏—á–µ–Ω–æ –æ–∫–Ω–æ –∞–Ω–∞–ª–∏–∑–∞
                            older_avg = np.mean(episode_winrates[-60:-30]) if len(episode_winrates) >= 60 else recent_avg  # –£–≤–µ–ª–∏—á–µ–Ω–æ –æ–∫–Ω–æ
                            
                            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥ —É–ª—É—á—à–µ–Ω–∏—è, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º patience
                            if recent_avg > older_avg + recent_improvement_threshold:
                                patience_counter = max(0, patience_counter - 5)  # –£–º–µ–Ω—å—à–∞–µ–º patience —Å–∏–ª—å–Ω–µ–µ (–±—ã–ª–æ -3)
                            elif recent_avg > older_avg:
                                patience_counter = max(0, patience_counter - 2)  # –ù–µ–±–æ–ª—å—à–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ (–±—ã–ª–æ -1)
                            elif recent_avg < older_avg - 0.05:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–æ—Ä–æ–≥ —É—Ö—É–¥—à–µ–Ω–∏—è —Å 0.03 –¥–æ 0.05
                                patience_counter += 1
                            # –ï—Å–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ–±–æ–ª—å—à–∏–µ, –Ω–µ –º–µ–Ω—è–µ–º patience
                        else:
                            patience_counter += 0  # –ù–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º patience –≤ –Ω–∞—á–∞–ª–µ
                    else:
                        # –í –Ω–∞—á–∞–ª–µ –æ–±—É—á–µ–Ω–∏—è –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º patience
                        patience_counter = 0
                # Reduce-on-plateau: —Ç–æ–ª—å–∫–æ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                try:
                    episodes_since_best += 1
                except Exception:
                    episodes_since_best = lr_plateau_patience + 1
                is_retrain = bool(load_model_path) or bool(parent_run_id)
                allow_reduce = (not reduce_plateau_only_for_retrain) or is_retrain
                if allow_reduce and episodes_since_best >= lr_plateau_patience:
                    try:
                        # —Ç–µ–∫—É—â–µ–µ lr –∏–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
                        current_lr = None
                        for g in dqn_solver.optimizer.param_groups:
                            current_lr = g.get('lr', None)
                            break
                        if current_lr is None:
                            current_lr = float(getattr(cfg, 'lr', 1e-3))
                        new_lr = max(lr_min, float(current_lr) * 0.5)
                        if new_lr < current_lr:
                            for g in dqn_solver.optimizer.param_groups:
                                g['lr'] = new_lr
                            try:
                                cfg.lr = new_lr
                            except Exception:
                                pass
                            print(f"üîß Reduce-on-plateau: lr {current_lr:.6f} ‚Üí {new_lr:.6f}")
                        # –°–Ω–∏–∂–∞–µ–º epsilon –∫ eps_final –º—è–≥–∫–æ
                        try:
                            eps_final = float(getattr(cfg, 'eps_final', 0.01))
                            dqn_solver.epsilon = max(eps_final, dqn_solver.epsilon * 0.7)
                            print(f"üîß Reduce-on-plateau: epsilon ‚Üí {dqn_solver.epsilon:.4f}")
                        except Exception:
                            pass
                    except Exception:
                        pass
                    finally:
                        episodes_since_best = 0

            # --- –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ —ç–ø–∏–∑–æ–¥–∞ ---
            try:
                # –°—É–º–º–∞—Ä–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
                _ac2 = get_env_attr_safe(env, 'action_counts')
                if isinstance(_ac2, dict):
                    action_counts_total[0] = action_counts_total.get(0, 0) + int(_ac2.get(0, 0) or 0)
                    action_counts_total[1] = action_counts_total.get(1, 0) + int(_ac2.get(1, 0) or 0)
                    action_counts_total[2] = action_counts_total.get(2, 0) + int(_ac2.get(2, 0) or 0)
                # –ü–æ–ø—ã—Ç–∫–∏ –ø–æ–∫—É–ø–æ–∫ –∏ –ø—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–∞–∑–æ–≤
                buy_attempts_total += int(get_env_attr_safe(env, 'buy_attempts', 0) or 0)
                buy_rejected_vol_total += int(get_env_attr_safe(env, 'buy_rejected_vol', 0) or 0)
                buy_rejected_roi_total += int(get_env_attr_safe(env, 'buy_rejected_roi', 0) or 0)
                # –ë—ã–ª–∞ –ª–∏ —Å–¥–µ–ª–∫–∞ –≤ —ç–ø–∏–∑–æ–¥–µ
                new_trades_added = len(all_trades) - trades_before
                if new_trades_added > 0:
                    episodes_with_trade_count += 1
            except Exception:
                pass

            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            if episode % 10 == 0:
                avg_winrate = np.mean(episode_winrates[-10:]) if episode_winrates else 0
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—É –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                log_crypto = current_crypto
                
                logger.info(f"[INFO] Episode {episode}/{episodes} –¥–ª—è {log_crypto}, Avg Winrate: {avg_winrate:.3f}, Epsilon: {dqn_solver.epsilon:.4f}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ early stopping
                if episode >= min_episodes_before_stopping:
                    remaining_patience = patience_limit - patience_counter
                    print(f"  üìä Early stopping –¥–ª—è {log_crypto}: patience {patience_counter}/{patience_limit} (–æ—Å—Ç–∞–ª–æ—Å—å {remaining_patience})")
                    if patience_counter > patience_limit * 0.8:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–∏ –∫ –ª–∏–º–∏—Ç—É
                        print(f"  ‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: patience_counter –ø—Ä–∏–±–ª–∏–∂–∞–µ—Ç—Å—è –∫ –ª–∏–º–∏—Ç—É!")                    
                
                # –û—á–∏—â–∞–µ–º GPU –ø–∞–º—è—Ç—å –∫–∞–∂–¥—ã–µ 10 —ç–ø–∏–∑–æ–¥–æ–≤
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –±—É—Ñ–µ—Ä–∞
            save_frequency = getattr(cfg, 'save_frequency', 50)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∫–∞–∂–¥—ã–µ 50 —ç–ø–∏–∑–æ–¥–æ–≤
            save_only_on_improvement = getattr(cfg, 'save_only_on_improvement', False)
            buffer_save_frequency = getattr(cfg, 'buffer_save_frequency', max(200, save_frequency * 4))
            
            if not save_only_on_improvement and episode > 0 and episode % save_frequency == 0:
                dqn_solver.save_model()
                logger.info("[INFO] Periodic save model at episode %d", episode)
            
            if episode > 0 and episode % buffer_save_frequency == 0:
                dqn_solver.save()
                logger.info("[INFO] Periodic save model + replay buffer at episode %d", episode)
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è —Ç–∞–∫–∂–µ
                _save_training_results(
                    run_dir=run_dir,
                    dfs=dfs, # –ü–µ—Ä–µ–¥–∞–µ–º dfs
                    cfg=cfg,
                    training_name=training_name,
                    current_episode=episode,
                    total_episodes_planned=episodes,
                    all_trades=all_trades,
                    episode_winrates=episode_winrates,
                    best_winrate=best_winrate,
                    best_episode_idx=best_episode_idx,
                    action_counts_total=action_counts_total,
                    buy_attempts_total=buy_attempts_total,
                    buy_rejected_vol_total=buy_rejected_vol_total,
                    buy_rejected_roi_total=buy_rejected_roi_total,
                    episodes_with_trade_count=episodes_with_trade_count,
                    total_steps_processed=total_steps_processed,
                    episode_length=episode_length,
                    seed=seed,
                    dqn_solver=dqn_solver,
                    env=env,
                    is_multi_crypto=is_multi_crypto,
                    parent_run_id=parent_run_id,
                    root_id=root_id,
                    training_start_time=training_start_time,
                    current_total_training_time=time.time() - training_start_time,
                )
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–Ω–∞–ø—à–æ—Ç last_model.pth (–æ—Ç–¥–µ–ª—å–Ω–æ)
                try:
                    import shutil as _sh
                    if os.path.exists(cfg.model_path):
                        _sh.copy2(cfg.model_path, os.path.join(run_dir, 'last_model.pth'))
                except Exception:
                    pass
            
            # –£–ª—É—á—à–µ–Ω–Ω—ã–π Early stopping —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏
            if episode >= min_episodes_before_stopping:
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ª–∏—à–∫–æ–º —Ä–∞–Ω–Ω–µ–≥–æ stopping
                if episode < episodes // 2:  # –ù–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –≤ –ø–µ—Ä–≤–æ–π –ø–æ–ª–æ–≤–∏–Ω–µ –æ–±—É—á–µ–Ω–∏—è (–±—ã–ª–æ 1/3)
                    patience_counter = min(patience_counter, patience_limit // 4)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º patience —Å–∏–ª—å–Ω–µ–µ (–±—ã–ª–æ 1/3)
                elif episode < episodes * 3 // 4:  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞ –¥–æ 3/4 (–±—ã–ª–æ 1/2)
                    patience_counter = min(patience_counter, patience_limit // 2)
                
                # –û—Å–Ω–æ–≤–Ω–æ–π –∫—Ä–∏—Ç–µ—Ä–∏–π - patience
                if patience_counter >= patience_limit:
                    logger.info(f"[INFO] Early stopping triggered for {training_name} after {episode} episodes (patience limit reached)")
                    print(f"  ‚ö†Ô∏è Early stopping: –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç patience ({patience_limit})")
                    print(f"  üîç –û—Ç–ª–∞–¥–∫–∞: patience_counter={patience_counter}, patience_limit={patience_limit}")
                    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±–Ω–æ–≤–ª—è–µ–º actual_episodes –ø—Ä–∏ early stopping
                    actual_episodes = episode
                    break
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π - –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ (–£–õ–£–ß–®–ï–ù–û)
                if len(episode_winrates) >= 400 and episode >= episodes * 4 // 5:  # –£–≤–µ–ª–∏—á–∏–ª —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è: 400 —ç–ø–∏–∑–æ–¥–æ–≤ –∏ –ø–æ—Å–ª–µ–¥–Ω—è—è 1/5
                    recent_winrate = np.mean(episode_winrates[-80:])   # –£–≤–µ–ª–∏—á–∏–ª –æ–∫–Ω–æ –∞–Ω–∞–ª–∏–∑–∞ —Å 50 –¥–æ 80
                    mid_winrate = np.mean(episode_winrates[-160:-80])  # –£–≤–µ–ª–∏—á–∏–ª –æ–∫–Ω–æ —Å 100:-50 –¥–æ 160:-80
                    early_winrate = np.mean(episode_winrates[-240:-160])  # –£–≤–µ–ª–∏—á–∏–ª –æ–∫–Ω–æ —Å 150:-100 –¥–æ 240:-160
                    
                    # –ï—Å–ª–∏ winrate —Å—Ç–∞–±–∏–ª—å–Ω–æ –ø–∞–¥–∞–µ—Ç –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ 240 —ç–ø–∏–∑–æ–¥–æ–≤ (–±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–µ —É—Å–ª–æ–≤–∏–µ)
                    if (recent_winrate < mid_winrate < early_winrate and 
                        mid_winrate - recent_winrate > trend_threshold * 2.5 and  # –£–≤–µ–ª–∏—á–∏–ª –ø–æ—Ä–æ–≥ —Å 2.0 –¥–æ 2.5
                        early_winrate - mid_winrate > trend_threshold * 2.5):
                        
                        logger.info(f"[INFO] Early stopping triggered for {training_name} after {episode} episodes (declining trend)")
                        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±–Ω–æ–≤–ª—è–µ–º actual_episodes –ø—Ä–∏ early stopping
                        actual_episodes = episode
                        break
                
                                # –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π - –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Å—Ç–∞–±–∏–ª—å–Ω–∞, –¥–∞–µ–º –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏
                if patience_counter >= long_term_patience:
                    logger.info(f"[INFO] Early stopping triggered for {training_name} after {episode} episodes (long-term patience)")
                    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±–Ω–æ–≤–ª—è–µ–º actual_episodes –ø—Ä–∏ early stopping
                    actual_episodes = episode
                    break

        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        training_end_time = time.time()
        total_training_time = training_end_time - training_start_time
        
        print("\n" + "="*60)
        print(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–£–ß–ï–ù–ò–Ø –¥–ª—è {training_name}")
        print("="*60)
        
        print(f"‚è±Ô∏è –í–†–ï–ú–Ø –û–ë–£–ß–ï–ù–ò–Ø:")
        print(f"  ‚Ä¢ –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_training_time:.2f} —Å–µ–∫—É–Ω–¥ ({total_training_time/60:.1f} –º–∏–Ω—É—Ç)")
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ZeroDivisionError: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ episode > 0 –ø–µ—Ä–µ–¥ –¥–µ–ª–µ–Ω–∏–µ–º
        if episode > 0:
            print(f"  ‚Ä¢ –í—Ä–µ–º—è –Ω–∞ —ç–ø–∏–∑–æ–¥: {total_training_time/episode:.2f} —Å–µ–∫—É–Ω–¥")
            print(f"  ‚Ä¢ –≠–ø–∏–∑–æ–¥–æ–≤ –≤ –º–∏–Ω—É—Ç—É: {episode/(total_training_time/60):.1f}")
        else:
            print(f"  ‚Ä¢ –í—Ä–µ–º—è –Ω–∞ —ç–ø–∏–∑–æ–¥: –ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ (—ç–ø–∏–∑–æ–¥ = 0)")
            print(f"  ‚Ä¢ –≠–ø–∏–∑–æ–¥–æ–≤ –≤ –º–∏–Ω—É—Ç—É: –ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ (—ç–ø–∏–∑–æ–¥ = 0)")
        
        stats_all = dqn_solver.print_trade_stats(all_trades)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if all_trades:
            total_profit = sum([t.get('roi', 0) for t in all_trades if t.get('roi', 0) > 0])
            total_loss = abs(sum([t.get('roi', 0) for t in all_trades if t.get('roi', 0) < 0]))
            avg_duration = np.mean([t.get('duration', 0) for t in all_trades])
            
            print(f"\nüí∞ –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(f"  ‚Ä¢ –û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: {total_profit:.4f}")
            print(f"  ‚Ä¢ –û–±—â–∏–π —É–±—ã—Ç–æ–∫: {total_loss:.4f}")
            print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–¥–µ–ª–∫–∏: {avg_duration:.1f} –º–∏–Ω—É—Ç")
            print(f"  ‚Ä¢ –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ —ç–ø–∏–∑–æ–¥—ã: {episodes}")
            print(f"  ‚Ä¢ –†–µ–∞–ª—å–Ω—ã–µ —ç–ø–∏–∑–æ–¥—ã: {episode}")
            if episode < episodes:
                print(f"  ‚Ä¢ Early Stopping: –°—Ä–∞–±–æ—Ç–∞–ª –Ω–∞ {episode} —ç–ø–∏–∑–æ–¥–µ")
            else:
                print(f"  ‚Ä¢ Early Stopping: –ù–µ —Å—Ä–∞–±–æ—Ç–∞–ª")
            print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π winrate: {np.mean(episode_winrates):.3f}")
        else:
            print(f"\n‚ö†Ô∏è –ù–µ—Ç —Å–¥–µ–ª–æ–∫ –∑–∞ –≤—Å–µ {episodes} —ç–ø–∏–∑–æ–¥–æ–≤!")

        # –ü–µ—á–∞—Ç—å –ø—Ä–∏—á–∏–Ω –ø—Ä–æ–¥–∞–∂ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        try:
            sell_types_total = get_env_attr_safe(env, 'cumulative_sell_types', {})
            if isinstance(sell_types_total, dict) and sell_types_total:
                print("\nüßæ –ü—Ä–∏—á–∏–Ω—ã –ø—Ä–æ–¥–∞–∂ (–∞–≥—Ä–µ–≥–∞—Ç):")
                for k, v in sell_types_total.items():
                    print(f"  ‚Ä¢ {k}: {int(v)}")
        except Exception:
            pass
        
        if hasattr(cfg, 'use_wandb') and cfg.use_wandb:
            wandb.log({**stats_all, "scope": "cumulative", "episode": episodes})
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ replay buffer
        print("\nüíæ –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ replay buffer")
        # –ï–¥–∏–Ω—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ env –≤ —á–µ–∫–ø–æ–π–Ω—Ç
        norm_stats = None
        try:
            export_stats = get_env_attr_safe(env, 'export_normalization_stats')
            if callable(export_stats):
                norm_stats = export_stats()
        except Exception:
            norm_stats = None
        dqn_solver.save(normalization_stats=norm_stats)
        # –ü–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤ ‚Äî —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º encoder_manifest.json, encoder_index.json –∏ current.json (–∞—Ç–æ–º–∞—Ä–Ω–æ)
        try:
            enc_path = getattr(cfg, 'encoder_path', None)
            enc_sha = _sha256_of_file(enc_path) if enc_path and os.path.exists(enc_path) else None
            enc_size = os.path.getsize(enc_path) if enc_path and os.path.exists(enc_path) else None
            # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ü–µ–Ω–∏—Ç—å —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —ç–Ω–∫–æ–¥–µ—Ä–∞ (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥)
            try:
                num_params = None
                if hasattr(dqn_solver.model, 'get_feature_extractor'):
                    _fe = dqn_solver.model.get_feature_extractor()
                    if _fe is not None:
                        num_params = sum(p.numel() for p in _fe.parameters())
            except Exception:
                num_params = None

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Å–≤–æ–¥–∫–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞
            try:
                avg_winrate_val = float(np.mean(episode_winrates)) if episode_winrates else None
            except Exception:
                avg_winrate_val = None
            try:
                frames_info = {}
                if isinstance(dfs, dict):
                    for _k in ('df_5min','df_15min','df_1h'):
                        _dfx = dfs.get(_k)
                        frames_info[_k] = {
                            'rows': int(len(_dfx)) if _dfx is not None else None
                        }
                    # –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –¥–ª—è 5m
                    _df5 = dfs.get('df_5min')
                    if _df5 is not None and len(_df5) > 0:
                        try:
                            _start_ts = _df5.index.min()
                            _end_ts = _df5.index.max()
                            frames_info['df_5min']['date_range'] = {
                                'start': str(_start_ts),
                                'end': str(_end_ts),
                            }
                        except Exception:
                            pass
            except Exception:
                frames_info = {}

            # --- –ò—Ç–æ–≥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è freeze‚Äë—Ä–µ—à–µ–Ω–∏—è ---
            training_indicators = None
            try:
                # 1) Q‚Äëloss stability (EMA/STD/–Ω–∞–∫–ª–æ–Ω –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —á–∞—Å—Ç–∏)
                q_loss_metrics = None
                if q_loss_history:
                    arr = np.array(q_loss_history, dtype=np.float32)
                    # EMA (alpha=0.1)
                    ema = float(arr[0])
                    alpha = 0.1
                    for v in arr[1:]:
                        ema = alpha * float(v) + (1.0 - alpha) * ema
                    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20% —Ç–æ—á–µ–∫ –¥–ª—è STD –∏ slope
                    w = max(10, int(len(arr) * 0.2))
                    tail = arr[-w:]
                    std_last = float(np.std(tail)) if tail.size > 1 else 0.0
                    # –õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ (slope) –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –æ–∫–Ω—É
                    x = np.arange(tail.size, dtype=np.float32)
                    slope = float(np.polyfit(x, tail, deg=1)[0]) if tail.size >= 2 else 0.0
                    thr_std = float(getattr(cfg, 'q_loss_std_threshold', 2e-3))
                    thr_slope = float(getattr(cfg, 'q_loss_slope_threshold', 1e-4))
                    loss_stable = (abs(slope) < thr_slope) and (std_last < thr_std)
                    q_loss_metrics = {
                        'ema': ema,
                        'std_last_20pct': std_last,
                        'slope_last_20pct': slope,
                        'thresholds': { 'std': thr_std, 'abs_slope': thr_slope },
                        'stable': bool(loss_stable),
                        'count': int(len(arr)),
                    }

                # 2) Feature drift (–∫–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)
                drift_metrics = None
                if drift_cosine_history:
                    mean_cos_last = float(drift_cosine_history[-1])
                    # –°—á–∏—Ç–∞–µ–º –º–æ–º–µ–Ω—Ç —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏: –ø–µ—Ä–≤—ã–π –∏–Ω–¥–µ–∫—Å, —Å –∫–æ—Ç–æ—Ä–æ–≥–æ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è >= 0.99 –ø–æ–¥—Ä—è–¥ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 3 —Å–Ω—ç–ø—à–æ—Ç–∞—Ö
                    stable_since = None
                    if len(drift_cosine_history) >= 3:
                        for i in range(len(drift_cosine_history) - 3, -1, -1):
                            if min(drift_cosine_history[i: i+3]) >= 0.99:
                                stable_since = int(drift_snapshot_episodes[i]) if i < len(drift_snapshot_episodes) else None
                                break
                    drift_metrics = {
                        'mean_cos_sim_last': mean_cos_last,
                        'stable_since_episode': stable_since,
                        'probe_size': int(len(probe_states)),
                        'interval_episodes': probe_interval_episodes,
                        'threshold': 0.99,
                    }

                # 3) Q‚Äëvalue stability (–∫–æ—ç—Ñ—Ñ. –≤–∞—Ä–∏–∞—Ü–∏–∏ –∏ –º–∞–∫—Å. –æ—Å—Ü–∏–ª–ª—è—Ü–∏—è –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 10%)
                q_value_metrics = None
                if q_values_history:
                    H = len(q_values_history)
                    m = max(2, int(np.ceil(H * 0.1)))
                    window = q_values_history[-m:]
                    # –ú–∞—Ç—Ä–∏—Ü–∞ [m, N]
                    mat = np.stack(window, axis=0)
                    mean_per_state = np.mean(mat, axis=0)
                    std_per_state = np.std(mat, axis=0)
                    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ (—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å)
                    cv = std_per_state / (np.abs(mean_per_state) + 1e-8)
                    mean_cv_last = float(np.mean(cv))
                    # –ú–∞–∫—Å. –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –æ—Å—Ü–∏–ª–ª—è—Ü–∏—è
                    range_per_state = (np.max(mat, axis=0) - np.min(mat, axis=0)) / (np.abs(mean_per_state) + 1e-8)
                    max_osc_last = float(np.max(range_per_state))
                    thr_cv = float(getattr(cfg, 'q_value_cv_threshold', 0.10))
                    thr_osc = float(getattr(cfg, 'q_value_osc_threshold', 0.10))
                    q_value_metrics = {
                        'mean_cv_last': mean_cv_last,
                        'max_oscillation_last_10pct': max_osc_last,
                        'thresholds': { 'cv': thr_cv, 'osc': thr_osc },
                    }

                # –ò—Ç–æ–≥–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è freeze
                freeze_rec = None
                try:
                    cond_loss = (q_loss_metrics or {}).get('stable', False)
                    cond_drift = (drift_metrics or {}).get('mean_cos_sim_last', 0.0) >= 0.99
                    cond_q = ((q_value_metrics or {}).get('max_oscillation_last_10pct', 1.0) <= (q_value_metrics or {}).get('thresholds', {}).get('osc', 0.10))
                    should_freeze = bool(cond_loss and cond_drift and cond_q)
                    reasons = []
                    if cond_loss: reasons.append('loss_stable')
                    if cond_drift: reasons.append('drift_stopped')
                    if cond_q: reasons.append('q_values_stable')
                    freeze_rec = {
                        'should_freeze': should_freeze,
                        'reasons': reasons,
                        'evaluated_at_episode': int(actual_episodes) if isinstance(actual_episodes, (int, float)) else None,
                    }
                except Exception:
                    freeze_rec = None

                training_indicators = {
                    'q_loss_stability': q_loss_metrics,
                    'feature_drift': drift_metrics,
                    'q_value_stability': q_value_metrics,
                    'freeze_recommendation': freeze_rec,
                }
            except Exception:
                training_indicators = None

            # –°—É–º–º–∏—Ä—É–µ–º –æ–ø—ã—Ç —Å –ø—Ä–æ—à–ª–æ–≥–æ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞ –±–∞–∑–æ–≤–æ–≥–æ —ç–Ω–∫–æ–¥–µ—Ä–∞ (–µ—Å–ª–∏ –¥–æ–æ–±—É—á–∞–µ–º)
            prev_episodes_completed = None
            prev_time_sec = None
            prev_total_steps = None
            try:
                if base_encoder_path and os.path.exists(base_encoder_path):
                    _prev_manifest_path = os.path.join(os.path.dirname(base_encoder_path), 'encoder_manifest.json')
                    _prev = _safe_read_json(_prev_manifest_path) or {}
                    _tr = _prev.get('training') or {}
                    # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º cumulative, –∏–Ω–∞—á–µ –æ–±—ã—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    prev_episodes_completed = _tr.get('cumulative_episodes_completed')
                    if prev_episodes_completed is None:
                        prev_episodes_completed = _tr.get('episodes_completed')
                    prev_time_sec = _tr.get('cumulative_time_sec')
                    if prev_time_sec is None:
                        prev_time_sec = _tr.get('time_sec')
                    prev_total_steps = _tr.get('cumulative_total_steps')
                    if prev_total_steps is None:
                        prev_total_steps = _tr.get('total_steps')
            except Exception:
                prev_episodes_completed = None
                prev_time_sec = None
                prev_total_steps = None

            manifest_data = {
                'manifest_version': 1,
                'run_id': this_run_id,
                'training_run_dir': run_dir,
                'freeze_encoder': bool(getattr(cfg, 'freeze_encoder', False)),
                'encoder_type': getattr(cfg, 'encoder_type', None),
                'version': int(getattr(cfg, 'encoder_version', 0) or 0),
                'created_at': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
                'symbol': symbol_dir_name,
                'encoder': {
                    'path_abs': os.path.abspath(enc_path) if enc_path else None,
                    'path_rel': enc_path,
                    'sha256': enc_sha,
                    'size_bytes': enc_size,
                    'num_parameters': num_params,
                },
                'model': {
                    'path_abs': os.path.abspath(cfg.model_path) if getattr(cfg, 'model_path', None) else None,
                    'path_rel': getattr(cfg, 'model_path', None),
                },
                'parent_run_id': parent_run_id,
                'root_id': this_root_id,
                'base_encoder': {
                    'selected_id': selected_encoder_id,
                    'path': base_encoder_path,
                    'root': base_encoder_root,
                },
                'seed': int(seed) if isinstance(seed, int) else None,
                'training': {
                    'episodes_planned': int(episodes) if isinstance(episodes, (int, float)) else None,
                    'episodes_completed': int(actual_episodes) if isinstance(actual_episodes, (int, float)) else None,
                    'episode_length': int(episode_length) if isinstance(episode_length, (int, float)) else None,
                    'total_steps': int(total_steps_processed) if isinstance(total_steps_processed, (int, float)) else None,
                    'time_sec': float(total_training_time) if isinstance(total_training_time, (int, float)) else None,
                    'start_utc': datetime.utcfromtimestamp(training_start_time).strftime('%Y-%m-%dT%H:%M:%SZ') if isinstance(training_start_time, (int, float)) else None,
                    'end_utc': datetime.utcfromtimestamp(training_start_time + total_training_time).strftime('%Y-%m-%dT%H:%M:%SZ') if isinstance(training_start_time, (int, float)) and isinstance(total_training_time, (int, float)) else None,
                    'prev_episodes_completed': int(prev_episodes_completed) if isinstance(prev_episodes_completed, (int, float)) else None,
                    'prev_time_sec': float(prev_time_sec) if isinstance(prev_time_sec, (int, float)) else None,
                    'prev_total_steps': int(prev_total_steps) if isinstance(prev_total_steps, (int, float)) else None,
                    'cumulative_episodes_completed': (
                        int(prev_episodes_completed) + int(actual_episodes)
                    ) if isinstance(prev_episodes_completed, (int, float)) and isinstance(actual_episodes, (int, float)) else int(actual_episodes) if isinstance(actual_episodes, (int, float)) else None,
                    'cumulative_time_sec': (
                        float(prev_time_sec) + float(total_training_time)
                    ) if isinstance(prev_time_sec, (int, float)) and isinstance(total_training_time, (int, float)) else float(total_training_time) if isinstance(total_training_time, (int, float)) else None,
                    'cumulative_total_steps': (
                        int(prev_total_steps) + int(total_steps_processed)
                    ) if isinstance(prev_total_steps, (int, float)) and isinstance(total_steps_processed, (int, float)) else int(total_steps_processed) if isinstance(total_steps_processed, (int, float)) else None,
                },
                'performance': {
                    'avg_winrate': avg_winrate_val,
                    'best_winrate': float(best_winrate) if isinstance(best_winrate, (int, float)) else None,
                    'best_episode': int(best_episode_idx) if isinstance(best_episode_idx, (int, float)) else None,
                },
                'data': {
                    'frames': frames_info,
                },
                # –ú–µ—Å—Ç–∞ –¥–ª—è –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ–± –æ–±—É—á–µ–Ω–∏–∏/–¥–∞—Ç–∞—Ö/–º–µ—Ç—Ä–∏–∫–∞—Ö –º–æ–∂–Ω–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∑–∂–µ
            }
            # –í–∫–ª–∞–¥—ã–≤–∞–µ–º training_indicators –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏
            if training_indicators is not None:
                manifest_data['training_indicators'] = training_indicators
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º encoder_manifest.json –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —Å–æ–∑–¥–∞–≤–∞–ª–∏ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é
            if create_new_encoder:
                enc_manifest_path = os.path.join(os.path.dirname(enc_path) if enc_path else run_dir, 'encoder_manifest.json')
                _atomic_write_json(enc_manifest_path, manifest_data)

                # –û–±–Ω–æ–≤–ª—è–µ–º encoder_index.json —Å–ø–∏—Å–∫–æ–º –≤–µ—Ä—Å–∏–π
                encoder_base = os.path.join("result", "dqn", symbol_dir_name, "encoder")
                encoder_type = getattr(cfg, 'encoder_type', 'unfrozen') or 'unfrozen'
                encoder_type_dir = os.path.join(encoder_base, encoder_type)
                index_path = os.path.join(encoder_type_dir, 'encoder_index.json')
                index_data = _safe_read_json(index_path) or []
                index_entry = {
                    'version': int(getattr(cfg, 'encoder_version', 0) or 0),
                    'run_id': this_run_id,
                    'date': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
                    'encoder_type': encoder_type,
                    'encoder_path': enc_path,
                    'model_path': getattr(cfg, 'model_path', None),
                    'symbol': symbol_dir_name,
                    'sha256': enc_sha,
                    'size_bytes': enc_size,
                }
                try:
                    index_entry['episodes_completed'] = int(actual_episodes) if isinstance(actual_episodes, (int, float)) else None
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ñ–∏–∫—Å–∏—Ä—É–µ–º cumulative (–µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ–ø—ã—Ç)
                    cum_eps = (
                        int(prev_episodes_completed) + int(actual_episodes)
                    ) if isinstance(prev_episodes_completed, (int, float)) and isinstance(actual_episodes, (int, float)) else int(actual_episodes) if isinstance(actual_episodes, (int, float)) else None
                    index_entry['cumulative_episodes_completed'] = cum_eps
                except Exception:
                    pass
                index_data.append(index_entry)
                _atomic_write_json(index_path, index_data)

                # –£–∫–∞–∑–∞—Ç–µ–ª—å –Ω–∞ —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é
                current_path = os.path.join(encoder_type_dir, 'current.json')
                _atomic_write_json(current_path, {'version': f"v{int(getattr(cfg, 'encoder_version', 0) or 0)}", 'sha256': enc_sha})
        except Exception:
            pass
        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–Ω–∫–æ–¥–µ—Ä–∞ (fallback): –µ—Å–ª–∏ —Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî —Å–æ—Ö—Ä–∞–Ω–∏–º –º–æ–¥–µ–ª—å (–≤–∫–ª—é—á–∞—è encoder_only)
        try:
            enc_check = getattr(cfg, 'encoder_path', None)
            if enc_check and not os.path.exists(enc_check):
                dqn_solver.save_model()
        except Exception:
            pass
        # –§–∏–Ω–∞–ª—å–Ω—ã–π last_model —Å–Ω–∞–ø—à–æ—Ç
        try:
            import shutil as _sh
            if os.path.exists(cfg.model_path):
                _sh.copy2(cfg.model_path, os.path.join(run_dir, 'last_model.pth'))
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —É–¥–æ–±–Ω—É—é –∫–æ–ø–∏—é —ç–Ω–∫–æ–¥–µ—Ä–∞ –≤ run_dir (–µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
            try:
                enc_src = getattr(cfg, 'encoder_path', None)
                if enc_src and os.path.exists(enc_src):
                    _sh.copy2(enc_src, os.path.join(run_dir, 'last_encoder.pth'))
            except Exception:
                pass
        except Exception:
            pass
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        _save_training_results(
            run_dir=run_dir,
            dfs=dfs, # –ü–µ—Ä–µ–¥–∞–µ–º dfs
            cfg=cfg,
            training_name=training_name,
            current_episode=actual_episodes, # –ò—Å–ø–æ–ª—å–∑—É–µ–º actual_episodes –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            total_episodes_planned=episodes,
            all_trades=all_trades,
            episode_winrates=episode_winrates,
            best_winrate=best_winrate,
            best_episode_idx=best_episode_idx,
            action_counts_total=action_counts_total,
            buy_attempts_total=buy_attempts_total,
            buy_rejected_vol_total=buy_rejected_vol_total,
            buy_rejected_roi_total=buy_rejected_roi_total,
            episodes_with_trade_count=episodes_with_trade_count,
            total_steps_processed=total_steps_processed,
            episode_length=episode_length,
            seed=seed,
            dqn_solver=dqn_solver,
            env=env,
            is_multi_crypto=is_multi_crypto,
            parent_run_id=parent_run_id,
            root_id=root_id,
            training_start_time=training_start_time,
            current_total_training_time=total_training_time, # –ò—Å–ø–æ–ª—å–∑—É–µ–º final total_training_time
        )

        # –î–æ–±–∞–≤–∏–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±–æ—Ä–µ —ç–Ω–∫–æ–¥–µ—Ä–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π JSON –≤ run_dir
        try:
            selection = {
                'selected_id': selected_encoder_id,
                'train_encoder': bool(train_encoder_flag),
                'mode': 'unfrozen' if train_encoder_flag else 'frozen',
                'base_encoder_path': base_encoder_path,
                'created_new_version': bool(create_new_encoder),
                'new_version': f"v{created_encoder_version}" if create_new_encoder else None,
                'final_encoder_path': getattr(cfg, 'encoder_path', None),
            }
            _atomic_write_json(os.path.join(run_dir, 'encoder_selection.json'), selection)
        except Exception:
            pass

        # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–¥–ª–µ–Ω–∏–π (–µ—Å–ª–∏ –æ–±—ë—Ä—Ç–∫–∞ –∞–∫—Ç–∏–≤–Ω–∞)
        try:
            if hasattr(env, 'episode_extensions_total'):
                print(f"  ‚Ä¢ –ü—Ä–æ–¥–ª–µ–Ω–∏—è —ç–ø–∏–∑–æ–¥–æ–≤: {int(env.episode_extensions_total)} —Ä–∞–∑ (+{int(env.episode_extension_steps_total)} —à–∞–≥–æ–≤)")
        except Exception:
            pass

        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤
        if len(episode_winrates) > 10:
            recent_winrate = np.mean(episode_winrates[-10:])
            overall_winrate = np.mean(episode_winrates)
            print(f"üìà Winrate —Ç—Ä–µ–Ω–¥: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —ç–ø–∏–∑–æ–¥–æ–≤: {recent_winrate:.3f}, –æ–±—â–∏–π: {overall_winrate:.3f}")
            
            if recent_winrate > overall_winrate:
                print("‚úÖ –ú–æ–¥–µ–ª—å —É–ª—É—á—à–∞–µ—Ç—Å—è!")
            else:
                print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è")
        
        return "–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ"    
    finally:
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º wandb
        if wandb_run is not None:
            wandb_run.finish()
