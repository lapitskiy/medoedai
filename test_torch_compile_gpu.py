#!/usr/bin/env python3
"""
üß™ –¢–µ—Å—Ç torch.compile –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ GPU
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º
"""

import torch
import sys

def test_torch_compile_gpu():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç torch.compile –Ω–∞ —Ç–µ–∫—É—â–µ–º GPU"""
    print("üß™ –¢–ï–°–¢ TORCH.COMPILE –î–õ–Ø GPU")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å PyTorch
    print(f"üì¶ PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    print(f"üîß torch.compile –¥–æ—Å—Ç—É–ø–µ–Ω: {hasattr(torch, 'compile')}")
    
    if not hasattr(torch, 'compile'):
        print("‚ùå torch.compile –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏ PyTorch")
        print("üí° –û–±–Ω–æ–≤–∏—Ç–µ –¥–æ PyTorch 2.0+")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º CUDA
    print(f"üöÄ CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.cuda.is_available()}")
    
    if not torch.cuda.is_available():
        print("‚ÑπÔ∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, torch.compile –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ CPU —Ä–µ–∂–∏–º–µ")
        return test_torch_compile_cpu()
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
    device_count = torch.cuda.device_count()
    current_device = torch.cuda.current_device()
    device_name = torch.cuda.get_device_name(current_device)
    
    print(f"üéØ GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {device_count}")
    print(f"üéØ –¢–µ–∫—É—â–∏–π GPU: {device_name}")
    print(f"üéØ GPU –∏–Ω–¥–µ–∫—Å: {current_device}")
    
    # CUDA Capability
    device_capability = torch.cuda.get_device_capability()
    print(f"üîç CUDA Capability: {device_capability[0]}.{device_capability[1]}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ä–µ–∂–∏–º—ã
    if device_capability[0] >= 8:  # Ampere+ (A100, H100, RTX 4090, etc.)
        supported_modes = ['max-autotune', 'default', 'reduce-overhead']
        recommended_mode = 'max-autotune'
        print("‚úÖ –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π GPU (Ampere+), –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ —Ä–µ–∂–∏–º—ã")
    elif device_capability[0] >= 7:  # Volta+ (V100, RTX 2080, etc.)
        supported_modes = ['max-autotune', 'default', 'reduce-overhead']
        recommended_mode = 'max-autotune'
        print("‚úÖ –•–æ—Ä–æ—à–∏–π GPU (Volta+), –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Ä–µ–∂–∏–º–æ–≤")
    elif device_capability[0] >= 6:  # Pascal (P100, GTX 1080, etc.)
        supported_modes = ['default', 'reduce-overhead']
        recommended_mode = 'default'
        print("‚ö†Ô∏è –°—Ç–∞—Ä—ã–π GPU (Pascal), –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞")
    else:  # Maxwell –∏ —Å—Ç–∞—Ä—à–µ
        supported_modes = ['default']
        recommended_mode = 'default'
        print("‚ùå –û—á–µ–Ω—å —Å—Ç–∞—Ä—ã–π GPU, –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞")
    
    print(f"üéØ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ä–µ–∂–∏–º—ã: {supported_modes}")
    print(f"üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–µ–∂–∏–º: {recommended_mode}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º torch.compile
    print(f"\nüöÄ –¢–µ—Å—Ç–∏—Ä—É—é torch.compile —Å —Ä–µ–∂–∏–º–æ–º '{recommended_mode}'...")
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞
        model = torch.nn.Sequential(
            torch.nn.Linear(10, 64),
            torch.nn.ReLU(),
            torch.nn.Linear(64, 32),
            torch.nn.ReLU(),
            torch.nn.Linear(32, 1)
        ).to('cuda')
        
        # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
        compiled_model = torch.compile(model, mode=recommended_mode)
        print("‚úÖ torch.compile —É—Å–ø–µ—à–µ–Ω!")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        print("\nüìä –¢–µ—Å—Ç–∏—Ä—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å...")
        
        # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        x = torch.randn(1000, 10, device='cuda')
        
        # –¢–µ–ø–ª—ã–π –∑–∞–ø—É—Å–∫
        for _ in range(5):
            _ = compiled_model(x)
        
        torch.cuda.synchronize()
        
        # –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏
        import time
        start_time = time.time()
        
        for _ in range(100):
            _ = compiled_model(x)
        
        torch.cuda.synchronize()
        end_time = time.time()
        
        compiled_time = end_time - start_time
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –æ–±—ã—á–Ω–æ–π –º–æ–¥–µ–ª—å—é
        start_time = time.time()
        
        for _ in range(100):
            _ = model(x)
        
        torch.cuda.synchronize()
        end_time = time.time()
        
        normal_time = end_time - start_time
        
        speedup = normal_time / compiled_time
        print(f"‚ö° –û–±—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å: {normal_time:.4f}—Å")
        print(f"üöÄ –°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {compiled_time:.4f}—Å")
        print(f"üéØ –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.2f}x")
        
        if speedup > 1.1:
            print("‚úÖ torch.compile –¥–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ!")
        elif speedup > 0.9:
            print("‚ö†Ô∏è torch.compile —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ —É—Å–∫–æ—Ä–µ–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ")
        else:
            print("‚ùå torch.compile –∑–∞–º–µ–¥–ª—è–µ—Ç —Ä–∞–±–æ—Ç—É")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ torch.compile: {e}")
        
        # –ü—Ä–æ–±—É–µ–º fallback —Ä–µ–∂–∏–º
        if recommended_mode != 'default':
            print(f"\nüîÑ –ü—Ä–æ–±—É—é fallback —Ä–µ–∂–∏–º 'default'...")
            try:
                compiled_model = torch.compile(model, mode='default')
                print("‚úÖ torch.compile —Å —Ä–µ–∂–∏–º–æ–º 'default' —É—Å–ø–µ—à–µ–Ω!")
                return True
            except Exception as e2:
                print(f"‚ùå Fallback —Ä–µ–∂–∏–º —Ç–æ–∂–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e2}")
        
        return False

def test_torch_compile_cpu():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç torch.compile –Ω–∞ CPU"""
    print("\nüñ•Ô∏è –¢–µ—Å—Ç–∏—Ä—É—é torch.compile –Ω–∞ CPU...")
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞
        model = torch.nn.Sequential(
            torch.nn.Linear(10, 64),
            torch.nn.ReLU(),
            torch.nn.Linear(64, 32),
            torch.nn.ReLU(),
            torch.nn.Linear(32, 1)
        )
        
        # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
        compiled_model = torch.compile(model, mode='default')
        print("‚úÖ torch.compile –Ω–∞ CPU —É—Å–ø–µ—à–µ–Ω!")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        print("\nüìä –¢–µ—Å—Ç–∏—Ä—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ CPU...")
        
        # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        x = torch.randn(1000, 10)
        
        # –¢–µ–ø–ª—ã–π –∑–∞–ø—É—Å–∫
        for _ in range(5):
            _ = compiled_model(x)
        
        # –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏
        import time
        start_time = time.time()
        
        for _ in range(100):
            _ = compiled_model(x)
        
        end_time = time.time()
        compiled_time = end_time - start_time
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –æ–±—ã—á–Ω–æ–π –º–æ–¥–µ–ª—å—é
        start_time = time.time()
        
        for _ in range(100):
            _ = model(x)
        
        end_time = time.time()
        normal_time = end_time - start_time
        
        speedup = normal_time / compiled_time
        print(f"‚ö° –û–±—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å: {normal_time:.4f}—Å")
        print(f"üöÄ –°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {compiled_time:.4f}—Å")
        print(f"üéØ –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.2f}x")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ torch.compile –Ω–∞ CPU: {e}")
        return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï TORCH.COMPILE")
    print("=" * 50)
    
    success = test_torch_compile_gpu()
    
    if success:
        print("\nüéâ torch.compile —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
        print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        print("  ‚Ä¢ –î–ª—è –æ–±—É—á–µ–Ω–∏—è: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ torch.compile")
        print("  ‚Ä¢ –î–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: torch.compile –º–æ–∂–µ—Ç –¥–∞—Ç—å —É—Å–∫–æ—Ä–µ–Ω–∏–µ")
        print("  ‚Ä¢ –ü—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö: –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–µ–∂–∏–º 'default'")
    else:
        print("\n‚ùå torch.compile –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print("\nüí° –†–ï–®–ï–ù–ò–Ø:")
        print("  ‚Ä¢ –û—Ç–∫–ª—é—á–∏—Ç–µ torch.compile –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        print("  ‚Ä¢ –û–±–Ω–æ–≤–∏—Ç–µ PyTorch –¥–æ –≤–µ—Ä—Å–∏–∏ 2.0+")
        print("  ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å GPU")
    
    print("\n" + "=" * 50)

if __name__ == "__main__":
    main()
