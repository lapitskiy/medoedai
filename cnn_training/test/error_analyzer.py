#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—à–∏–±–æ–∫ CNN –º–æ–¥–µ–ª–∏
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –Ω–∞ –∫–∞–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from cnn_training.model_validator import CNNModelValidator
import numpy as np
import json
from datetime import datetime

class CNNErrorAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫ CNN –º–æ–¥–µ–ª–∏"""
    
    def __init__(self):
        self.validator = CNNModelValidator()
    
    def analyze_single_symbol(self, model_path: str, symbol: str) -> dict:
        """–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –Ω–∞ –æ–¥–Ω–æ–º —Å–∏–º–≤–æ–ª–µ"""
        print(f"üîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –¥–ª—è {symbol}...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model = self.validator._load_model(model_path)
        if model is None:
            return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å"}
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å–∏–º–≤–æ–ª (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É–±–ª–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ validate_cnn_model)
        from cnn_training.model_validator import validate_cnn_model
        results = validate_cnn_model(
            model_path=model_path,
            test_symbols=[symbol],
            test_period="last_year"
        )
        
        if not results['success']:
            return {"error": f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {results.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"}
        
        symbol_results = results.get('symbol_results', [])
        if not symbol_results:
            return {"error": "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å–∏–º–≤–æ–ª–∞"}
        
        result = symbol_results[0]
        
        if not result.get('success', False):
            return {"error": f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"}
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        analysis = {
            "symbol": symbol,
            "accuracy": result['accuracy'],
            "samples": result['samples_tested'],
            "error_analysis": result.get('error_analysis', {}),
            "patterns": result.get('patterns_detected', []),
            "confidence": result.get('avg_confidence', 0)
        }
        
        return analysis
    
    def analyze_multiple_symbols(self, model_path: str, symbols: list) -> dict:
        """–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–∏–º–≤–æ–ª–∞—Ö"""
        print(f"üîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –¥–ª—è —Å–∏–º–≤–æ–ª–æ–≤: {symbols}")
        
        results = {}
        for symbol in symbols:
            results[symbol] = self.analyze_single_symbol(model_path, symbol)
        
        return results
    
    def print_detailed_analysis(self, analysis: dict):
        """–í—ã–≤–æ–¥ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        symbol = analysis['symbol']
        accuracy = analysis['accuracy']
        samples = analysis['samples']
        error_analysis = analysis.get('error_analysis', {})
        
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –î–õ–Ø {symbol}:")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%}")
        print(f"  –û–±—Ä–∞–∑—Ü–æ–≤: {samples}")
        print(f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis.get('confidence', 0):.2%}")
        print()
        
        if not error_analysis:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫")
            return
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        cm = error_analysis.get('confusion_matrix', [])
        if cm and len(cm) == 2:
            print("üî¢ –ú–ê–¢–†–ò–¶–ê –û–®–ò–ë–û–ö:")
            print(f"  –ü—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –ø–∞–¥–µ–Ω–∏–µ (0): {cm[0][0]}")
            print(f"  –û—à–∏–±–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ —Ä–æ—Å—Ç –≤–º–µ—Å—Ç–æ –ø–∞–¥–µ–Ω–∏—è: {cm[0][1]}")
            print(f"  –û—à–∏–±–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –ø–∞–¥–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ —Ä–æ—Å—Ç–∞: {cm[1][0]}")
            print(f"  –ü—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ —Ä–æ—Å—Ç (1): {cm[1][1]}")
            print()
        
        # –¢–∏–ø—ã –æ—à–∏–±–æ–∫
        error_patterns = error_analysis.get('error_patterns', {})
        if error_patterns:
            total_errors = error_patterns.get('total_errors', 0)
            total_correct = error_patterns.get('total_correct', 0)
            
            print("‚ùå –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö:")
            print(f"  –í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {total_errors}")
            print(f"  –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {total_correct}")
            print(f"  –ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫: {total_errors/(total_errors+total_correct)*100:.1f}%")
            
            error_types = error_patterns.get('error_types', {})
            if error_types:
                print(f"\n  –¢–∏–ø—ã –æ—à–∏–±–æ–∫:")
                for error_type, count in error_types.items():
                    error_desc = self._describe_error_type(error_type)
                    print(f"    {error_desc}: {count} —Ä–∞–∑ ({count/total_errors*100:.1f}%)")
            print()
        
        # –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
        class_balance = error_analysis.get('class_balance', {})
        if class_balance:
            print("‚öñÔ∏è –ë–ê–õ–ê–ù–° –ö–õ–ê–°–°–û–í:")
            distribution = class_balance.get('class_distribution', {})
            for class_id, info in distribution.items():
                class_name = "–ü–∞–¥–µ–Ω–∏–µ" if class_id == 0 else "–†–æ—Å—Ç"
                print(f"  {class_name} (–∫–ª–∞—Å—Å {class_id}): {info['count']} ({info['percentage']:.1f}%)")
            
            is_balanced = class_balance.get('is_balanced', False)
            imbalance_ratio = class_balance.get('imbalance_ratio', 1.0)
            print(f"  –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å: {'‚úÖ –î–∞' if is_balanced else '‚ùå –ù–µ—Ç'}")
            print(f"  –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {imbalance_ratio:.2f}")
            print()
        
        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        confidence_analysis = error_analysis.get('prediction_confidence', {})
        if confidence_analysis:
            print("üéØ –£–í–ï–†–ï–ù–ù–û–°–¢–¨ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô:")
            dist = confidence_analysis.get('confidence_distribution', {})
            print(f"  –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {dist.get('high', 0):.1f}%")
            print(f"  –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {dist.get('medium', 0):.1f}%")
            print(f"  –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {dist.get('low', 0):.1f}%")
            print(f"  –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {confidence_analysis.get('avg_pattern_length', 0):.1f}")
            print()
    
    def _describe_error_type(self, error_type: str) -> str:
        """–û–ø–∏—Å–∞–Ω–∏–µ —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏"""
        if "True_0_Pred_1" in error_type:
            return "–õ–æ–∂–Ω—ã–π —Ä–æ—Å—Ç (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ —Ä–æ—Å—Ç, –∞ –±—ã–ª–æ –ø–∞–¥–µ–Ω–∏–µ)"
        elif "True_1_Pred_0" in error_type:
            return "–õ–æ–∂–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –ø–∞–¥–µ–Ω–∏–µ, –∞ –±—ã–ª —Ä–æ—Å—Ç)"
        else:
            return error_type
    
    def generate_recommendations(self, analysis: dict) -> list:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        recommendations = []
        accuracy = analysis['accuracy']
        error_analysis = analysis.get('error_analysis', {})
        
        if accuracy < 0.55:
            recommendations.extend([
                "üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´:",
                "  ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å –±–ª–∏–∑–∫–∞ –∫ —Å–ª—É—á–∞–π–Ω–æ–π (50%)",
                "  ‚Ä¢ –ú–æ–¥–µ–ª—å –Ω–µ —É–ª–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ –Ω–æ–≤—ã—Ö —Å–∏–º–≤–æ–ª–∞—Ö",
                "  ‚Ä¢ –¢—Ä–µ–±—É–µ—Ç—Å—è –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã",
                "",
                "üöÄ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:",
                "  1. –û–±—É—á–∏—Ç—å –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å —Å:",
                "     - –ë–æ–ª—å—à–µ —Å–∏–º–≤–æ–ª–æ–≤ –≤ –æ–±—É—á–µ–Ω–∏–∏ (10+ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç)",
                "     - –£–ª—É—á—à–µ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π (–±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–µ —Å–ª–æ–∏)",
                "     - –õ—É—á—à–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)",
                "  2. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ",
                "  3. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –ø–æ–¥—Ö–æ–¥—ã (LSTM, Transformer)",
                "  4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–∏ –º–æ–¥–µ–ª–µ–π"
            ])
        elif accuracy < 0.65:
            recommendations.extend([
                "üü° –ü–†–û–ë–õ–ï–ú–´ –°–†–ï–î–ù–ï–ô –°–ï–†–¨–ï–ó–ù–û–°–¢–ò:",
                "  ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å –≤—ã—à–µ —Å–ª—É—á–∞–π–Ω–æ–π, –Ω–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è",
                "  ‚Ä¢ –ú–æ–¥–µ–ª—å —á–∞—Å—Ç–∏—á–Ω–æ —É–ª–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã",
                "  ‚Ä¢ –¢—Ä–µ–±—É—é—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏—è",
                "",
                "üöÄ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:",
                "  1. –£–ª—É—á—à–∏—Ç—å —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å:",
                "     - –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (RSI, MACD, Bollinger Bands)",
                "     - –£–≤–µ–ª–∏—á–∏—Ç—å –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è",
                "     - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã",
                "  2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å—é –≤ —Ç–æ—Ä–≥–æ–≤–ª–µ",
                "  3. –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"
            ])
        else:
            recommendations.extend([
                "üü¢ –ü–†–ò–ï–ú–õ–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:",
                "  ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏",
                "  ‚Ä¢ –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±–æ–±—â–∞—é—â—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å",
                "  ‚Ä¢ –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å—é",
                "",
                "üöÄ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:",
                "  1. –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏:",
                "     - –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —Å–∏–º–≤–æ–ª–æ–≤ –≤ –≤–∞–ª–∏–¥–∞—Ü–∏—é",
                "     - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ä–æ–≥–∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π",
                "     - –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç",
                "  2. –ù–∞—á–∞—Ç—å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–æ—Ä–≥–æ–≤–ª–µ",
                "  3. –ü–æ—Å—Ç–æ—è–Ω–Ω–æ –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
            ])
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫
        if error_analysis:
            error_patterns = error_analysis.get('error_patterns', {})
            if error_patterns:
                most_common_error = error_patterns.get('most_common_error')
                if most_common_error:
                    error_desc = self._describe_error_type(most_common_error[0])
                    recommendations.append(f"  4. –û–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞: {error_desc}")
            
            class_balance = error_analysis.get('class_balance', {})
            if class_balance and not class_balance.get('is_balanced', True):
                recommendations.append("  5. –ò—Å–ø—Ä–∞–≤–∏—Ç—å –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è")
        
        return recommendations

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫"""
    print("üîç –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö CNN –ú–û–î–ï–õ–ò")
    print("=" * 50)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    model_path = "cnn_training/result/multi/runs/93b1/cnn_model_multi_best.pth"
    test_symbols = ['SOLUSDT', 'XRPUSDT', 'TONUSDT']
    
    print(f"üìä –ú–æ–¥–µ–ª—å: {model_path}")
    print(f"üéØ –¢–µ—Å—Ç–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã: {test_symbols}")
    print()
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = CNNErrorAnalyzer()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Å–∏–º–≤–æ–ª
    all_results = {}
    for symbol in test_symbols:
        print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {symbol}...")
        result = analyzer.analyze_single_symbol(model_path, symbol)
        all_results[symbol] = result
        
        if 'error' not in result:
            analyzer.print_detailed_analysis(result)
            recommendations = analyzer.generate_recommendations(result)
            print("\n".join(recommendations))
            print("\n" + "="*50 + "\n")
    
    # –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑
    print("üìä –û–ë–©–ò–ô –ê–ù–ê–õ–ò–ó:")
    print("-" * 30)
    
    accuracies = [r['accuracy'] for r in all_results.values() if 'error' not in r]
    if accuracies:
        avg_accuracy = np.mean(accuracies)
        best_symbol = max(all_results.items(), key=lambda x: x[1].get('accuracy', 0))
        worst_symbol = min(all_results.items(), key=lambda x: x[1].get('accuracy', 1))
        
        print(f"–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å: {avg_accuracy:.2%}")
        print(f"–õ—É—á—à–∏–π —Å–∏–º–≤–æ–ª: {best_symbol[0]} ({best_symbol[1]['accuracy']:.2%})")
        print(f"–•—É–¥—à–∏–π —Å–∏–º–≤–æ–ª: {worst_symbol[0]} ({worst_symbol[1]['accuracy']:.2%})")
        
        if avg_accuracy < 0.55:
            print("\nüî¥ –í–´–í–û–î: –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏")
        elif avg_accuracy < 0.65:
            print("\nüü° –í–´–í–û–î: –ú–æ–¥–µ–ª—å –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ —É–ª—É—á—à–µ–Ω–∏—è—Ö")
        else:
            print("\nüü¢ –í–´–í–û–î: –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–∏–µ–º–ª–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")

if __name__ == "__main__":
    main()
