services:
  postgres:
    image: postgres:14
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: medoed_db
      POSTGRES_USER: medoed_user
      POSTGRES_PASSWORD: medoed
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s

  redis:
    image: redis:latest
    container_name: redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 10
      start_period: 5s

  medoedai:
    build: .
    container_name: medoedai
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    ports:
      - "5050:5050"
    environment:
      TORCHSERVE_URL: http://serving:8080/predictions/medoedai_model
      DISABLE_TORCH_COMPILE: "true"   # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å torch.compile –¥–ª—è Tesla P100
      FORCE_DISABLE_TORCH_COMPILE: "true"  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç torch.compile
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/0
      PYTHONDONTWRITEBYTECODE: "1"
      FLASK_DEBUG: "False"
    env_file:
      - .env
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ Docker API
    working_dir: /workspace
    command: >
      sh -c "
        echo 'üßπ –û—á–∏—â–∞—é Redis –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º...' &&
        python clear_redis.py &&
        echo '‚úÖ Redis –æ—á–∏—â–µ–Ω, –∑–∞–ø—É—Å–∫–∞—é Flask...' &&
        python main.py
      "
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  celery-worker:
    build: .
    container_name: celery-worker
    depends_on:
      medoedai:
        condition: service_started
      redis:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/0
      PYTHONDONTWRITEBYTECODE: "1"
      DISABLE_TORCH_COMPILE: "true"   # –û—Ç–∫–ª—é—á–∏—Ç—å torch.compile –¥–ª—è Tesla P100
      FORCE_DISABLE_TORCH_COMPILE: "true"  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞
      # –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º Celery (–æ–±—ã—á–Ω—ã–µ –æ—á–µ—Ä–µ–¥–∏)
      CELERY_POOL: prefork
      CELERY_CONCURRENCY: "6"
      # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤ –≤–Ω—É—Ç—Ä–∏ NumPy/MKL/Torch
      OMP_NUM_THREADS: "4"
      MKL_NUM_THREADS: "4"
      TORCH_NUM_THREADS: "4"
      # –Ø–≤–Ω–æ —Å–∫—Ä—ã—Ç—å GPU –¥–ª—è –≤–æ—Ä–∫–µ—Ä–∞
      CUDA_VISIBLE_DEVICES: ""
    env_file:
      - .env
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock
    working_dir: /workspace
    # –ò—Å–∫–ª—é—á–∞–µ–º –æ—á–µ—Ä–µ–¥—å train –∏–∑ –æ–±—â–µ–≥–æ –≤–æ—Ä–∫–µ—Ä–∞, —á—Ç–æ–±—ã –Ω–µ –∫–æ–Ω–∫—É—Ä–∏—Ä–æ–≤–∞—Ç—å –∑–∞ CPU
    command: ["sh","-lc","celery -A tasks.celery_tasks worker -Q celery -P ${CELERY_POOL:-prefork} -c ${CELERY_CONCURRENCY:-6} --loglevel=info"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–æ—Ä–∫–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ CPU —è–¥—Ä–∞
  celery-train:
    build: .
    container_name: celery-train
    depends_on:
      medoedai:
        condition: service_started
      redis:
        condition: service_healthy
    restart: unless-stopped
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/0
      PYTHONDONTWRITEBYTECODE: "1"
      DISABLE_TORCH_COMPILE: "true"
      FORCE_DISABLE_TORCH_COMPILE: "true"
      CELERY_POOL: prefork
      CELERY_CONCURRENCY: "1"  # –æ–¥–∏–Ω –ø—Ä–æ—Ü–µ—Å—Å, –Ω–æ –º–∞–∫—Å–∏–º—É–º –ø–æ—Ç–æ–∫–æ–≤ –≤–Ω—É—Ç—Ä–∏ BLAS/Torch
      CUDA_VISIBLE_DEVICES: ""
      TRAIN_CPU_FRACTION: "0.8"  # –¥–æ–ª—è CPU —è–¥–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –æ–±—É—á–µ–Ω–∏–µ–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 80%)
    env_file:
      - .env
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock
    working_dir: /workspace
    command: ['sh','-lc','NPROC=$(nproc); THREADS=$(python -c "import os,math; n=os.cpu_count() or 1; f=float(os.environ.get(\"TRAIN_CPU_FRACTION\", \"0.8\")); print(max(1,int(n*f)))"); export OMP_NUM_THREADS=$THREADS MKL_NUM_THREADS=$THREADS TORCH_NUM_THREADS=$THREADS; echo Using $THREADS/$NPROC CPU threads for training; exec celery -A tasks.celery_tasks worker -Q train -P ${CELERY_POOL:-prefork} -c ${CELERY_CONCURRENCY:-1} --loglevel=info']

  pytorch-gpu:
    image: pytorch/pytorch:2.2.2-cuda12.1-cudnn8-runtime
    container_name: pytorch-gpu
    depends_on:
      celery-worker:
        condition: service_started
    ports:
      - "8090:8090"
    volumes:
      - ./workspace:/workspace
      - ./models:/models
    working_dir: /workspace
    command: ["bash","-lc","python train.py && sleep 2"]
    restart: "no"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  trading_agent:
    build:
      context: .
      dockerfile: Dockerfile.trading_agent
    container_name: trading_agent
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - BYBIT_API_KEY=${BYBIT_API_KEY:-}
      - BYBIT_SECRET_KEY=${BYBIT_SECRET_KEY:-}
      - TRADING_MODE=${TRADING_MODE:-sandbox}
    env_file:
      - .env       
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ Docker API
    working_dir: /workspace
    command: ["sleep", "infinity"]  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è —É–¥–µ—Ä–∂–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –≤ –∞–∫—Ç–∏–≤–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]    

  celery-beat:
    build: .
    container_name: celery-beat
    command: ["celery", "-A", "tasks.celery_tasks", "beat", "--loglevel=info"]
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/0
      ENABLE_TRADING_BEAT: "1"
    env_file:
      - .env      
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock
    working_dir: /workspace
    depends_on:
      - redis
      - celery-worker
    restart: unless-stopped

volumes:
  pgdata:

