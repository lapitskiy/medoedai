#!/usr/bin/env python3
"""
üöÄ MedoedAI - Flask –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è DQN —Ç–æ—Ä–≥–æ–≤—ã–º –±–æ—Ç–æ–º

–ó–∞–ø—É—Å–∫:
    python main.py              # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫
    flask run                   # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
    FLASK_APP=main.py flask run # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
"""

import requests
from flask import Flask, request, jsonify, render_template
from flask import redirect, url_for

import redis

from tasks.celery_tasks import celery
from celery.result import AsyncResult

import os
from tasks.celery_tasks import search_lstm_task, train_dqn, train_dqn_multi_crypto, trade_step
from utils.db_utils import clean_ohlcv_data, delete_ohlcv_for_symbol_timeframe, load_latest_candles_from_csv_to_db
from utils.parser import parser_download_and_combine_with_library

import logging
from flask import Response
import json

import time

import glob
import os

logging.basicConfig(level=logging.INFO)

# –°–æ–∑–¥–∞–µ–º Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = Flask(__name__)

# –§—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ Redis –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
def clear_redis_on_startup():
    """–û—á–∏—â–∞–µ—Ç Redis –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Redis (–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ö–æ—Å—Ç—ã)
        redis_hosts = ['localhost', 'redis', '127.0.0.1']
        r = None
        
        for host in redis_hosts:
            try:
                r = redis.Redis(host=host, port=6379, db=0, socket_connect_timeout=5)
                r.ping()  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–∏–ª–∏—Å—å –∫ Redis –Ω–∞ {host}")
                break
            except Exception:
                continue
        
        if r is None:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Redis")
            return None
        
        # –û—á–∏—â–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        r.flushall()
        print("‚úÖ Redis –æ—á–∏—â–µ–Ω –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
        if r.dbsize() == 0:
            print("‚úÖ Redis –ø—É—Å—Ç, –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
        else:
            print(f"‚ö†Ô∏è –í Redis –æ—Å—Ç–∞–ª–æ—Å—å {r.dbsize()} –∫–ª—é—á–µ–π")
            
        return r
            
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å Redis: {e}")
        print("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏ Redis")
        return None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Redis –∫–ª–∏–µ–Ω—Ç –∏ –æ—á–∏—â–∞–µ–º –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
redis_client = clear_redis_on_startup()
if redis_client is None:
    # Fallback - —Å–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏
    try:
        redis_client = redis.Redis(host='localhost', port=6379, db=0)
    except:
        redis_client = redis.Redis(host='redis', port=6379, db=0)



@app.before_request
def log_request_info():
    logging.info(f"Request from {request.remote_addr}: {request.method} {request.path}")
    logging.info("Headers: %s", dict(request.headers))  # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏

@app.route("/")
def index():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á Celery –∏ –∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
    task_ids = redis_client.keys("celery-task-meta-*")  # –ò—â–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
    print(f"task_ids {print(task_ids)}")
    tasks = []

    for task_id in task_ids:
        task_id = task_id.decode("utf-8").replace("celery-task-meta-", "")
        task = AsyncResult(task_id, app=celery)

        tasks.append({
            "task_id": task_id,
            "state": task.state,
            "result": task.result if task.successful() else None
        })

    return render_template("index.html", tasks=tasks)


@app.route("/task-start-search", methods=["POST"])
def start_task():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∑–∞–¥–∞—á—É Celery –∏ –¥–µ–ª–∞–µ—Ç —Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
    query = request.form.get("query", "")  # –ë–µ—Ä—ë–º query –∏–∑ —Ñ–æ—Ä–º—ã

    if not query:
        return redirect(url_for("index"))  # –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –≥–ª–∞–≤–Ω—É—é

    task = search_lstm_task.apply_async(args=[query])  # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ Celery

    return redirect(url_for("index"))  # –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –≥–ª–∞–≤–Ω—É—é


@app.route("/task-status/<task_id>", methods=["GET"])
def get_task_status(task_id):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –ø–æ task_id"""
    task = long_running_task.AsyncResult(task_id)

    if task.state == "PENDING":
        response = {"state": "PENDING", "status": "–ó–∞–¥–∞—á–∞ –≤ –æ—á–µ—Ä–µ–¥–∏"}
    elif task.state == "IN_PROGRESS":
        response = {"state": "IN_PROGRESS", "status": "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è", "progress": task.info}
    elif task.state == "SUCCESS":
        response = {"state": "SUCCESS", "status": "–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞", "result": task.result}
    elif task.state == "FAILURE":
        response = {"state": "FAILURE", "status": "–û—à–∏–±–∫–∞", "error": str(task.info)}
    else:
        response = {"state": task.state, "status": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"}

    return jsonify(response)


@app.route("/start-search", methods=["POST"])
def start_parameter_search():
    try:
        response = requests.post(
            "http://parameter-search:5052/run-search",
            json={"query": "some_value"},  # –ó–¥–µ—Å—å –ø–µ—Ä–µ–¥–∞—ë–º –Ω—É–∂–Ω—ã–π query
            headers={"Content-Type": "application/json"}
        )
        return response.json()
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/train_dqn', methods=['POST'])
def train():
    task = train_dqn.apply_async(queue="train")
    return redirect(url_for("index"))

@app.route('/train_dqn_multi_crypto', methods=['POST'])
def train_multi_crypto():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ DQN"""
    task = train_dqn_multi_crypto.apply_async(queue="train")
    return redirect(url_for("index"))





@app.route('/trade_dqn', methods=['POST'])
def trade():
    task = trade_step.apply_async()
    return redirect(url_for("index"))

# –ù–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
@app.route('/clean_data', methods=['POST'])
def clean_data():
    timeframes_to_clean = ['5m', '15m', '1h']
    symbol_name ='BTC/USDT'
    
    max_close_change_percent = 15.0
    max_hl_range_percent = 20.0
    volume_multiplier = 10.0

    results = []
    for tf in timeframes_to_clean:
        try:
            # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ—á–∏—Å—Ç–∫–∏ –Ω–∞–ø—Ä—è–º—É—é (–æ–Ω–∞ –±–æ–ª—å—à–µ –Ω–µ Celery-–∑–∞–¥–∞—á–∞)
            result = clean_ohlcv_data(tf, symbol_name,
                                      max_close_change_percent,
                                      max_hl_range_percent,
                                      volume_multiplier)
            results.append(result)
        except Exception as e:
            results.append({"status": "error", "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {tf} –¥–ª—è {symbol_name}: {str(e)}"})

    return jsonify({'status': '–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –≤—Å–µ—Ö —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤.', 'results': results})


# –ù–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
@app.route('/clean_db', methods=['POST'])
def clean_db():
    timeframes_to_clean = '5m'
    symbol_name ='BTC/USDT'            

    results = []
    try:
        # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ—á–∏—Å—Ç–∫–∏ –Ω–∞–ø—Ä—è–º—É—é (–æ–Ω–∞ –±–æ–ª—å—à–µ –Ω–µ Celery-–∑–∞–¥–∞—á–∞)
        delete_ohlcv_for_symbol_timeframe('BTC/USDT', timeframes_to_clean)
        delete_ohlcv_for_symbol_timeframe('BTCUSDT', timeframes_to_clean)
    except Exception as e:
        results.append({"status": "error", "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –¥–ª—è {symbol_name}: {str(e)}"})


    return jsonify({'status': '–û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –æ—Ç –≤—Å–µ—Ö —Å–≤–µ—á–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤.', 'results': results})

@app.route('/analyze_training_results', methods=['POST'])
def analyze_training_results():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è DQN –º–æ–¥–µ–ª–∏"""
    try:
        # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ temp/train_results
        results_dir = "temp/train_results"
        if not os.path.exists(results_dir):
            return jsonify({
                'status': 'error',
                'message': f'–ü–∞–ø–∫–∞ {results_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.',
                'success': False
            }), 404
        
        result_files = glob.glob(os.path.join(results_dir, 'training_results_*.pkl'))
        
        if not result_files:
            return jsonify({
                'status': 'error',
                'message': '–§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.',
                'success': False
            }), 404
        
        # –ë–µ—Ä–µ–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π —Ñ–∞–π–ª
        latest_file = max(result_files, key=os.path.getctime)
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∞–Ω–∞–ª–∏–∑–∞
        try:
            from analyze_training_results import analyze_training_results as analyze_func
        except ImportError:
            # –ï—Å–ª–∏ –º–æ–¥—É–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é —Ñ—É–Ω–∫—Ü–∏—é –∞–Ω–∞–ª–∏–∑–∞
            def analyze_func(filename):
                print(f"üìä –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {filename}")
                print("‚ö†Ô∏è –ú–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ matplotlib –∏ numpy.")
                print("üí° –î–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: pip install matplotlib numpy")
                return "–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        try:
            import pickle
            with open(latest_file, 'rb') as f:
                results = pickle.load(f)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± actual_episodes
            if 'actual_episodes' in results:
                actual_episodes = results['actual_episodes']
                planned_episodes = results['episodes']
                
                if actual_episodes < planned_episodes:
                    print(f"‚ö†Ô∏è Early Stopping —Å—Ä–∞–±–æ—Ç–∞–ª! –û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –Ω–∞ {actual_episodes} —ç–ø–∏–∑–æ–¥–µ –∏–∑ {planned_episodes}")
                else:
                    print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é: {actual_episodes} —ç–ø–∏–∑–æ–¥–æ–≤")                    
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ—Ç–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        print(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞: {latest_file}")
        
        # –í—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º stdout –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≤—ã–≤–æ–¥–∞
        import io
        import sys
        from contextlib import redirect_stdout
        
        output = io.StringIO()
        with redirect_stdout(output):
            analyze_func(latest_file)
        
        analysis_output = output.getvalue()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± actual_episodes –≤ –æ—Ç–≤–µ—Ç
        response_data = {
            'status': 'success',
            'message': '–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ',
            'success': True,
            'file_analyzed': latest_file,
            'output': analysis_output,
            'available_files': result_files
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —ç–ø–∏–∑–æ–¥–∞—Ö –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º episode_winrates_count –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è early stopping
            if 'episode_winrates' in results:
                response_data['episode_winrates_count'] = len(results['episode_winrates'])
                print(f"üîç episode_winrates_count: {response_data['episode_winrates_count']}")
            
            if 'actual_episodes' in results:
                response_data['actual_episodes'] = results['actual_episodes']
                response_data['episodes'] = results['episodes']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ actual_episodes –∏ episode_winrates_count
                if 'episode_winrates_count' in response_data:
                    if response_data['actual_episodes'] != response_data['episode_winrates_count']:
                        print(f"‚ö†Ô∏è –ù–ï–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï: actual_episodes={response_data['actual_episodes']}, episode_winrates_count={response_data['episode_winrates_count']}")
                        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º actual_episodes –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                        response_data['actual_episodes'] = response_data['episode_winrates_count']
                        print(f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: actual_episodes = {response_data['actual_episodes']}")
            else:
                # –ï—Å–ª–∏ actual_episodes –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ –ª–æ–≥–æ–≤
                if 'output' in response_data:
                    output_text = response_data['output']
                    # –ò—â–µ–º Early stopping –≤ –ª–æ–≥–∞—Ö
                    if 'Early stopping triggered after' in output_text:
                        import re
                        early_stopping_match = re.search(r'Early stopping triggered after (\d+) episodes', output_text)
                        if early_stopping_match:
                            actual_episodes = int(early_stopping_match.group(1))
                            # –ò—â–µ–º –ø–ª–∞–Ω–∏—Ä—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤
                            episodes_match = re.search(r'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤: (\d+)', output_text)
                            if episodes_match:
                                planned_episodes = int(episodes_match.group(1))
                                response_data['actual_episodes'] = actual_episodes
                                response_data['episodes'] = planned_episodes
                                print(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ –ª–æ–≥–æ–≤: actual_episodes={actual_episodes}, episodes={planned_episodes}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ actual_episodes: {e}")
        
        return jsonify(response_data)
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}',
            'success': False
        }), 500

@app.route('/list_training_results', methods=['GET'])
def list_training_results():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è"""
    try:
        # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ temp/train_results
        results_dir = "temp/train_results"
        if not os.path.exists(results_dir):
            return jsonify({
                'status': 'error',
                'message': f'–ü–∞–ø–∫–∞ {results_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞',
                'success': False,
                'files': []
            }), 404
        
        result_files = glob.glob(os.path.join(results_dir, 'training_results_*.pkl'))
        
        if not result_files:
            return jsonify({
                'status': 'error',
                'message': '–§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã',
                'success': False,
                'files': []
            }), 404
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
        files_info = []
        for file in result_files:
            stat = os.stat(file)
            files_info.append({
                'filename': file,
                'size': stat.st_size,
                'created': stat.st_ctime,
                'modified': stat.st_mtime
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
        files_info.sort(key=lambda x: x['created'], reverse=True)
        
        return jsonify({
            'status': 'success',
            'message': f'–ù–∞–π–¥–µ–Ω–æ {len(result_files)} —Ñ–∞–π–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤',
            'success': True,
            'files': files_info
        })
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤: {str(e)}',
            'success': False
        }), 500

@app.route('/analyze_bad_trades', methods=['POST'])
def analyze_bad_trades():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–ª–æ—Ö–∏–µ —Å–¥–µ–ª–∫–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è DQN –º–æ–¥–µ–ª–∏"""
    try:
        # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ temp/train_results
        results_dir = "temp/train_results"
        if not os.path.exists(results_dir):
            return jsonify({
                'status': 'error',
                'message': f'–ü–∞–ø–∫–∞ {results_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.',
                'success': False
            }), 404
        
        result_files = glob.glob(os.path.join(results_dir, 'training_results_*.pkl'))
        
        if not result_files:
            return jsonify({
                'status': 'error',
                'message': '–§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.',
                'success': False
            }), 404
        
        # –ë–µ—Ä–µ–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π —Ñ–∞–π–ª
        latest_file = max(result_files, key=os.path.getctime)
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∞–Ω–∞–ª–∏–∑–∞ –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫
        try:
            from analyze_bad_trades import analyze_bad_trades_detailed, print_bad_trades_analysis, print_detailed_recommendations
        except ImportError:
            return jsonify({
                'status': 'error',
                'message': '–ú–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞ –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.',
                'success': False
            }), 500
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        try:
            import pickle
            with open(latest_file, 'rb') as f:
                results = pickle.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–¥–µ–ª–æ–∫
            if 'all_trades' not in results:
                return jsonify({
                    'status': 'error',
                    'message': '–í —Ñ–∞–π–ª–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–¥–µ–ª–∫–∞—Ö',
                    'success': False
                }), 404
            
            trades = results['all_trades']
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–ª–æ—Ö–∏–µ —Å–¥–µ–ª–∫–∏
            bad_trades_analysis = analyze_bad_trades_detailed(trades)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Å–¥–µ–ª–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            bad_trades_analysis['all_trades'] = trades
            
            # –í—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º stdout –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≤—ã–≤–æ–¥–∞
            import io
            import sys
            from contextlib import redirect_stdout
            
            output = io.StringIO()
            with redirect_stdout(output):
                print_bad_trades_analysis(bad_trades_analysis)
                print_detailed_recommendations(bad_trades_analysis)
            
            analysis_output = output.getvalue()
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
            response_data = {
                'status': 'success',
                'message': '–ê–Ω–∞–ª–∏–∑ –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ',
                'success': True,
                'file_analyzed': latest_file,
                'output': analysis_output,
                'bad_trades_count': bad_trades_analysis.get('bad_trades_count', 0),
                'bad_trades_percentage': bad_trades_analysis.get('bad_trades_percentage', 0),
                'analysis_summary': {
                    'total_trades': len(trades),
                    'bad_trades': bad_trades_analysis.get('bad_trades_count', 0),
                    'avg_bad_roi': bad_trades_analysis.get('avg_bad_roi', 0),
                    'avg_bad_duration': bad_trades_analysis.get('avg_bad_duration', 0),
                    'loss_distribution': bad_trades_analysis.get('loss_distribution', {})
                }
            }
            
            return jsonify(response_data)
            
        except Exception as e:
            return jsonify({
                'status': 'error',
                'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞: {str(e)}',
                'success': False
            }), 500
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫: {str(e)}',
            'success': False
        }), 500

# –ù–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
@app.route('/parser', methods=['POST'])
def parser():
    results = []
    symbol = 'BTCUSDT'
    interval = '5m'
    desired_candles = 100000
    csv_file_path = None

    try:
        # 1. –í—ã–∑—ã–≤–∞–µ–º –≤–Ω–µ—à–Ω—é—é —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞–µ—Ç CSV —Å 100 000 —Å–≤–µ—á–∞–º–∏
        csv_file_path = parser_download_and_combine_with_library(
            symbol='BTCUSDT',
            interval=interval,
            months_to_fetch=12, # –≠—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è parser_download_and_combine_with_library
            desired_candles=desired_candles
        )
        results.append({"status": "success", "message": f"CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {csv_file_path}"})

        # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —ç—Ç–∏ 100 000 —Å–≤–µ—á–µ–π –∏–∑ CSV –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î
        loaded_count = load_latest_candles_from_csv_to_db(
            file_path=csv_file_path,
            symbol_name=symbol,
            timeframe=interval
        )
        if loaded_count > 0:
            results.append({"status": "success", "message": f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} —Å–≤–µ—á–µ–π –∏–∑ CSV –≤ –ë–î."})
        else:
            results.append({"status": "warning", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ—á–∏ –∏–∑ CSV –≤ –ë–î."})

    except Exception as e:
        results.append({"status": "error", "message": f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}"})

    response = {'status': '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω', 'results': results}
    return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')

# –ù–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å–≤–µ—á–µ–π
@app.route('/parser_multi_crypto', methods=['POST'])
def parser_multi_crypto():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Å–≤–µ—á–∏ –¥–ª—è –≤—Å–µ—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ"""
    results = []
    interval = '5m'
    desired_candles = 100000
    
    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    crypto_symbols = [
        'BTCUSDT',  # –ë–∏—Ç–∫–æ–∏–Ω
        'TONUSDT',  # TON
        'ETHUSDT',  # –≠—Ñ–∏—Ä–∏—É–º
        'SOLUSDT',  # Solana
        'ADAUSDT',  # Cardano
        'BNBUSDT'   # Binance Coin
    ]
    
    print(f"üöÄ –ù–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å–≤–µ—á–µ–π –¥–ª—è {len(crypto_symbols)} –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç...")
    print(f"üìä –¢–∞–π–º—Ñ—Ä–µ–π–º: {interval}, –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {desired_candles}")
    
    for i, symbol in enumerate(crypto_symbols, 1):
        try:
            print(f"\nüì• [{i}/{len(crypto_symbols)}] –°–∫–∞—á–∏–≤–∞—é {symbol}...")
            
            # 1. –°–∫–∞—á–∏–≤–∞–µ–º —Å–≤–µ—á–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã
            csv_file_path = parser_download_and_combine_with_library(
                symbol=symbol,
                interval=interval,
                months_to_fetch=12,
                desired_candles=desired_candles
            )
            
            if csv_file_path:
                results.append({
                    "status": "success", 
                    "symbol": symbol,
                    "message": f"CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {csv_file_path}"
                })
                
                # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ—á–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                try:
                    loaded_count = load_latest_candles_from_csv_to_db(
                        file_path=csv_file_path,
                        symbol_name=symbol,
                        timeframe=interval
                    )
                    
                    if loaded_count > 0:
                        results.append({
                            "status": "success",
                            "symbol": symbol,
                            "message": f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} —Å–≤–µ—á–µ–π –≤ –ë–î"
                        })
                        print(f"  ‚úÖ {symbol}: {loaded_count} —Å–≤–µ—á–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ –ë–î")
                    else:
                        results.append({
                            "status": "warning",
                            "symbol": symbol,
                            "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ—á–∏ –≤ –ë–î"
                        })
                        print(f"  ‚ö†Ô∏è {symbol}: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î")
                        
                except Exception as db_error:
                    results.append({
                        "status": "error",
                        "symbol": symbol,
                        "message": f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î: {str(db_error)}"
                    })
                    print(f"  ‚ùå {symbol}: –æ—à–∏–±–∫–∞ –ë–î - {db_error}")
                    
            else:
                results.append({
                    "status": "error",
                    "symbol": symbol,
                    "message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å CSV —Ñ–∞–π–ª"
                })
                print(f"  ‚ùå {symbol}: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å CSV")
                
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {symbol}: {str(e)}"
            results.append({
                "status": "error",
                "symbol": symbol,
                "message": error_msg
            })
            print(f"  ‚ùå {symbol}: {error_msg}")
            continue
    
    # –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞–º
    successful = sum(1 for r in results if r['status'] == 'success')
    failed = sum(1 for r in results if r['status'] == 'error')
    warnings = sum(1 for r in results if r['status'] == 'warning')
    
    print(f"\n{'='*60}")
    print(f"üìä –°–í–û–î–ö–ê –°–ö–ê–ß–ò–í–ê–ù–ò–Ø")
    print(f"{'='*60}")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}")
    print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {warnings}")
    print(f"‚ùå –û—à–∏–±–∫–∏: {failed}")
    print(f"üìà –í—Å–µ–≥–æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç: {len(crypto_symbols)}")
    
    response = {
        'status': '–ú—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ',
        'summary': {
            'total_cryptos': len(crypto_symbols),
            'successful': successful,
            'warnings': warnings,
            'failed': failed
        },
        'results': results
    }
    
    return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')

@app.route('/clear_redis', methods=['POST'])
def clear_redis():
    """–û—á–∏—â–∞–µ—Ç Redis –≤—Ä—É—á–Ω—É—é"""
    try:
        global redis_client
        redis_client.flushall()
        return jsonify({
            "success": True,
            "message": "Redis –æ—á–∏—â–µ–Ω —É—Å–ø–µ—à–Ω–æ"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/models')
def models_page():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏"""
    return render_template('models.html')

@app.route('/create_model_version', methods=['POST'])
def create_model_version():
    """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º ID"""
    import shutil
    import uuid
    from datetime import datetime
    from pathlib import Path
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É good_models –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        good_models_dir = Path('good_models')
        good_models_dir.mkdir(exist_ok=True)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID (4 —Å–∏–º–≤–æ–ª–∞)
        model_id = str(uuid.uuid4())[:4].upper()
        
        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
        train_results_dir = Path('temp/train_results')
        if not train_results_dir.exists():
            return jsonify({
                "success": False,
                "error": "–ü–∞–ø–∫–∞ temp/train_results –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            })
        
        result_files = list(train_results_dir.glob('training_results_*.pkl'))
        if not result_files:
            return jsonify({
                "success": False,
                "error": "–§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            })
        
        latest_result_file = max(result_files, key=lambda x: x.stat().st_mtime)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏
        model_file = Path('dqn_model.pth')
        replay_file = Path('replay_buffer.pkl')
        
        if not model_file.exists():
            return jsonify({
                "success": False,
                "error": "–§–∞–π–ª dqn_model.pth –Ω–µ –Ω–∞–π–¥–µ–Ω"
            })
        
        if not replay_file.exists():
            return jsonify({
                "success": False,
                "error": "–§–∞–π–ª replay_buffer.pkl –Ω–µ –Ω–∞–π–¥–µ–Ω"
            })
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã —Å –Ω–æ–≤—ã–º–∏ –∏–º–µ–Ω–∞–º–∏
        new_model_file = good_models_dir / f'dqn_model_{model_id}.pth'
        new_replay_file = good_models_dir / f'replay_buffer_{model_id}.pkl'
        new_result_file = good_models_dir / f'train_result_{model_id}.pkl'
        
        shutil.copy2(model_file, new_model_file)
        shutil.copy2(replay_file, new_replay_file)
        shutil.copy2(latest_result_file, new_result_file)
        
        return jsonify({
            "success": True,
            "model_id": model_id,
            "files": [
                f'dqn_model_{model_id}.pth',
                f'replay_buffer_{model_id}.pkl',
                f'train_result_{model_id}.pkl'
            ]
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/get_models_list')
def get_models_list():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    from pathlib import Path
    import pickle
    from datetime import datetime
    
    try:
        good_models_dir = Path('good_models')
        if not good_models_dir.exists():
            return jsonify({
                "success": True,
                "models": []
            })
        
        models = []
        
        # –ò—â–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π
        model_files = list(good_models_dir.glob('dqn_model_*.pth'))
        
        for model_file in model_files:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –º–æ–¥–µ–ª–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            model_id = model_file.stem.replace('dqn_model_', '')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            replay_file = good_models_dir / f'replay_buffer_{model_id}.pkl'
            result_file = good_models_dir / f'train_result_{model_id}.pkl'
            
            if not replay_file.exists() or not result_file.exists():
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–ø–æ–ª–Ω—ã–µ –º–æ–¥–µ–ª–∏
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤
            model_size = f"{model_file.stat().st_size / 1024 / 1024:.1f} MB"
            replay_size = f"{replay_file.stat().st_size / 1024 / 1024:.1f} MB"
            result_size = f"{result_file.stat().st_size / 1024:.1f} KB"
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É —Å–æ–∑–¥–∞–Ω–∏—è
            creation_time = datetime.fromtimestamp(model_file.stat().st_ctime)
            date_str = creation_time.strftime('%d.%m.%Y %H:%M')
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ —Ñ–∞–π–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            stats = {}
            try:
                with open(result_file, 'rb') as f:
                    results = pickle.load(f)
                    if 'final_stats' in results:
                        stats = results['final_stats']
            except:
                pass  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, –æ—Å—Ç–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é
            
            models.append({
                "id": model_id,
                "date": date_str,
                "files": {
                    "model": f'dqn_model_{model_id}.pth',
                    "model_size": model_size,
                    "replay": f'replay_buffer_{model_id}.pkl',
                    "replay_size": replay_size,
                    "results": f'train_result_{model_id}.pkl',
                    "results_size": result_size
                },
                "stats": stats
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        models.sort(key=lambda x: x['date'], reverse=True)
        
        return jsonify({
            "success": True,
            "models": models
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/analyze_model', methods=['POST'])
def analyze_model():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å"""
    import pickle
    from pathlib import Path
    
    try:
        data = request.get_json()
        model_id = data.get('model_id')
        
        if not model_id:
            return jsonify({
                "success": False,
                "error": "ID –º–æ–¥–µ–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω"
            })
        
        result_file = Path(f'good_models/train_result_{model_id}.pkl')
        if not result_file.exists():
            return jsonify({
                "success": False,
                "error": f"–§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω"
            })
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        with open(result_file, 'rb') as f:
            results = pickle.load(f)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑
        analysis = f"""üìä –ê–ù–ê–õ–ò–ó –ú–û–î–ï–õ–ò {model_id}
{'='*50}

üìÖ –î–∞—Ç–∞ –æ–±—É—á–µ–Ω–∏—è: {results.get('training_date', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}
‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {results.get('total_training_time', 0) / 3600:.1f} —á–∞—Å–æ–≤
üéØ –≠–ø–∏–∑–æ–¥–æ–≤: {results.get('actual_episodes', results.get('episodes', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))}

üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
"""
        
        if 'final_stats' in results:
            stats = results['final_stats']
            analysis += f"""
‚Ä¢ Winrate: {stats.get('winrate', 0) * 100:.1f}%
‚Ä¢ P/L Ratio: {stats.get('pl_ratio', 0):.2f}
‚Ä¢ –°–¥–µ–ª–æ–∫: {stats.get('trades_count', 0)}
‚Ä¢ –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å: {stats.get('avg_profit', 0) * 100:.2f}%
‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —É–±—ã—Ç–æ–∫: {stats.get('avg_loss', 0) * 100:.2f}%
‚Ä¢ –ü–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫: {stats.get('bad_trades_count', 0)}
"""
        
        if 'all_trades' in results:
            trades = results['all_trades']
            analysis += f"""
üìä –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–î–ï–õ–û–ö:
‚Ä¢ –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {len(trades)}
‚Ä¢ –ü—Ä–∏–±—ã–ª—å–Ω—ã—Ö: {sum(1 for t in trades if t.get('roi', 0) > 0)}
‚Ä¢ –£–±—ã—Ç–æ—á–Ω—ã—Ö: {sum(1 for t in trades if t.get('roi', 0) < 0)}
‚Ä¢ –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö: {sum(1 for t in trades if abs(t.get('roi', 0)) < 0.001)}
"""
        
        return jsonify({
            "success": True,
            "analysis": analysis
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/delete_model', methods=['POST'])
def delete_model():
    """–£–¥–∞–ª—è–µ—Ç –º–æ–¥–µ–ª—å –∏ –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
    from pathlib import Path
    import os
    
    try:
        data = request.get_json()
        model_id = data.get('model_id')
        
        if not model_id:
            return jsonify({
                "success": False,
                "error": "ID –º–æ–¥–µ–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω"
            })
        
        good_models_dir = Path('good_models')
        
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏
        files_to_delete = [
            good_models_dir / f'dqn_model_{model_id}.pth',
            good_models_dir / f'replay_buffer_{model_id}.pkl',
            good_models_dir / f'train_result_{model_id}.pkl'
        ]
        
        deleted_files = []
        for file_path in files_to_delete:
            if file_path.exists():
                os.remove(file_path)
                deleted_files.append(file_path.name)
        
        if not deleted_files:
            return jsonify({
                "success": False,
                "error": f"–§–∞–π–ª—ã –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            })
        
        return jsonify({
            "success": True,
            "message": f"–ú–æ–¥–µ–ª—å {model_id} —É–¥–∞–ª–µ–Ω–∞",
            "deleted_files": deleted_files
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ Flask —Å–µ—Ä–≤–µ—Ä–∞
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5050))  # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    debug_mode = os.environ.get("FLASK_DEBUG", "False").lower() == "true"
    print(f"üöÄ –ó–∞–ø—É—Å–∫–∞—é Flask —Å–µ—Ä–≤–µ—Ä –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    print(f"üåê –û—Ç–∫—Ä–æ–π—Ç–µ: http://localhost:{port}")
    print(f"üîß Debug —Ä–µ–∂–∏–º: {'–í–ö–õ–Æ–ß–ï–ù' if debug_mode else '–û–¢–ö–õ–Æ–ß–ï–ù'}")
    app.run(host="0.0.0.0", port=port, debug=debug_mode)
