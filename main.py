#!/usr/bin/env python3
"""
üöÄ MedoedAI - Flask –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è DQN —Ç–æ—Ä–≥–æ–≤—ã–º –±–æ—Ç–æ–º

–ó–∞–ø—É—Å–∫:
    python main.py              # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫
    flask run                   # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
    FLASK_APP=main.py flask run # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
"""

import requests # type: ignore
from flask import Flask, request, jsonify, render_template, current_app # type: ignore
from flask import redirect, url_for
from pathlib import Path

import redis # type: ignore

from tasks.celery_tasks import celery
from routes.bybit import bybit_bp
from routes.trading import trading_bp, get_matched_full_trades
from routes.models_admin import models_admin_bp
from routes.oos import oos_bp
from routes.training import training_bp
from routes.analysis_page import analytics_bp
from routes.sac import sac_bp
from utils.redis_utils import get_redis_client, clear_redis_on_startup

"""get_redis_client –±–µ—Ä—ë–º –∏–∑ utils.redis_utils"""

 
from celery.result import AsyncResult

import os
from utils.config_loader import get_config_value
import re
from tasks.celery_tasks import search_lstm_task, train_dqn, train_dqn_multi_crypto, train_dqn_symbol
from utils.db_utils import load_latest_candles_from_csv_to_db
from utils.parser import parser_download_and_combine_with_library
from utils.trade_utils import (
    get_recent_trades, 
    get_trade_statistics, 
    get_trades_by_symbol,
    get_model_predictions, 
    get_prediction_statistics
)

import logging
from flask import Response
import json

import time

import glob
import os
import pickle

import docker # type: ignore

from tasks.celery_task_trade import start_trading_task
from utils.celery_utils import ensure_symbol_worker

logging.basicConfig(level=logging.INFO)

# –°–æ–∑–¥–∞–µ–º Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = Flask(__name__)

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –º–∞—Ä—à—Ä—É—Ç—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ (–∞–Ω–∞–ª–∏–∑ DQN)
from routes.analysis import analysis_api_bp
app.register_blueprint(analysis_api_bp)
app.register_blueprint(bybit_bp)
app.register_blueprint(trading_bp)
app.register_blueprint(models_admin_bp)
app.register_blueprint(training_bp, url_prefix='/training')
from routes.clean import clean_bp
app.register_blueprint(clean_bp)
app.register_blueprint(oos_bp)
app.register_blueprint(sac_bp)
app.register_blueprint(analytics_bp)

# –§—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ Redis –≤—ã–Ω–µ—Å–µ–Ω–∞ –≤ utils.redis_utils.clear_redis_on_startup

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Redis –∫–ª–∏–µ–Ω—Ç –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏ (decode_responses=True)
redis_client = get_redis_client()

@app.before_request
def log_request_info():
    logging.info(f"Request from {request.remote_addr}: {request.method} {request.path}")
    logging.info("Headers: %s", dict(request.headers))  # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏

@app.route("/")
def index():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á Celery –∏ –∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
    tasks = []

    # 1) –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ ui:tasks
    try:
        recent_ids = redis_client.lrange("ui:tasks", 0, 49) or []
        for raw_id in recent_ids:
            try:
                task_id = raw_id.decode("utf-8")
            except Exception:
                task_id = str(raw_id)
            task = AsyncResult(task_id, app=celery)
            tasks.append({
                "task_id": task_id,
                "state": task.state,
                "result": task.result if task.successful() else None
            })
    except Exception as _e:
        app.logger.error(f"/ index: –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è ui:tasks: {_e}")

    # 2) Fallback: —Å–∫–∞–Ω–∏—Ä—É–µ–º backend –ø–æ –∫–ª—é—á–∞–º (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ –¥–ª—è PENDING)
    if not tasks:
        try:
            task_keys = redis_client.keys("celery-task-meta-*") or []
            for key in task_keys:
                task_id = key.decode("utf-8").replace("celery-task-meta-", "")
                task = AsyncResult(task_id, app=celery)
                tasks.append({
                    "task_id": task_id,
                    "state": task.state,
                    "result": task.result if task.successful() else None
                })
        except Exception as _e:
            app.logger.error(f"/ index: –æ—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è backend: {_e}")

    return render_template("index.html", tasks=tasks)

@app.route("/task-start-search", methods=["POST"])
def start_task():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∑–∞–¥–∞—á—É Celery –∏ –¥–µ–ª–∞–µ—Ç —Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
    query = request.form.get("query", "")  # –ë–µ—Ä—ë–º query –∏–∑ —Ñ–æ—Ä–º—ã

    if not query:
        return redirect(url_for("index"))  # –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –≥–ª–∞–≤–Ω—É—é

    task = search_lstm_task.apply_async(args=[query])  # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ Celery

    return redirect(url_for("index"))  # –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –≥–ª–∞–≤–Ω—É—é


@app.route("/task-status/<task_id>", methods=["GET"])
def get_task_status(task_id):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –ø–æ task_id"""
    task = AsyncResult(task_id, app=celery)

    if task.state == "PENDING":
        response = {"state": "PENDING", "status": "–ó–∞–¥–∞—á–∞ –≤ –æ—á–µ—Ä–µ–¥–∏"}
    elif task.state == "IN_PROGRESS":
        response = {"state": "IN_PROGRESS", "status": "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è", "progress": task.info}
    elif task.state == "SUCCESS":
        response = {"state": "SUCCESS", "status": "–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞", "result": task.result}
    elif task.state == "FAILURE":
        response = {"state": "FAILURE", "status": "–û—à–∏–±–∫–∞", "error": str(task.info)}
    else:
        response = {"state": task.state, "status": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"}

    return jsonify(response)


@app.route("/start-search", methods=["POST"])
def start_parameter_search():
    try:
        response = requests.post(
            "http://parameter-search:5052/run-search",
            json={"query": "some_value"},  # –ó–¥–µ—Å—å –ø–µ—Ä–µ–¥–∞—ë–º –Ω—É–∂–Ω—ã–π query
            headers={"Content-Type": "application/json"}
        )
        return response.json()
    except Exception as e:
        return jsonify({"error": str(e)}), 500

 
@app.route('/list_training_results', methods=['GET'])
def list_training_results():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ result/<SYMBOL>/runs/*/{train_result.pkl, manifest.json}"""
    try:
        base = os.path.join('result')
        if not os.path.exists(base):
            return jsonify({'status': 'error','message': f'–ü–∞–ø–∫–∞ {base} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞','success': False,'files': []}), 404
        items = []
        for sym in sorted(os.listdir(base)):
            sym_dir = os.path.join(base, sym, 'runs')
            if not os.path.isdir(sym_dir):
                continue
            for run_id in os.listdir(sym_dir):
                run_dir = os.path.join(sym_dir, run_id)
                if not os.path.isdir(run_dir):
                    continue
                tr = os.path.join(run_dir, 'train_result.pkl')
                mf = os.path.join(run_dir, 'manifest.json')
                mp = os.path.join(run_dir, 'model.pth')
                if os.path.exists(tr):
                    try:
                        stat = os.stat(tr)
                        manifest = {}
                        try:
                            if os.path.exists(mf):
                                manifest = json.loads(open(mf,'r',encoding='utf-8').read())
                        except Exception:
                            manifest = {}
                        items.append({
                            'symbol': sym,
                            'run_id': run_id,
                            'train_result': tr,
                            'model_path': mp if os.path.exists(mp) else None,
                            'manifest': manifest,
                            'size': stat.st_size,
                            'created': stat.st_ctime,
                            'modified': stat.st_mtime
                        })
                    except Exception:
                        continue
        if not items:
            return jsonify({'status': 'error','message': '–§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã','success': False,'files': []}), 404
        items.sort(key=lambda x: (x.get('created') or 0), reverse=True)
        return jsonify({'status': 'success','message': f'–ù–∞–π–¥–µ–Ω–æ {len(items)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤','success': True,'files': items})
    except Exception as e:
        return jsonify({'status': 'error','message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞: {str(e)}','success': False}), 500

@app.route('/list_result_models', methods=['GET'])
def list_result_models():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π –∏–∑ result (dqn_model_*.pth)."""
    try:
        results_dir = "result"
        if not os.path.exists(results_dir):
            return jsonify({
                'status': 'error',
                'message': f'–ü–∞–ø–∫–∞ {results_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞',
                'success': False,
                'files': []
            }), 404

        model_files = glob.glob(os.path.join(results_dir, 'dqn_model_*.pth'))
        if not model_files:
            return jsonify({
                'status': 'error',
                'message': '–§–∞–π–ª—ã –≤–µ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã',
                'success': False,
                'files': []
            }), 404

        files_info = []
        for file in model_files:
            stat = os.stat(file)
            files_info.append({
                'filename': file,
                'size': stat.st_size,
                'created': stat.st_ctime,
                'modified': stat.st_mtime
            })

        files_info.sort(key=lambda x: x['modified'], reverse=True)

        return jsonify({
            'status': 'success',
            'message': f'–ù–∞–π–¥–µ–Ω–æ {len(files_info)} —Ñ–∞–π–ª–æ–≤ –≤–µ—Å–æ–≤',
            'success': True,
            'files': files_info
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –≤–µ—Å–æ–≤: {str(e)}',
            'success': False
        }), 500

@app.route('/get_result_model_info', methods=['POST'])
def get_result_model_info():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –≤–µ—Å–æ–≤ –∏–∑ result/ (dqn_model_*.pth):
    —Å–∏–º–≤–æ–ª/–∫–æ–¥, –Ω–∞–ª–∏—á–∏–µ replay/train_result, –±–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (winrate, trades_count, episodes).
    Body: { filename: 'result/dqn_model_XXXX.pth' }
    """
    try:
        data = request.get_json(silent=True) or {}
        filename = (data.get('filename') or '').strip()
        if not filename:
            return jsonify({'success': False, 'error': '–ù–µ —É–∫–∞–∑–∞–Ω filename'}), 400

        results_dir = Path('result')
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–∏
        req_norm = filename.replace('\\', '/')
        p = Path(req_norm)
        if not p.is_absolute():
            if not (p.parts and p.parts[0].lower() == results_dir.name.lower()):
                p = results_dir / p.name
        try:
            p = p.resolve()
        except Exception:
            pass
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: —Ç–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–∏ result/
        if not str(p).lower().startswith(str(results_dir.resolve()).lower()):
            return jsonify({'success': False, 'error': '–§–∞–π–ª –≤–Ω–µ –ø–∞–ø–∫–∏ result'}), 400
        if not p.exists() or not p.is_file() or p.suffix != '.pth':
            return jsonify({'success': False, 'error': '–û–∂–∏–¥–∞–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ (.pth) –≤–Ω—É—Ç—Ä–∏ result'}), 400

        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–≤—É—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –ø—É—Ç–µ–π:
        # 1) –ü–ª–æ—Å–∫–∏–π: result/dqn_model_<code>.pth
        # 2) –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π run: result/<SYMBOL>/runs/<run_id>/model.pth
        code = None
        symbol_str = None
        replay_file = None
        train_file = None
        if p.name.startswith('dqn_model_'):
            code = p.stem.replace('dqn_model_', '')
            replay_file = results_dir / f'replay_buffer_{code}.pkl'
            train_file = results_dir / f'train_result_{code}.pkl'
            # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Å–∏–º–≤–æ–ª –∏–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –∫–æ–¥–∞
            try:
                base = code.split('_')[0].upper()
                if base and len(base) <= 6:
                    symbol_str = base + 'USDT'
            except Exception:
                symbol_str = None
        else:
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—É—Ç—å run: .../result/<SYMBOL>/runs/<run_id>/model.pth
            try:
                parts = [x for x in p.parts]
                # –ù–∞–π–¥—ë–º –∏–Ω–¥–µ–∫—Å 'runs'
                if 'runs' in parts:
                    idx = parts.index('runs')
                    if idx + 1 < len(parts):
                        run_id = parts[idx + 1]
                        code = run_id
                        run_dir = p.parent
                        replay_file = run_dir / 'replay.pkl'
                        train_file = run_dir / 'train_result.pkl'
                        # –°–∏–º–≤–æ–ª –±–µ—Ä—ë–º –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞ –ø–µ—Ä–µ–¥ 'runs'
                        if idx - 1 >= 0:
                            symbol_str = parts[idx - 1]
            except Exception:
                pass
            if not code:
                return jsonify({'success': False, 'error': '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –º–æ–¥–µ–ª—å: –æ–∂–∏–¥–∞–µ—Ç—Å—è dqn_model_*.pth –∏–ª–∏ runs/.../model.pth'}), 400

        info = {
            'success': True,
            'model_file': str(p),
            'model_size_bytes': p.stat().st_size if p.exists() else 0,
            'code': code,
            'symbol': symbol_str,
            'replay_exists': replay_file.exists(),
            'train_result_exists': train_file.exists(),
            'replay_file': str(replay_file) if replay_file.exists() else None,
            'train_result_file': str(train_file) if train_file.exists() else None,
            'stats': {},
            'episodes': None
        }

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ train_result_*.pkl –µ—Å–ª–∏ –µ—Å—Ç—å
        if train_file.exists():
            try:
                with open(train_file, 'rb') as f:
                    results = pickle.load(f)
                stats = results.get('final_stats', {}) or {}
                info['stats'] = {
                    'winrate': stats.get('winrate'),
                    'pl_ratio': stats.get('pl_ratio'),
                    'trades_count': stats.get('trades_count')
                }

                planned_episodes = results.get('episodes')
                actual_episodes = results.get('actual_episodes')
                info['episodes'] = actual_episodes if actual_episodes is not None else planned_episodes
                info['episodes_planned'] = planned_episodes
                info['actual_episodes'] = actual_episodes

                train_metadata = results.get('train_metadata') or {}
                info['seed'] = train_metadata.get('seed')
                info['cuda_available'] = train_metadata.get('cuda_available', False)
                info['gpu_name'] = train_metadata.get('gpu_name')
                info['total_training_time'] = results.get('total_training_time')
                if info['total_training_time'] and info['episodes']:
                    try:
                        info['avg_time_per_episode_sec'] = info['total_training_time'] / max(info['episodes'], 1)
                    except Exception:
                        info['avg_time_per_episode_sec'] = None
                else:
                    info['avg_time_per_episode_sec'] = None

                info['train_metadata'] = {
                    'created_at_utc': train_metadata.get('created_at_utc'),
                    'hostname': train_metadata.get('hostname'),
                    'platform': train_metadata.get('platform'),
                    'python_version': train_metadata.get('python_version'),
                    'torch_version': train_metadata.get('torch_version'),
                    'cuda_available': train_metadata.get('cuda_available'),
                    'gpu_name': train_metadata.get('gpu_name'),
                    'git_commit': train_metadata.get('git_commit'),
                    'seed': train_metadata.get('seed'),
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª–∏–Ω—É —ç–ø–∏–∑–æ–¥–∞, –µ—Å–ª–∏ –æ–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ gym_snapshot
                gym_snapshot = results.get('gym_snapshot', {}) or {}
                if 'episode_length' in gym_snapshot:
                    info['episode_length'] = gym_snapshot['episode_length']
                elif 'cfg_snapshot' in results and isinstance(results['cfg_snapshot'], dict):
                    info['episode_length'] = results['cfg_snapshot'].get('episode_length')

                # –ü—É—Ç–∏ –∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º
                info['model_path'] = results.get('model_path') or info.get('model_file')
                info['buffer_path'] = results.get('buffer_path')

                weights = results.get('weights') or {}
                info['weights'] = {
                    'model_path': weights.get('model_path'),
                    'model_sha256': weights.get('model_sha256'),
                    'buffer_path': weights.get('buffer_path'),
                    'buffer_sha256': weights.get('buffer_sha256'),
                }

                # –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ winrate –ø–æ —ç–ø–∏–∑–æ–¥–∞–º
                def _sanitize_sequence(seq):
                    if not isinstance(seq, (list, tuple)):
                        return []
                    clean = []
                    for value in seq:
                        if isinstance(value, (int, float)) and value == value:
                            clean.append(float(value))
                    return clean

                episode_winrates = _sanitize_sequence(results.get('episode_winrates'))
                best_winrate = results.get('best_winrate')
                if best_winrate is None and episode_winrates:
                    best_winrate = max(episode_winrates)
                info['best_winrate'] = best_winrate
                if episode_winrates:
                    info['episode_winrate_summary'] = {
                        'count': len(episode_winrates),
                        'last': episode_winrates[-1],
                        'best': max(episode_winrates),
                        'avg': sum(episode_winrates) / len(episode_winrates),
                    }

                validation_rewards = _sanitize_sequence(results.get('validation_rewards'))
                if validation_rewards:
                    info['validation_summary'] = {
                        'count': len(validation_rewards),
                        'last': validation_rewards[-1],
                        'best': max(validation_rewards),
                        'avg': sum(validation_rewards) / len(validation_rewards),
                    }

            except Exception as e:
                app.logger.warning(f"get_result_model_info: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å train_file {train_file}: {e}")
                app.logger.warning(f"get_result_model_info: –ü—É—Ç—å –∫ train_file: {train_file.resolve()}")

        return jsonify(info)
    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ –≤ get_result_model_info: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

# –ù–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
@app.route('/parser', methods=['POST'])
def parser():
    results = []
    symbol = 'BTCUSDT'
    interval = '5m'
    desired_candles = 100000
    csv_file_path = None

    try:
        # 1. –í—ã–∑—ã–≤–∞–µ–º –≤–Ω–µ—à–Ω—é—é —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞–µ—Ç CSV —Å 100 000 —Å–≤–µ—á–∞–º–∏
        csv_file_path = parser_download_and_combine_with_library(
            symbol='BTCUSDT',
            interval=interval,
            months_to_fetch=12, # –≠—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è parser_download_and_combine_with_library
            desired_candles=desired_candles
        )
        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω ‚Äî –Ω–µ –ø—ã—Ç–∞–µ–º—Å—è —á–∏—Ç–∞—Ç—å/–∑–∞–≥—Ä—É–∂–∞—Ç—å
        try:
            import os as _os
            if not csv_file_path or not _os.path.exists(csv_file_path):
                results.append({"status": "warning", "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ CSV-—Ñ–∞–π–ª–æ–≤ (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ –¥–∞–ª–∞ –¥–∞–Ω–Ω—ã—Ö)."})
                response = {'status': '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω', 'results': results}
                return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')
        except Exception:
            pass
        results.append({"status": "success", "message": f"CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {csv_file_path}"})

        # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —ç—Ç–∏ 100 000 —Å–≤–µ—á–µ–π –∏–∑ CSV –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î
        loaded_count = load_latest_candles_from_csv_to_db(
            file_path=csv_file_path,
            symbol_name=symbol,
            timeframe=interval
        )
        if loaded_count > 0:
            results.append({"status": "success", "message": f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} —Å–≤–µ—á–µ–π –∏–∑ CSV –≤ –ë–î."})
        else:
            results.append({"status": "warning", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ—á–∏ –∏–∑ CSV –≤ –ë–î."})

    except Exception as e:
        results.append({"status": "error", "message": f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}"})

    response = {'status': '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω', 'results': results}
    return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')

# –ù–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã–º–∏
@app.route('/data', methods=['GET'])
def data_page():
    return render_template('data.html')


@app.route('/models')
def models_page():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏"""
    return render_template('models.html')

@app.route('/create_model_version', methods=['POST'])
def create_model_version():
    """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º ID"""
    import shutil
    import uuid
    from datetime import datetime
    from pathlib import Path
    import traceback
    
    try:
        # –ß–∏—Ç–∞–µ–º —Å–∏–º–≤–æ–ª –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        try:
            data = request.get_json(silent=True) or {}
        except Exception:
            data = {}
        requested_symbol = (data.get('symbol') or '').strip()
        requested_file = (data.get('file') or '').strip()
        requested_ensemble = (data.get('ensemble') or 'ensemble-a').strip() or 'ensemble-a'
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID (4 —Å–∏–º–≤–æ–ª–∞)
        model_id = str(uuid.uuid4())[:4].upper()
        
        # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–ø–∫—É result/ –∏ —Å–∏–º–≤–æ–ª (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω)
        result_dir = Path('result')
        if not result_dir.exists():
            return jsonify({
                "success": False,
                "error": "–ü–∞–ø–∫–∞ result –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ."
            })
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º base_code (—Å–∏–º–≤–æ–ª—å–Ω—ã–π –ø—Ä–µ—Ñ–∏–∫—Å)
        def normalize_symbol(sym: str) -> str:
            if not sym:
                return ''
            s = sym.upper().replace('/', '')
            for suffix in ["USDT", "USD", "USDC", "BUSD", "USDP"]:
                if s.endswith(suffix):
                    s = s[:-len(suffix)]
                    break
            s = s.lower()
            if s in ("–º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–∞", "multi", "multicrypto"):
                s = "multi"
            return s
        
        base_code = normalize_symbol(requested_symbol)
        
        selected_result_file = None
        selected_model_file = None
        selected_replay_file = None
        run_dir_path = None
        # 1) –ï—Å–ª–∏ —Ñ—Ä–æ–Ω—Ç –ø—Ä–∏—Å–ª–∞–ª —è–≤–Ω—ã–π —Ñ–∞–π–ª ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if requested_file:
            from pathlib import Path as _Path
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–µ—à–∏ (Windows/Unix)
            req_norm = requested_file.replace('\\', '/')
            safe_path = _Path(req_norm)
            result_dir_abs = result_dir.resolve()

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç —Å —É—á—ë—Ç–æ–º —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ñ–æ—Ä–º–∞—Ç–∞ –ø—É—Ç–∏
            if safe_path.is_absolute():
                candidate = safe_path
            else:
                # –ï—Å–ª–∏ –ø—É—Ç—å —É–∂–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 'result/'
                if safe_path.parts and safe_path.parts[0].lower() == result_dir.name.lower():
                    candidate = _Path(req_norm)
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤–Ω—É—Ç—Ä–∏ result/
                    candidate = result_dir / safe_path.name

            try:
                cand_resolved = candidate.resolve()
            except Exception:
                cand_resolved = candidate

            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏ result/
            try:
                inside_result = str(cand_resolved).lower().startswith(str(result_dir_abs).lower())
            except Exception:
                inside_result = False

            if inside_result and cand_resolved.exists() and cand_resolved.is_file():
                run_dir = cand_resolved.parent
                run_dir_path = run_dir
                name_low = cand_resolved.name.lower()
                # 1) –ï—Å–ª–∏ –≤—ã–±—Ä–∞–ª–∏ –º–æ–¥–µ–ª—å .pth –∏–∑ –ø–∞–ø–∫–∏ run ‚Äî –∏—â–µ–º —Ä—è–¥–æ–º replay –∏ results
                if cand_resolved.suffix == '.pth':
                    # –ø—Ä–∏–Ω–∏–º–∞–µ–º –ª—é–±–æ–π *.pth –∫–∞–∫ –º–æ–¥–µ–ª—å
                    selected_model_file = cand_resolved
                    for f in run_dir.iterdir():
                        if not f.is_file():
                            continue
                        n = f.name.lower()
                        if n.endswith('.pkl') and (n.startswith('replay_buffer') or 'replay' in n):
                            selected_replay_file = selected_replay_file or f
                        elif n.endswith('.pkl') and (n.startswith('train_result') or 'result' in n):
                            selected_result_file = selected_result_file or f
                    # –ï—Å–ª–∏ –∫–∞–∫–∏—Ö-—Ç–æ —Ñ–∞–π–ª–æ–≤ –Ω–µ—Ç ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º, –Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏–º
                    if not (selected_replay_file and selected_result_file):
                        pass
                    try:
                        if selected_result_file is not None:
                            fname = selected_result_file.stem
                            parts = fname.split('_', 2)
                            if len(parts) >= 3:
                                base_code = parts[2].lower()
                    except Exception:
                        pass
                # 2) –ï—Å–ª–∏ –≤—ã–±—Ä–∞–ª–∏ train_result_*.pkl ‚Äî –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –∏—â–µ–º —Ä—è–¥–æ–º .pth –∏ replay
                elif cand_resolved.suffix == '.pkl' and name_low.startswith('train_result_'):
                    selected_result_file = cand_resolved
                    for f in run_dir.iterdir():
                        if not f.is_file():
                            continue
                        n = f.name.lower()
                        if n.endswith('.pth'):
                            selected_model_file = selected_model_file or f
                        elif n.endswith('.pkl') and (n.startswith('replay_buffer') or 'replay' in n):
                            selected_replay_file = selected_replay_file or f
                    if not selected_model_file:
                        return jsonify({
                            "success": False,
                            "error": "–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å *.pth —Ä—è–¥–æ–º —Å —Ñ–∞–π–ª–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
                        })
                    try:
                        fname = selected_result_file.stem
                        parts = fname.split('_', 2)
                        if len(parts) >= 3:
                            base_code = parts[2].lower()
                    except Exception:
                        pass
                else:
                    return jsonify({
                        "success": False,
                        "error": "–û–∂–∏–¥–∞–ª—Å—è .pth –∏–ª–∏ train_result_*.pkl –≤–Ω—É—Ç—Ä–∏ result/"
                    })
            else:
                return jsonify({
                    "success": False,
                    "error": "–ù–µ–≤–µ—Ä–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–Ω—É—Ç—Ä–∏ result/"
                })
        elif base_code:
            # –ò—â–µ–º —Ç–æ—á–Ω—ã–π train_result_<base_code>.pkl
            candidate = result_dir / f"train_result_{base_code}.pkl"
            if candidate.exists():
                selected_result_file = candidate
            else:
                return jsonify({
                    "success": False,
                    "error": f"–§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å–∏–º–≤–æ–ª–∞ {base_code} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ result/"
                })
        else:
            # Fallback: –±–µ—Ä—ë–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π train_result_*.pkl
            result_files = list(result_dir.glob('train_result_*.pkl'))
            if not result_files:
                return jsonify({
                    "success": False,
                    "error": "–§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ result/"
                })
            selected_result_file = max(result_files, key=lambda x: x.stat().st_mtime)
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Å–∏–º–≤–æ–ª –∏–∑ –∏–º–µ–Ω–∏
            try:
                fname = selected_result_file.stem  # train_result_<code>
                parts = fname.split('_', 2)
                if len(parts) >= 3:
                    base_code = parts[2].lower()
            except Exception:
                pass

        if not base_code:
            base_code = "model"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        if selected_model_file and selected_replay_file and selected_result_file:
            model_file = selected_model_file
            replay_file = selected_replay_file
        else:
            model_file = result_dir / f'dqn_model_{base_code}.pth'
            replay_file = result_dir / f'replay_buffer_{base_code}.pkl'
        
        if not model_file.exists():
            return jsonify({
                "success": False,
                "error": f"–§–∞–π–ª {model_file.name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ result/"
            })
        # replay –∏ results –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É models/<symbol>/<ensemble>/vN
        named_id = f"{base_code}_{model_id}"
        try:
            from datetime import datetime as _dt
            from pathlib import Path as _Path
            import json as _json

            models_root = _Path('models')
            models_root.mkdir(exist_ok=True)

            # –°–∏–º–≤–æ–ª –ø–∞–ø–∫–∏ –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ (btc, bnb, ton)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–º–≤–æ–ª –∏–∑ –∫–æ–¥–∞ (–ø—Ä–µ—Ñ–∏–∫—Å –¥–æ –ø–µ—Ä–≤–æ–≥–æ '_')
            try:
                symbol_base = (base_code.split('_', 1)[0] or base_code).lower()
            except Exception:
                symbol_base = base_code.lower()
            symbol_dir = models_root / symbol_base
            symbol_dir.mkdir(exist_ok=True)

            # Ensemble –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –≤ payload, –∏–Ω–∞—á–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'ensemble-a'
            ensemble_name = (data.get('ensemble') or 'ensemble-a').strip() or 'ensemble-a'
            ensemble_dir = symbol_dir / ensemble_name
            ensemble_dir.mkdir(exist_ok=True)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–π –Ω–æ–º–µ—Ä –≤–µ—Ä—Å–∏–∏ vN
            existing_versions = []
            for p in ensemble_dir.iterdir():
                try:
                    if p.is_dir() and p.name.startswith('v'):
                        n = int(p.name[1:])
                        existing_versions.append(n)
                except Exception:
                    pass
            next_num = (max(existing_versions) + 1) if existing_versions else 1
            version_name = f'v{next_num}'
            version_dir = ensemble_dir / version_name
            version_dir.mkdir(exist_ok=False)
            
            # –ö–æ–ø–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤–µ—Ä—Å–∏–∏ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤)
            ver_model = version_dir / model_file.name
            ver_replay = version_dir / (replay_file.name if replay_file.exists() else 'replay_buffer.pkl')
            ver_result = version_dir / (selected_result_file.name if (selected_result_file and selected_result_file.exists()) else 'train_result.pkl')
            shutil.copy2(model_file, ver_model)
            try:
                if replay_file.exists():
                    shutil.copy2(replay_file, ver_replay)
            except Exception:
                pass
            try:
                if selected_result_file and selected_result_file.exists():
                    shutil.copy2(selected_result_file, ver_result)
            except Exception:
                pass
            
            # –ü–∏—à–µ–º manifest.yaml (–±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç PyYAML)
            manifest_path = version_dir / 'manifest.yaml'
            try:
                # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                stats_brief = {}
                if ver_result.exists():
                    try:
                        import pickle as _pickle
                        with open(ver_result, 'rb') as _f:
                            _res = _pickle.load(_f)
                            if isinstance(_res, dict) and 'final_stats' in _res:
                                stats_brief = _res['final_stats'] or {}
                    except Exception:
                        pass
                created_ts = _dt.utcnow().isoformat()
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º run_id –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –æ–Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω–∞
                manifest_id = (str(run_dir_path.name) if run_dir_path is not None else named_id)
                yaml_text = (
                    'id: "' + manifest_id + '"\n'
                    'symbol: "' + base_code.lower() + '"\n'
                    'ensemble: "' + ensemble_name + '"\n'
                    'version: "' + version_name + '"\n'
                    'created_at: "' + created_ts + '"\n'
                    'run_id: "' + manifest_id + '"\n'
                    + (('source_run_path: "' + str(run_dir_path).replace('\\','/') + '"\n') if run_dir_path is not None else '')
                    + 'files:\n'
                    '  model: "' + ver_model.name + '"\n'
                    '  replay: "' + ver_replay.name + '"\n'
                    '  results: "' + ver_result.name + '"\n'
                    'stats:\n' + ''.join([
                        f"  {k}: {v}\n" for k, v in (stats_brief.items() if isinstance(stats_brief, dict) else [])
                    ])
                )
                with open(manifest_path, 'w', encoding='utf-8') as mf:
                    mf.write(yaml_text)
            except Exception:
                pass

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–∏–º–ª–∏–Ω–∫ current -> vN (–µ—Å–ª–∏ –Ω–µ —É–¥–∞—ë—Ç—Å—è ‚Äî —Å–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª-—É–∫–∞–∑–∞—Ç–µ–ª—å)
            current_link = ensemble_dir / 'current'
            try:
                if current_link.exists() or current_link.is_symlink():
                    try:
                        if current_link.is_symlink() or current_link.is_file():
                            current_link.unlink()
                        elif current_link.is_dir():
                            shutil.rmtree(current_link)
                    except Exception:
                        pass
                os.symlink(version_name, current_link)
            except Exception:
                # –§–æ–ª–ª–±–µ–∫: –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∏–º—è –≤–µ—Ä—Å–∏–∏ –≤ —Ñ–∞–π–ª
                try:
                    with open(current_link, 'w', encoding='utf-8') as fcur:
                        fcur.write(version_name)
                except Exception:
                    pass
        except Exception:
            # –ù–µ –≤–∞–ª–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π, –µ—Å–ª–∏ models/ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
            pass
        
        return jsonify({
            "success": True,
            "model_id": (run_dir_path.name if run_dir_path is not None else named_id),
            "files": [
                ver_model.name,
                ver_replay.name if ver_replay.exists() else None,
                ver_result.name if ver_result.exists() else None
            ]
        })
        
    except Exception as e:
        print("[create_model_version] ERROR:\n" + traceback.format_exc())
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/get_models_list')
def get_models_list():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    from pathlib import Path
    import pickle
    from datetime import datetime
    
    try:
        models: list = []

        # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É models/

        # 2) –ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: models/<symbol>/<ensemble>/vN
        models_root = Path('models')
        if models_root.exists():
            for symbol_dir in models_root.iterdir():
                if not symbol_dir.is_dir():
                    continue
                for ensemble_dir in symbol_dir.iterdir():
                    if not ensemble_dir.is_dir():
                        continue
                    for version_dir in ensemble_dir.iterdir():
                        if not version_dir.is_dir() or not version_dir.name.startswith('v'):
                            continue
                        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
                        model_files = list(version_dir.glob('dqn_model_*.pth'))
                        replay_files = list(version_dir.glob('replay_buffer_*.pkl'))
                        result_files = list(version_dir.glob('train_result_*.pkl'))
                        if not model_files or not replay_files or not result_files:
                            continue
                        model_file = model_files[0]
                        replay_file = replay_files[0]
                        result_file = result_files[0]
            model_id = model_file.stem.replace('dqn_model_', '')
            model_size = f"{model_file.stat().st_size / 1024 / 1024:.1f} MB"
            replay_size = f"{replay_file.stat().st_size / 1024 / 1024:.1f} MB"
            result_size = f"{result_file.stat().st_size / 1024:.1f} KB"
            creation_time = datetime.fromtimestamp(model_file.stat().st_ctime)
            date_str = creation_time.strftime('%d.%m.%Y %H:%M')
            stats = {}
            try:
                with open(result_file, 'rb') as f:
                    results = pickle.load(f)
                    if isinstance(results, dict) and 'final_stats' in results:
                        stats = results['final_stats']
            except Exception:                                          
                pass
            models.append({
                "id": model_id,
                "date": date_str,
                "files": {
                                "model": model_file.name,
                    "model_size": model_size,
                                "replay": replay_file.name,
                    "replay_size": replay_size,
                                "results": result_file.name,
                    "results_size": result_size
                },
                "stats": stats
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        models.sort(key=lambda x: x['date'], reverse=True)
        
        return jsonify({
            "success": True,
            "models": models
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
        
@app.route('/list_ensembles')
def list_ensembles():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∞–Ω—Å–∞–º–±–ª–µ–π –∏ –≤–µ—Ä—Å–∏–π –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.
    Query params: symbol=BTCUSDT (–∏–ª–∏ btc)
    """
    try:
        symbol = (request.args.get('symbol') or '').strip()
        if not symbol:
            return jsonify({"success": False, "error": "symbol –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω"}), 400
        s = symbol.upper().replace('/', '')
        if s.endswith('USDT'):
            s = s[:-4]
        base_code = s.lower()

        from pathlib import Path
        import pickle as _pickle
        root = Path('models') / base_code
        if not root.exists():
            return jsonify({"success": True, "ensembles": {}})

        ensembles = {}
        for ens_dir in root.iterdir():
            if not ens_dir.is_dir():
                continue
            versions = []
            current = None
            canary = None
            # –°–æ–±–∏—Ä–∞–µ–º vN
            for vdir in ens_dir.iterdir():
                if vdir.is_dir() and vdir.name.startswith('v'):
                    # –ò—â–µ–º —Ñ–∞–π–ª—ã –∏ manifest
                    files = { 'model': None, 'replay': None, 'results': None }
                    # –§–æ–ª–±—ç–∫–∏, –µ—Å–ª–∏ –∏–º–µ–Ω–∞ –Ω–µ –ø–æ —à–∞–±–ª–æ–Ω—É
                    fallback_model = None
                    fallback_replay = None
                    fallback_results = None
                    manifest = None
                    stats = {}
                    for f in vdir.iterdir():
                        if f.name.startswith('dqn_model_') and f.suffix == '.pth':
                            files['model'] = f.name
                        elif f.name.startswith('replay_buffer_') and f.suffix == '.pkl':
                            files['replay'] = f.name
                        elif f.name.startswith('train_result_') and f.suffix == '.pkl':
                            files['results'] = f.name
                        elif f.name == 'manifest.yaml':
                            manifest = f.name
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ–ª–±—ç–∫–∏
                        elif f.suffix == '.pth' and fallback_model is None:
                            fallback_model = f.name
                        elif f.suffix == '.pkl':
                            n = f.name.lower()
                            if ('replay' in n) and fallback_replay is None:
                                fallback_replay = f.name
                            if (('train_result' in n) or ('result' in n)) and fallback_results is None:
                                fallback_results = f.name
                    # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ train_result_*.pkl
                    try:
                        # –í—ã–±–æ—Ä —Ñ–∞–π–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º —Ñ–æ–ª–±—ç–∫–æ–≤
                        res_name = files.get('results') or fallback_results
                        if res_name:
                            _res_path = vdir / res_name
                            if _res_path.exists():
                                with open(_res_path, 'rb') as _f:
                                    _res = _pickle.load(_f)
                                    if isinstance(_res, dict) and 'final_stats' in _res:
                                        stats = _res['final_stats'] or {}
                    except Exception:
                        stats = {}
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ–ª–±—ç–∫–∏, –µ—Å–ª–∏ —Å—Ç—Ä–æ–≥–∏–µ –∏–º–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
                    if files['model'] is None and fallback_model is not None:
                        files['model'] = fallback_model
                    if files['replay'] is None and fallback_replay is not None:
                        files['replay'] = fallback_replay
                    if files['results'] is None and fallback_results is not None:
                        files['results'] = fallback_results
                    
                    # –ß–∏—Ç–∞–µ–º ID –∏–∑ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                    manifest_id = None
                    if manifest:
                        try:
                            manifest_path = vdir / manifest
                            if manifest_path.exists():
                                with open(manifest_path, 'r', encoding='utf-8') as mf:
                                    manifest_content = mf.read()
                                    # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å id: "–∑–Ω–∞—á–µ–Ω–∏–µ"
                                    for line in manifest_content.split('\n'):
                                        if line.strip().startswith('id:'):
                                            manifest_id = line.split(':', 1)[1].strip().strip('"\'')
                                            break
                        except Exception:
                            pass
                    
                    versions.append({
                        'version': vdir.name,
                        'files': files,
                        'manifest': manifest,
                        'manifest_id': manifest_id,
                        'stats': stats,
                        'path': str(vdir).replace('\\','/')
                    })
                elif vdir.name == 'current':
                    current = str(vdir).replace('\\','/')
                elif vdir.name == 'canary':
                    canary = str(vdir).replace('\\','/')
            ensembles[ens_dir.name] = {
                'versions': sorted(versions, key=lambda x: int(x['version'][1:]) if x['version'].startswith('v') and x['version'][1:].isdigit() else 0),
                'current': current,
                'canary': canary,
                'path': str(ens_dir).replace('\\','/')
            }

        return jsonify({"success": True, "ensembles": ensembles})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/delete_model', methods=['POST'])
def delete_model():
    """–£–¥–∞–ª—è–µ—Ç –º–æ–¥–µ–ª—å –∏ –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
    from pathlib import Path
    import os
    
    try:
        data = request.get_json()
        model_id = data.get('model_id')
        
        if not model_id:
            return jsonify({
                "success": False,
                "error": "ID –º–æ–¥–µ–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω"
            })
        
        # –£–¥–∞–ª—è–µ–º –º–æ–¥–µ–ª—å –∏–∑ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã models/
        models_root = Path('models')
        deleted_files = []
        if models_root.exists():
            for symbol_dir in models_root.iterdir():
                if not symbol_dir.is_dir():
                    continue
                for ensemble_dir in symbol_dir.iterdir():
                    if not ensemble_dir.is_dir():
                        continue
                    for version_dir in list(ensemble_dir.iterdir()):
                        if not version_dir.is_dir():
                            continue
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —Ñ–∞–π–ª–∞–º –º–æ–¥–µ–ª–∏
                        for name in [f'dqn_model_{model_id}.pth', f'replay_buffer_{model_id}.pkl', f'train_result_{model_id}.pkl']:
                            fp = version_dir / name
                            if fp.exists():
                                try:
                                    os.remove(fp)
                                    deleted_files.append(str(fp))
                                except Exception:
                                    pass
                        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—É—é –≤–µ—Ä—Å–∏—é
                        try:
                            if version_dir.is_dir() and not any(version_dir.iterdir()):
                                import shutil as _sh
                                _sh.rmtree(version_dir, ignore_errors=True)
                        except Exception:
                            pass
        
        if not deleted_files:
            return jsonify({
                "success": False,
                "error": f"–§–∞–π–ª—ã –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            })
        
        return jsonify({
            "success": True,
            "message": f"–ú–æ–¥–µ–ª—å {model_id} —É–¥–∞–ª–µ–Ω–∞",
            "deleted_files": deleted_files
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/predictions/recent')
def get_recent_predictions():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏"""
    try:
        symbol = request.args.get('symbol')
        action = request.args.get('action')
        limit = int(request.args.get('limit', 50))
        
        # 1) –û—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å: –±–µ—Ä—ë–º –∏–∑ –ë–î
        predictions = get_model_predictions(symbol=symbol, action=action, limit=limit)

        # 2) –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–º–≤–æ–ª–∞ (fallback): BTCUSDT <-> BTC/USDT
        if (not predictions) and symbol:
            try:
                alt = None
                if '/' in symbol:
                    alt = symbol.replace('/', '')
                else:
                    # –≤—Å—Ç–∞–≤–∏–º —Å–ª—ç—à –ø–µ—Ä–µ–¥ USDT/USDC/FDUSD/DAI –∏ —Ç.–ø. (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é USDT)
                    if symbol.upper().endswith('USDT'):
                        alt = symbol[:-4] + '/' + symbol[-4:]
                if alt and alt != symbol:
                    alt_predictions = get_model_predictions(symbol=alt, action=action, limit=limit)
                    if alt_predictions:
                        predictions = alt_predictions
                        symbol = alt  # —Å–æ–æ–±—â–∏–º –≤ –æ—Ç–≤–µ—Ç–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Å–∏–º–≤–æ–ª
            except Exception:
                pass
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        predictions_data = []
        for prediction in predictions or []:
            try:
                q_values = json.loads(prediction.q_values) if prediction.q_values else []
                market_conditions = json.loads(prediction.market_conditions) if prediction.market_conditions else {}
            except:
                q_values = []
                market_conditions = {}
            
            prediction_data = {
                'id': prediction.id,
                'timestamp': prediction.timestamp.isoformat() if prediction.timestamp else None,
                'symbol': prediction.symbol,
                'action': prediction.action,
                'q_values': q_values,
                'current_price': prediction.current_price,
                'position_status': prediction.position_status,
                'confidence': prediction.confidence,
                'model_path': prediction.model_path,
                'market_conditions': market_conditions,
                'created_at': prediction.created_at.isoformat() if prediction.created_at else None
            }
            predictions_data.append(prediction_data)
        
        # 3) –ï—Å–ª–∏ –ë–î –ø—É—Å—Ç–∞ ‚Äî –æ—Ç–¥–∞—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–Ω–∏–º–æ–∫ –∏–∑ Redis (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã celery-trade)
        if len(predictions_data) == 0:
            try:
                from utils.redis_utils import get_redis_client as _get_rc
                _rc = _get_rc()
                keys = sorted(_rc.keys('trading:latest_result_*') or [], reverse=True)
                for k in keys:
                    try:
                        raw = _rc.get(k)
                        if not raw:
                            continue
                        snap = json.loads(raw)
                        preds = snap.get('predictions') or []
                        if not preds:
                            continue
                        ts = snap.get('timestamp')
                        # –í —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö —Å–∏–º–≤–æ–ª –Ω–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è ‚Äî –ø–æ–¥—Å—Ç–∞–≤–∏–º –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π
                        sym_for_resp = symbol or (snap.get('symbols') or [None])[0]
                        for p in preds[:limit]:
                            predictions_data.append({
                                'id': None,
                                'timestamp': ts,
                                'symbol': sym_for_resp,
                                'action': p.get('action'),
                                'q_values': p.get('q_values') or [],
                                'current_price': None,
                                'position_status': None,
                                'confidence': p.get('confidence'),
                                'model_path': p.get('model_path'),
                                'market_conditions': {},
                                'created_at': ts
                            })
                        if predictions_data:
                            break
                    except Exception:
                        continue
            except Exception:
                pass

        return jsonify({
            'success': True,
            'predictions': predictions_data,
            'total_predictions': len(predictions_data)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/predictions/statistics')
def get_prediction_statistics_api():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏"""
    try:
        symbol = request.args.get('symbol')
        stats = get_prediction_statistics(symbol=symbol)
        
        return jsonify({
            'success': True,
            'statistics': stats
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# =============================================================

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ Flask —Å–µ—Ä–≤–µ—Ä–∞
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5050))  # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    debug_mode = os.environ.get("FLASK_DEBUG", "False").lower() == "true"
    print(f"üöÄ –ó–∞–ø—É—Å–∫–∞—é Flask —Å–µ—Ä–≤–µ—Ä –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    print(f"üåê –û—Ç–∫—Ä–æ–π—Ç–µ: http://localhost:{port}")
    print(f"üîß Debug —Ä–µ–∂–∏–º: {'–í–ö–õ–Æ–ß–ï–ù' if debug_mode else '–û–¢–ö–õ–Æ–ß–ï–ù'}")
    
    # –£–±–∏—Ä–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    # init_trading_agent()
    
    app.run(host="0.0.0.0", port=port, debug=debug_mode)
