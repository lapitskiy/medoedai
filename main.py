#!/usr/bin/env python3
"""
üöÄ MedoedAI - Flask –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è DQN —Ç–æ—Ä–≥–æ–≤—ã–º –±–æ—Ç–æ–º

–ó–∞–ø—É—Å–∫:
    python main.py              # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫
    flask run                   # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
    FLASK_APP=main.py flask run # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
"""

import requests
from flask import Flask, request, jsonify, render_template
from flask import redirect, url_for

import redis

from tasks.celery_tasks import celery
from routes.bybit import bybit_bp
from routes.trading import trading_bp
from routes.models_admin import models_admin_bp
from utils.redis_utils import get_redis_client, clear_redis_on_startup

"""get_redis_client –±–µ—Ä—ë–º –∏–∑ utils.redis_utils"""

 
from celery.result import AsyncResult

import os
import re
from tasks.celery_tasks import search_lstm_task, train_dqn, train_dqn_multi_crypto, trade_step, start_trading_task, train_dqn_symbol
from utils.db_utils import load_latest_candles_from_csv_to_db
from utils.parser import parser_download_and_combine_with_library
from utils.trade_utils import (
    get_recent_trades, 
    get_trade_statistics, 
    get_trades_by_symbol,
    get_model_predictions, 
    get_prediction_statistics
)

import logging
from flask import Response
import json

import time

import glob
import os

import docker

from tasks.celery_tasks import start_trading_task
from utils.celery_utils import ensure_symbol_worker

logging.basicConfig(level=logging.INFO)

# –°–æ–∑–¥–∞–µ–º Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = Flask(__name__)
app.register_blueprint(bybit_bp)
app.register_blueprint(trading_bp)
app.register_blueprint(models_admin_bp)
from routes.clean import clean_bp
app.register_blueprint(clean_bp)

# –§—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ Redis –≤—ã–Ω–µ—Å–µ–Ω–∞ –≤ utils.redis_utils.clear_redis_on_startup

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Redis –∫–ª–∏–µ–Ω—Ç –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏ (decode_responses=True)
redis_client = get_redis_client()

@app.before_request
def log_request_info():
    logging.info(f"Request from {request.remote_addr}: {request.method} {request.path}")
    logging.info("Headers: %s", dict(request.headers))  # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏

@app.route("/")
def index():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á Celery –∏ –∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
    tasks = []

    # 1) –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ ui:tasks
    try:
        recent_ids = redis_client.lrange("ui:tasks", 0, 49) or []
        for raw_id in recent_ids:
            try:
                task_id = raw_id.decode("utf-8")
            except Exception:
                task_id = str(raw_id)
            task = AsyncResult(task_id, app=celery)
            tasks.append({
                "task_id": task_id,
                "state": task.state,
                "result": task.result if task.successful() else None
            })
    except Exception as _e:
        app.logger.error(f"/ index: –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è ui:tasks: {_e}")

    # 2) Fallback: —Å–∫–∞–Ω–∏—Ä—É–µ–º backend –ø–æ –∫–ª—é—á–∞–º (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ –¥–ª—è PENDING)
    if not tasks:
        try:
            task_keys = redis_client.keys("celery-task-meta-*") or []
            for key in task_keys:
                task_id = key.decode("utf-8").replace("celery-task-meta-", "")
                task = AsyncResult(task_id, app=celery)
                tasks.append({
                    "task_id": task_id,
                    "state": task.state,
                    "result": task.result if task.successful() else None
                })
        except Exception as _e:
            app.logger.error(f"/ index: –æ—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è backend: {_e}")

    return render_template("index.html", tasks=tasks)


@app.route("/task-start-search", methods=["POST"])
def start_task():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∑–∞–¥–∞—á—É Celery –∏ –¥–µ–ª–∞–µ—Ç —Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
    query = request.form.get("query", "")  # –ë–µ—Ä—ë–º query –∏–∑ —Ñ–æ—Ä–º—ã

    if not query:
        return redirect(url_for("index"))  # –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –≥–ª–∞–≤–Ω—É—é

    task = search_lstm_task.apply_async(args=[query])  # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ Celery

    return redirect(url_for("index"))  # –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –≥–ª–∞–≤–Ω—É—é


@app.route("/task-status/<task_id>", methods=["GET"])
def get_task_status(task_id):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –ø–æ task_id"""
    task = AsyncResult(task_id, app=celery)

    if task.state == "PENDING":
        response = {"state": "PENDING", "status": "–ó–∞–¥–∞—á–∞ –≤ –æ—á–µ—Ä–µ–¥–∏"}
    elif task.state == "IN_PROGRESS":
        response = {"state": "IN_PROGRESS", "status": "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è", "progress": task.info}
    elif task.state == "SUCCESS":
        response = {"state": "SUCCESS", "status": "–ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞", "result": task.result}
    elif task.state == "FAILURE":
        response = {"state": "FAILURE", "status": "–û—à–∏–±–∫–∞", "error": str(task.info)}
    else:
        response = {"state": task.state, "status": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"}

    return jsonify(response)


@app.route("/start-search", methods=["POST"])
def start_parameter_search():
    try:
        response = requests.post(
            "http://parameter-search:5052/run-search",
            json={"query": "some_value"},  # –ó–¥–µ—Å—å –ø–µ—Ä–µ–¥–∞—ë–º –Ω—É–∂–Ω—ã–π query
            headers={"Content-Type": "application/json"}
        )
        return response.json()
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/train_dqn', methods=['POST'])
def train():
    task = train_dqn.apply_async(queue="train")
    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –∏–∑ fetch/XHR ‚Äî –æ—Ç–≤–µ—á–∞–µ–º JSON, –∏–Ω–∞—á–µ —Ä–µ–¥–∏—Ä–µ–∫—Ç–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é
    try:
        wants_json = request.is_json or 'application/json' in (request.headers.get('Accept') or '')
    except Exception:
        wants_json = False
    if wants_json:
        return jsonify({"success": True, "task_id": task.id})
    return redirect(url_for("index"))

@app.route('/train_dqn_multi_crypto', methods=['POST'])
def train_multi_crypto():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ DQN"""
    task = train_dqn_multi_crypto.apply_async(queue="train")
    try:
        wants_json = request.is_json or 'application/json' in (request.headers.get('Accept') or '')
    except Exception:
        wants_json = False
    if wants_json:
        return jsonify({"success": True, "task_id": task.id})
    return redirect(url_for("index"))

@app.route('/train_dqn_symbol', methods=['POST'])
def train_dqn_symbol_route():
    data = request.get_json(silent=True) or {}
    symbol = data.get('symbol') or request.form.get('symbol') or 'BTCUSDT'
    # –≠–ø–∏–∑–æ–¥—ã: –∏–∑ —Ñ–æ—Ä–º—ã/JSON, fallback None (—á—Ç–æ–± Celery –≤–∑—è–ª –∏–∑ ENV)
    episodes_str = data.get('episodes') or request.form.get('episodes')
    episodes = None
    try:
        if episodes_str is not None and str(episodes_str).strip() != '':
            episodes = int(episodes_str)
    except Exception:
        episodes = None
    # Seed: –∏–∑ —Ñ–æ—Ä–º—ã/JSON; –µ—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –Ω–∞ –±—ç–∫–µ–Ω–¥–µ
    seed_raw = (data.get('seed') or request.form.get('seed') or '').strip()
    seed = None
    try:
        if seed_raw != '':
            seed = int(seed_raw)
    except Exception:
        seed = None
    # –û—á–µ—Ä–µ–¥—å per-symbol
    queue_name = f"train_{symbol.lower()}"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ–π –∑–∞–¥–∞—á–∏ per-symbol –≤ Redis + Celery
    running_key = f"celery:train:task:{symbol.upper()}"
    try:
        existing_task_id = redis_client.get(running_key)
        if existing_task_id:
            try:
                existing_task_id = existing_task_id.decode('utf-8')
            except Exception:
                existing_task_id = str(existing_task_id)
            ar = AsyncResult(existing_task_id, app=celery)
            if ar.state in ("PENDING", "STARTED", "RETRY", "IN_PROGRESS"):
                app.logger.info(f"train for {symbol} already running: {existing_task_id} state={ar.state}")
                # –ï—Å–ª–∏ —ç—Ç–æ fetch ‚Äî –≤–µ—Ä–Ω—ë–º JSON –±–µ–∑ —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞
                wants_json = request.is_json or 'application/json' in (request.headers.get('Accept') or '')
                if wants_json:
                    return jsonify({
                        "success": False,
                        "error": f"training for {symbol} already running",
                        "task_id": existing_task_id,
                        "state": ar.state
                    })
                return redirect(url_for("index"))
    except Exception as _e:
        app.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—É—é –∑–∞–¥–∞—á—É –¥–ª—è {symbol}: {_e}")

    # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ–±—â—É—é –æ—á–µ—Ä–µ–¥—å 'train' (—Å–ª—É—à–∞–µ—Ç—Å—è –±–∞–∑–æ–≤—ã–º –≤–æ—Ä–∫–µ—Ä–æ–º)
    # –ï—Å–ª–∏ seed –Ω–µ —É–∫–∞–∑–∞–Ω ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ web –∏ –ø–µ—Ä–µ–¥–∞–¥–∏–º –≤ Celery
    if seed is None:
        import random as _rnd
        seed = _rnd.randint(1, 2**31 - 1)
        app.logger.info(f"[train_dqn_symbol] generated random seed={seed}")

    task = train_dqn_symbol.apply_async(args=[symbol, episodes, seed], queue="train")
    app.logger.info(f"/train_dqn_symbol queued symbol={symbol} queue=train task_id={task.id}")
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º task_id –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –≥–ª–∞–≤–Ω–æ–π –∏ –æ—Ç–º–µ—Ç–∫—É per-symbol
    try:
        redis_client.lrem("ui:tasks", 0, task.id)  # —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        redis_client.lpush("ui:tasks", task.id)
        redis_client.ltrim("ui:tasks", 0, 49)     # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫
        redis_client.setex(running_key, 24 * 3600, task.id)
    except Exception as _e:
        app.logger.error(f"/train_dqn_symbol: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å ui:tasks: {_e}")
    # –û—Ç–≤–µ—Ç –¥–ª—è fetch/XHR ‚Äî JSON; –¥–ª—è —Ñ–æ—Ä–º ‚Äî —Ä–µ–¥–∏—Ä–µ–∫—Ç
    wants_json = request.is_json or 'application/json' in (request.headers.get('Accept') or '')
    if wants_json:
        return jsonify({
            "success": True,
            "task_id": task.id,
            "symbol": symbol,
            "episodes": episodes,
            "seed": seed
        })
    return redirect(url_for("index"))


@app.route('/continue_training', methods=['POST'])
def continue_training_route():
    """–ü—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –≤ result (dqn_model_*.pth, replay_buffer_*.pkl).

    Body: { file: 'result/train_result_<code>.pkl', episodes?: int }
    –ü–æ –∏–º–µ–Ω–∏ train_result_* –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è <code>, –∑–∞—Ç–µ–º –±–µ—Ä—É—Ç—Å—è dqn_model_<code>.pth –∏ replay_buffer_<code>.pkl.
    """
    try:
        data = request.get_json(silent=True) or {}
        requested_file = (data.get('file') or data.get('model') or '').strip()
        episodes_str = data.get('episodes') or request.form.get('episodes')
        episodes = None
        try:
            if episodes_str is not None and str(episodes_str).strip() != '':
                episodes = int(episodes_str)
        except Exception:
            episodes = None
        # –†–∞–∑–æ–±—Ä–∞—Ç—å seed; –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∑–∂–µ
        seed_raw = (data.get('seed') or request.form.get('seed') or '').strip()
        seed = None
        try:
            if seed_raw != '':
                seed = int(seed_raw)
        except Exception:
            seed = None

        from pathlib import Path as _Path
        result_dir = _Path('result')
        if not result_dir.exists():
            return jsonify({"success": False, "error": "–ü–∞–ø–∫–∞ result –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}), 400

        if not requested_file:
            return jsonify({"success": False, "error": "–ù–µ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–µ—Å–æ–≤ dqn_model_*.pth"}), 400

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç—å
        req_norm = requested_file.replace('\\', '/')
        safe_path = _Path(req_norm)
        if not safe_path.is_absolute():
            if not (safe_path.parts and safe_path.parts[0].lower() == result_dir.name.lower()):
                safe_path = result_dir / safe_path.name
        try:
            cand_resolved = safe_path.resolve()
        except Exception:
            cand_resolved = safe_path
        inside_result = str(cand_resolved).lower().startswith(str(result_dir.resolve()).lower())

        if not (inside_result and cand_resolved.exists() and cand_resolved.is_file()):
            return jsonify({"success": False, "error": "–ù–µ–≤–µ—Ä–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"}), 400

        model_file = None
        replay_file = None
        code = None
        symbol_from_path = None

        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ç—Ä—ë—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤: train_result_*, dqn_model_* –∏ runs/<run_id>/model.pth
        if cand_resolved.name.startswith('train_result_') and cand_resolved.suffix == '.pkl':
            fname = cand_resolved.stem  # train_result_<code>
            parts = fname.split('_', 2)
            if len(parts) < 3:
                return jsonify({"success": False, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–æ–¥ –º–æ–¥–µ–ª–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"}), 400
            code = parts[2]
            model_file = result_dir / f'dqn_model_{code}.pth'
            replay_file = result_dir / f'replay_buffer_{code}.pkl'
            if not model_file.exists():
                return jsonify({"success": False, "error": f"–§–∞–π–ª {model_file.name} –Ω–µ –Ω–∞–π–¥–µ–Ω"}), 400
            # replay_file –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äì —ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ
        elif cand_resolved.name.startswith('dqn_model_') and cand_resolved.suffix == '.pth':
            fname = cand_resolved.stem  # dqn_model_<code>
            parts = fname.split('_', 2)
            if len(parts) < 3:
                return jsonify({"success": False, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–æ–¥ –º–æ–¥–µ–ª–∏ –∏–∑ –∏–º–µ–Ω–∏ –≤–µ—Å–æ–≤"}), 400
            code = parts[2]
            model_file = cand_resolved
            replay_file = result_dir / f'replay_buffer_{code}.pkl'  # –º–æ–∂–µ—Ç –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å
        elif cand_resolved.name == 'model.pth' and 'runs' in cand_resolved.parts:
            # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç: result/<SYMBOL>/runs/<run_id>/model.pth
            try:
                parts = list(cand_resolved.parts)
                runs_idx = parts.index('runs')
                run_id = parts[runs_idx + 1] if runs_idx + 1 < len(parts) else None
                symbol_from_path = parts[runs_idx - 1] if runs_idx - 1 >= 0 else None
                if not run_id:
                    return jsonify({"success": False, "error": "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø—É—Ç—å –∫ run"}), 400
                code = run_id
                model_file = cand_resolved
                run_dir = cand_resolved.parent
                replay_file = run_dir / 'replay.pkl'
                # train_result –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è
            except Exception:
                return jsonify({"success": False, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—É—Ç—å run"}), 400
        else:
            return jsonify({"success": False, "error": "–û–∂–∏–¥–∞–ª—Å—è —Ñ–∞–π–ª dqn_model_*.pth, train_result_*.pkl –∏–ª–∏ runs/.../model.pth"}), 400

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤–æ–π —Ç–∞—Å–∫ –æ–±—É—á–µ–Ω–∏—è, –ø–µ—Ä–µ–¥–∞–≤ –ø—É—Ç–∏ –≤ ENV (—É–ø—Ä–æ—â–µ–Ω–∏–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–∏–≥–Ω–∞—Ç—É—Ä—ã Celery)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é –æ—á–µ—Ä–µ–¥—å 'train'
        from celery import group
        # –°–æ—Ö—Ä–∞–Ω–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ Redis –Ω–∞ —á–∞—Å
        try:
            redis_client.setex('continue:model_path', 3600, str(model_file))
            if replay_file and os.path.exists(str(replay_file)):
                redis_client.setex('continue:buffer_path', 3600, str(replay_file))
        except Exception:
            pass

        # –¢–∞—Å–∫ train_dqn_symbol –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø—É—Ç–∏, –ø–æ—ç—Ç–æ–º—É –≤—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä–∏–º–µ–Ω–∏–º —Å–∏–º–≤–æ–ª –∏–∑ code –¥–ª—è –¥–∞–Ω–Ω—ã—Ö,
        # –∞ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –≤ v_train_model_optimized –ø–æ —ç—Ç–∏–º –ø—É—Ç—è–º —á–µ—Ä–µ–∑ ENV.
        symbol_guess = None
        try:
            if symbol_from_path:
                symbol_guess = (str(symbol_from_path).upper())
            else:
                symbol_guess = (code.split('_', 1)[0] + 'USDT').upper()
        except Exception:
            symbol_guess = None
        if not symbol_guess:
            symbol_guess = 'BTCUSDT'
        # –ï—Å–ª–∏ seed –Ω–µ —É–∫–∞–∑–∞–Ω ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π
        if seed is None:
            import random as _rnd
            seed = _rnd.randint(1, 2**31 - 1)
            app.logger.info(f"[continue_training] generated random seed={seed}")

        task = train_dqn_symbol.apply_async(args=[symbol_guess, episodes, seed], queue='train')

        # –ü—Ä–æ–∫–∏–Ω–µ–º –ø—É—Ç–∏ —á–µ—Ä–µ–∑ ENV –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –≤–æ—Ä–∫–µ—Ä–∞ (–µ—Å–ª–∏ –æ–Ω —á–∏—Ç–∞–µ—Ç –∏—Ö)
        # –ï—Å–ª–∏ –≤–æ—Ä–∫–µ—Ä –≤ –¥—Ä—É–≥–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º Redis –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ ‚Äî —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤—ã—à–µ.
        try:
            os.environ['CONTINUE_MODEL_PATH'] = str(model_file)
            if replay_file and os.path.exists(str(replay_file)):
                os.environ['CONTINUE_BUFFER_PATH'] = str(replay_file)
        except Exception:
            pass

        # –î–æ–±–∞–≤–∏–º –∑–∞–¥–∞—á—É –≤ UI —Å–ø–∏—Å–æ–∫
        try:
            redis_client.lrem("ui:tasks", 0, task.id)
            redis_client.lpush("ui:tasks", task.id)
            redis_client.ltrim("ui:tasks", 0, 49)
        except Exception:
            pass

        return jsonify({"success": True, "task_id": task.id, "seed": seed})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500




# –ù–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
 

@app.route('/analyze_training_results', methods=['POST'])
def analyze_training_results():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è DQN –º–æ–¥–µ–ª–∏"""
    try:
        # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ runs/*/train_result.pkl)
        results_dir = "result"
        data = request.get_json(silent=True) or {}
        requested_file = (data.get('file') or '').strip()
        selected_file = None
        if requested_file:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—É—Ç—å; –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º Windows-—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
            req = requested_file.replace('\\', '/')
            if not os.path.isabs(req):
                # –ï—Å–ª–∏ —É–∂–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å result/ ‚Äî —Ç—Ä–∞–∫—Ç—É–µ–º –∫–∞–∫ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
                if req.startswith('result/'):
                    cand = os.path.abspath(req)
                else:
                    # –ò–Ω–∞—á–µ —Å—á–∏—Ç–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∫ –∫–∞—Ç–∞–ª–æ–≥—É result/
                    cand = os.path.abspath(os.path.join(results_dir, req))
            else:
                cand = os.path.abspath(req)
            # –ü—Ä–∏–Ω–∏–º–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—É—Ç–∏ –≤–Ω—É—Ç—Ä–∏ result/
            base_path = os.path.abspath(results_dir)
            if cand.startswith(base_path) and os.path.exists(cand):
                selected_file = cand
        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —É–∫–∞–∑–∞–Ω/–Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –∏—â–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç result/<SYMBOL>/runs/*/train_result.pkl
        if not selected_file:
            run_results = []
            if os.path.exists(results_dir):
                for sym in os.listdir(results_dir):
                    rdir = os.path.join(results_dir, sym, 'runs')
                    if not os.path.isdir(rdir):
                        continue
                    for run_id in os.listdir(rdir):
                        p = os.path.join(rdir, run_id, 'train_result.pkl')
                        if os.path.exists(p):
                            run_results.append(p)
            # –§–æ–ª–ª–±–µ–∫ –Ω–∞ —Å—Ç–∞—Ä—ã–π –ø–ª–æ—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç
            flat_results = glob.glob(os.path.join(results_dir, 'train_result_*.pkl'))
            all_candidates = (run_results or []) + (flat_results or [])
            if not all_candidates:
                return jsonify({'status': 'error','message': '–§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.','success': False}), 404
            selected_file = max(all_candidates, key=os.path.getctime)
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∞–Ω–∞–ª–∏–∑–∞
        try:
            from analyze_training_results import analyze_training_results as analyze_func
        except ImportError:
            # –ï—Å–ª–∏ –º–æ–¥—É–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é —Ñ—É–Ω–∫—Ü–∏—é –∞–Ω–∞–ª–∏–∑–∞
            def analyze_func(filename):
                print(f"üìä –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {filename}")
                print("‚ö†Ô∏è –ú–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ matplotlib –∏ numpy.")
                print("üí° –î–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: pip install matplotlib numpy")
                return "–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        try:
            import pickle
            with open(selected_file, 'rb') as f:
                results = pickle.load(f)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± actual_episodes
            if 'actual_episodes' in results:
                actual_episodes = results['actual_episodes']
                planned_episodes = results['episodes']
                
                if actual_episodes < planned_episodes:
                    print(f"‚ö†Ô∏è Early Stopping —Å—Ä–∞–±–æ—Ç–∞–ª! –û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –Ω–∞ {actual_episodes} —ç–ø–∏–∑–æ–¥–µ –∏–∑ {planned_episodes}")
                else:
                    print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é: {actual_episodes} —ç–ø–∏–∑–æ–¥–æ–≤")                    
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ—Ç–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        print(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞: {selected_file}")
        
        # –í—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º stdout –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≤—ã–≤–æ–¥–∞
        import io
        import sys
        from contextlib import redirect_stdout
        
        output = io.StringIO()
        with redirect_stdout(output):
            analyze_func(selected_file)
        
        analysis_output = output.getvalue()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± actual_episodes –≤ –æ—Ç–≤–µ—Ç
        response_data = {
            'status': 'success',
            'message': '–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ',
            'success': True,
            'file_analyzed': selected_file,
            'output': analysis_output,
            'available_files': []
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —ç–ø–∏–∑–æ–¥–∞—Ö –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º episode_winrates_count –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è early stopping
            if 'episode_winrates' in results:
                response_data['episode_winrates_count'] = len(results['episode_winrates'])
                print(f"üîç episode_winrates_count: {response_data['episode_winrates_count']}")
            
            if 'actual_episodes' in results:
                response_data['actual_episodes'] = results['actual_episodes']
                response_data['episodes'] = results['episodes']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ actual_episodes –∏ episode_winrates_count
                if 'episode_winrates_count' in response_data:
                    if response_data['actual_episodes'] != response_data['episode_winrates_count']:
                        print(f"‚ö†Ô∏è –ù–ï–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï: actual_episodes={response_data['actual_episodes']}, episode_winrates_count={response_data['episode_winrates_count']}")
                        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º actual_episodes –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                        response_data['actual_episodes'] = response_data['episode_winrates_count']
                        print(f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: actual_episodes = {response_data['actual_episodes']}")
            else:
                # –ï—Å–ª–∏ actual_episodes –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ –ª–æ–≥–æ–≤
                if 'output' in response_data:
                    output_text = response_data['output']
                    # –ò—â–µ–º Early stopping –≤ –ª–æ–≥–∞—Ö
                    if 'Early stopping triggered after' in output_text:
                        import re
                        early_stopping_match = re.search(r'Early stopping triggered after (\d+) episodes', output_text)
                        if early_stopping_match:
                            actual_episodes = int(early_stopping_match.group(1))
                            # –ò—â–µ–º –ø–ª–∞–Ω–∏—Ä—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤
                            episodes_match = re.search(r'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤: (\d+)', output_text)
                            if episodes_match:
                                planned_episodes = int(episodes_match.group(1))
                                response_data['actual_episodes'] = actual_episodes
                                response_data['episodes'] = planned_episodes
                                print(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ –ª–æ–≥–æ–≤: actual_episodes={actual_episodes}, episodes={planned_episodes}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ actual_episodes: {e}")
        
        return jsonify(response_data)
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}',
            'success': False
        }), 500

@app.route('/list_training_results', methods=['GET'])
def list_training_results():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ result/<SYMBOL>/runs/*/{train_result.pkl, manifest.json}"""
    try:
        base = os.path.join('result')
        if not os.path.exists(base):
            return jsonify({'status': 'error','message': f'–ü–∞–ø–∫–∞ {base} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞','success': False,'files': []}), 404
        items = []
        for sym in sorted(os.listdir(base)):
            sym_dir = os.path.join(base, sym, 'runs')
            if not os.path.isdir(sym_dir):
                continue
            for run_id in os.listdir(sym_dir):
                run_dir = os.path.join(sym_dir, run_id)
                if not os.path.isdir(run_dir):
                    continue
                tr = os.path.join(run_dir, 'train_result.pkl')
                mf = os.path.join(run_dir, 'manifest.json')
                mp = os.path.join(run_dir, 'model.pth')
                if os.path.exists(tr):
                    try:
                        stat = os.stat(tr)
                        manifest = {}
                        try:
                            if os.path.exists(mf):
                                import json as _json
                                manifest = _json.loads(open(mf,'r',encoding='utf-8').read())
                        except Exception:
                            manifest = {}
                        items.append({
                            'symbol': sym,
                            'run_id': run_id,
                            'train_result': tr,
                            'model_path': mp if os.path.exists(mp) else None,
                            'manifest': manifest,
                            'size': stat.st_size,
                            'created': stat.st_ctime,
                            'modified': stat.st_mtime
                        })
                    except Exception:
                        continue
        if not items:
            return jsonify({'status': 'error','message': '–§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã','success': False,'files': []}), 404
        items.sort(key=lambda x: (x.get('created') or 0), reverse=True)
        return jsonify({'status': 'success','message': f'–ù–∞–π–¥–µ–Ω–æ {len(items)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤','success': True,'files': items})
    except Exception as e:
        return jsonify({'status': 'error','message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞: {str(e)}','success': False}), 500

@app.route('/list_result_models', methods=['GET'])
def list_result_models():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π –∏–∑ result (dqn_model_*.pth)."""
    try:
        results_dir = "result"
        if not os.path.exists(results_dir):
            return jsonify({
                'status': 'error',
                'message': f'–ü–∞–ø–∫–∞ {results_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞',
                'success': False,
                'files': []
            }), 404

        model_files = glob.glob(os.path.join(results_dir, 'dqn_model_*.pth'))
        if not model_files:
            return jsonify({
                'status': 'error',
                'message': '–§–∞–π–ª—ã –≤–µ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã',
                'success': False,
                'files': []
            }), 404

        files_info = []
        for file in model_files:
            stat = os.stat(file)
            files_info.append({
                'filename': file,
                'size': stat.st_size,
                'created': stat.st_ctime,
                'modified': stat.st_mtime
            })

        files_info.sort(key=lambda x: x['modified'], reverse=True)

        return jsonify({
            'status': 'success',
            'message': f'–ù–∞–π–¥–µ–Ω–æ {len(files_info)} —Ñ–∞–π–ª–æ–≤ –≤–µ—Å–æ–≤',
            'success': True,
            'files': files_info
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –≤–µ—Å–æ–≤: {str(e)}',
            'success': False
        }), 500

@app.route('/get_result_model_info', methods=['POST'])
def get_result_model_info():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –≤–µ—Å–æ–≤ –∏–∑ result/ (dqn_model_*.pth):
    —Å–∏–º–≤–æ–ª/–∫–æ–¥, –Ω–∞–ª–∏—á–∏–µ replay/train_result, –±–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (winrate, trades_count, episodes).
    Body: { filename: 'result/dqn_model_XXXX.pth' }
    """
    try:
        data = request.get_json(silent=True) or {}
        filename = (data.get('filename') or '').strip()
        if not filename:
            return jsonify({'success': False, 'error': '–ù–µ —É–∫–∞–∑–∞–Ω filename'}), 400

        from pathlib import Path as _Path
        results_dir = _Path('result')
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–∏
        req_norm = filename.replace('\\', '/')
        p = _Path(req_norm)
        if not p.is_absolute():
            if not (p.parts and p.parts[0].lower() == results_dir.name.lower()):
                p = results_dir / p.name
        try:
            p = p.resolve()
        except Exception:
            pass
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: —Ç–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–∏ result/
        if not str(p).lower().startswith(str(results_dir.resolve()).lower()):
            return jsonify({'success': False, 'error': '–§–∞–π–ª –≤–Ω–µ –ø–∞–ø–∫–∏ result'}), 400
        if not p.exists() or not p.is_file() or p.suffix != '.pth':
            return jsonify({'success': False, 'error': '–û–∂–∏–¥–∞–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ (.pth) –≤–Ω—É—Ç—Ä–∏ result'}), 400

        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–≤—É—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –ø—É—Ç–µ–π:
        # 1) –ü–ª–æ—Å–∫–∏–π: result/dqn_model_<code>.pth
        # 2) –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π run: result/<SYMBOL>/runs/<run_id>/model.pth
        code = None
        symbol_str = None
        replay_file = None
        train_file = None
        if p.name.startswith('dqn_model_'):
            code = p.stem.replace('dqn_model_', '')
            replay_file = results_dir / f'replay_buffer_{code}.pkl'
            train_file = results_dir / f'train_result_{code}.pkl'
            # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Å–∏–º–≤–æ–ª –∏–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –∫–æ–¥–∞
            try:
                base = code.split('_')[0].upper()
                if base and len(base) <= 6:
                    symbol_str = base + 'USDT'
            except Exception:
                symbol_str = None
        else:
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—É—Ç—å run: .../result/<SYMBOL>/runs/<run_id>/model.pth
            try:
                parts = [x for x in p.parts]
                # –ù–∞–π–¥—ë–º –∏–Ω–¥–µ–∫—Å 'runs'
                if 'runs' in parts:
                    idx = parts.index('runs')
                    if idx + 1 < len(parts):
                        run_id = parts[idx + 1]
                        code = run_id
                        run_dir = p.parent
                        replay_file = run_dir / 'replay.pkl'
                        train_file = run_dir / 'train_result.pkl'
                        # –°–∏–º–≤–æ–ª –±–µ—Ä—ë–º –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞ –ø–µ—Ä–µ–¥ 'runs'
                        if idx - 1 >= 0:
                            symbol_str = parts[idx - 1]
            except Exception:
                pass
            if not code:
                return jsonify({'success': False, 'error': '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –º–æ–¥–µ–ª—å: –æ–∂–∏–¥–∞–µ—Ç—Å—è dqn_model_*.pth –∏–ª–∏ runs/.../model.pth'}), 400

        info = {
            'success': True,
            'model_file': str(p),
            'model_size_bytes': p.stat().st_size if p.exists() else 0,
            'code': code,
            'symbol': symbol_str,
            'replay_exists': replay_file.exists(),
            'train_result_exists': train_file.exists(),
            'replay_file': str(replay_file) if replay_file.exists() else None,
            'train_result_file': str(train_file) if train_file.exists() else None,
            'stats': {},
            'episodes': None
        }

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ train_result_*.pkl –µ—Å–ª–∏ –µ—Å—Ç—å
        if train_file.exists():
            try:
                import pickle
                with open(train_file, 'rb') as f:
                    results = pickle.load(f)
                stats = results.get('final_stats', {}) or {}
                info['stats'] = {
                    'winrate': stats.get('winrate'),
                    'pl_ratio': stats.get('pl_ratio'),
                    'trades_count': stats.get('trades_count')
                }
                info['episodes'] = results.get('actual_episodes', results.get('episodes'))
                # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º seed –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω
                try:
                    meta = results.get('train_metadata') or {}
                    if isinstance(meta, dict) and 'seed' in meta:
                        info['seed'] = meta.get('seed')
                    # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –æ–±—É—á–µ–Ω–∏—è
                    if isinstance(meta, dict):
                        info['cuda_available'] = bool(meta.get('cuda_available')) if ('cuda_available' in meta) else None
                        info['gpu_name'] = meta.get('gpu_name')
                except Exception:
                    pass
                # –î–æ–±–∞–≤–∏–º —Å—É–º–º–∞—Ä–Ω–æ–µ –≤—Ä–µ–º—è –∏ —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —ç–ø–∏–∑–æ–¥ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                total_training_time = results.get('total_training_time')
                if isinstance(total_training_time, (int, float)):
                    info['total_training_time'] = float(total_training_time)
                    try:
                        if info.get('episodes'):
                            avg_sec = float(total_training_time) / float(info['episodes'])
                            info['avg_time_per_episode_sec'] = avg_sec
                    except Exception:
                        pass
            except Exception as _e:
                info['stats_error'] = str(_e)

        # Fallback: –µ—Å–ª–∏ train_result.pkl –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –Ω–æ –µ—Å—Ç—å manifest.json ‚Äî –¥–æ—Å—Ç–∞—ë–º seed/—ç–ø–∏–∑–æ–¥—ã/–¥–∞—Ç—É
        try:
            if (not train_file.exists()) and p.name == 'model.pth' and 'runs' in str(p):
                run_dir = p.parent
                mf = run_dir / 'manifest.json'
                if mf.exists():
                    import json as _json
                    try:
                        with open(mf, 'r', encoding='utf-8') as _f:
                            _m = _json.load(_f)
                        if isinstance(_m, dict):
                            if 'seed' in _m and ('seed' not in info or info.get('seed') in (None, '‚Äî')):
                                info['seed'] = _m.get('seed')
                            if 'episodes_end' in _m and (info.get('episodes') is None):
                                info['episodes'] = _m.get('episodes_end')
                            if not info.get('symbol') and _m.get('symbol'):
                                info['symbol'] = _m.get('symbol')
                            # –û—Ç–º–µ—Ç–∏–º –¥–∞—Ç—É —Å–æ–∑–¥–∞–Ω–∏—è
                            if _m.get('created_at'):
                                info['created_at'] = _m.get('created_at')
                    except Exception:
                        pass
        except Exception:
            pass

        return jsonify(info)
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/analyze_bad_trades', methods=['POST'])
def analyze_bad_trades():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–ª–æ—Ö–∏–µ —Å–¥–µ–ª–∫–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è DQN –º–æ–¥–µ–ª–∏"""
    try:
        # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ result
        results_dir = "result"
        if not os.path.exists(results_dir):
            return jsonify({
                'status': 'error',
                'message': f'–ü–∞–ø–∫–∞ {results_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.',
                'success': False
            }), 404
        
        result_files = glob.glob(os.path.join(results_dir, 'train_result_*.pkl'))
        
        if not result_files:
            return jsonify({
                'status': 'error',
                'message': '–§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.',
                'success': False
            }), 404
        
        # –í—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏–∑ —Ç–µ–ª–∞ –∑–∞–ø—Ä–æ—Å–∞ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
        data = request.get_json(silent=True) or {}
        requested_file = data.get('file')
        selected_file = None
        if requested_file:
            safe_path = os.path.abspath(requested_file)
            base_path = os.path.abspath(results_dir)
            if safe_path.startswith(base_path) and os.path.exists(safe_path):
                selected_file = safe_path
        if not selected_file:
            selected_file = max(result_files, key=os.path.getctime)
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∞–Ω–∞–ª–∏–∑–∞ –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫ (—Å fallback –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)
        try:
            from analyze_bad_trades import analyze_bad_trades_detailed, print_bad_trades_analysis, print_detailed_recommendations
        except ImportError as e:
            app.logger.warning(f"Fallback analyze_bad_trades (ImportError: {e})")
            import numpy as _np
            def analyze_bad_trades_detailed(trades):
                if not trades:
                    return {
                        'bad_trades': [], 'bad_trades_count': 0,
                        'bad_trades_percentage': 0.0, 'avg_bad_roi': 0.0,
                        'avg_bad_duration': 0.0, 'loss_distribution': {},
                    }
                total = len(trades)
                bad = [t for t in trades if float(t.get('roi', 0.0)) < 0.0]
                bad_rois = [float(t.get('roi', 0.0)) for t in bad]
                bad_durs = [float(t.get('duration', 0.0)) for t in bad if t.get('duration') is not None]
                return {
                    'bad_trades': bad,
                    'bad_trades_count': len(bad),
                    'bad_trades_percentage': (len(bad)/total*100.0) if total else 0.0,
                    'avg_bad_roi': float(_np.mean(bad_rois)) if bad_rois else 0.0,
                    'avg_bad_duration': float(_np.mean(bad_durs)) if bad_durs else 0.0,
                    'loss_distribution': {
                        'very_small_losses': sum(1 for r in bad_rois if -0.002 <= r < 0),
                        'small_losses':      sum(1 for r in bad_rois if -0.01  <= r < -0.002),
                        'medium_losses':     sum(1 for r in bad_rois if -0.03  <= r < -0.01),
                        'large_losses':      sum(1 for r in bad_rois if r < -0.03),
                    }
                }
            def print_bad_trades_analysis(analysis):
                print("üìâ –ê–ù–ê–õ–ò–ó –ü–õ–û–•–ò–• –°–î–ï–õ–û–ö")
                print(f"–í—Å–µ–≥–æ –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫: {analysis.get('bad_trades_count', 0)}")
                print(f"–ü—Ä–æ—Ü–µ–Ω—Ç –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫: {analysis.get('bad_trades_percentage', 0):.2f}%")
                print(f"–°—Ä–µ–¥–Ω–∏–π ROI –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫: {analysis.get('avg_bad_roi', 0.0)*100:.4f}%")
                print(f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫: {analysis.get('avg_bad_duration', 0.0):.1f} –º–∏–Ω")
            def print_detailed_recommendations(analysis):
                print("üß† –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: ")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        try:
            import pickle
            with open(selected_file, 'rb') as f:
                results = pickle.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–¥–µ–ª–æ–∫
            if 'all_trades' not in results:
                return jsonify({
                    'status': 'error',
                    'message': '–í —Ñ–∞–π–ª–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–¥–µ–ª–∫–∞—Ö',
                    'success': False
                }), 404
            
            trades = results['all_trades']
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–ª–æ—Ö–∏–µ —Å–¥–µ–ª–∫–∏
            bad_trades_analysis = analyze_bad_trades_detailed(trades)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Å–¥–µ–ª–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            bad_trades_analysis['all_trades'] = trades
            
            # –í—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º stdout –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≤—ã–≤–æ–¥–∞
            import io
            import sys
            from contextlib import redirect_stdout
            
            output = io.StringIO()
            with redirect_stdout(output):
                print_bad_trades_analysis(bad_trades_analysis)
                print_detailed_recommendations(bad_trades_analysis)
            
            analysis_output = output.getvalue()
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
            response_data = {
                'status': 'success',
                'message': '–ê–Ω–∞–ª–∏–∑ –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ',
                'success': True,
                'file_analyzed': selected_file,
                'output': analysis_output,
                'bad_trades_count': bad_trades_analysis.get('bad_trades_count', 0),
                'bad_trades_percentage': bad_trades_analysis.get('bad_trades_percentage', 0),
                'analysis_summary': {
                    'total_trades': len(trades),
                    'bad_trades': bad_trades_analysis.get('bad_trades_count', 0),
                    'avg_bad_roi': bad_trades_analysis.get('avg_bad_roi', 0),
                    'avg_bad_duration': bad_trades_analysis.get('avg_bad_duration', 0),
                    'loss_distribution': bad_trades_analysis.get('loss_distribution', {})
                }
            }
            
            return jsonify(response_data)
            
        except Exception as e:
            return jsonify({
                'status': 'error',
                'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞: {str(e)}',
                'success': False
            }), 500
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ø–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫: {str(e)}',
            'success': False
        }), 500

# –ù–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
@app.route('/parser', methods=['POST'])
def parser():
    results = []
    symbol = 'BTCUSDT'
    interval = '5m'
    desired_candles = 100000
    csv_file_path = None

    try:
        # 1. –í—ã–∑—ã–≤–∞–µ–º –≤–Ω–µ—à–Ω—é—é —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞–µ—Ç CSV —Å 100 000 —Å–≤–µ—á–∞–º–∏
        csv_file_path = parser_download_and_combine_with_library(
            symbol='BTCUSDT',
            interval=interval,
            months_to_fetch=12, # –≠—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è parser_download_and_combine_with_library
            desired_candles=desired_candles
        )
        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω ‚Äî –Ω–µ –ø—ã—Ç–∞–µ–º—Å—è —á–∏—Ç–∞—Ç—å/–∑–∞–≥—Ä—É–∂–∞—Ç—å
        try:
            import os as _os
            if not csv_file_path or not _os.path.exists(csv_file_path):
                results.append({"status": "warning", "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ CSV-—Ñ–∞–π–ª–æ–≤ (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ –¥–∞–ª–∞ –¥–∞–Ω–Ω—ã—Ö)."})
                response = {'status': '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω', 'results': results}
                return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')
        except Exception:
            pass
        results.append({"status": "success", "message": f"CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {csv_file_path}"})

        # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —ç—Ç–∏ 100 000 —Å–≤–µ—á–µ–π –∏–∑ CSV –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î
        loaded_count = load_latest_candles_from_csv_to_db(
            file_path=csv_file_path,
            symbol_name=symbol,
            timeframe=interval
        )
        if loaded_count > 0:
            results.append({"status": "success", "message": f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} —Å–≤–µ—á–µ–π –∏–∑ CSV –≤ –ë–î."})
        else:
            results.append({"status": "warning", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ—á–∏ –∏–∑ CSV –≤ –ë–î."})

    except Exception as e:
        results.append({"status": "error", "message": f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}"})

    response = {'status': '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω', 'results': results}
    return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')

# –ù–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã–º–∏
@app.route('/data', methods=['GET'])
def data_page():
    return render_template('data.html')

# –û—Ç–¥–µ–ª—å–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è XMRUSDT
@app.route('/parser_xmr', methods=['POST'])
def parser_xmr():
    results = []
    symbol = 'XMRUSDT'
    interval = '5m'
    desired_candles = 100000
    csv_file_path = None

    try:
        csv_file_path = parser_download_and_combine_with_library(
            symbol=symbol,
            interval=interval,
            months_to_fetch=12,
            desired_candles=desired_candles
        )
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞; –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–Ω—è—Ç–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
        try:
            import os as _os
            if not csv_file_path or not _os.path.exists(csv_file_path):
                results.append({"status": "warning", "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ CSV-—Ñ–∞–π–ª–æ–≤ –¥–ª—è XMRUSDT (–≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)."})
                response = {'status': '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω', 'results': results}
                return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')
        except Exception:
            pass
        results.append({"status": "success", "message": f"CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {csv_file_path}"})

        loaded_count = load_latest_candles_from_csv_to_db(
            file_path=csv_file_path,
            symbol_name=symbol,
            timeframe=interval
        )
        if loaded_count > 0:
            results.append({"status": "success", "message": f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} —Å–≤–µ—á–µ–π –∏–∑ CSV –≤ –ë–î."})
        else:
            results.append({"status": "warning", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ—á–∏ –∏–∑ CSV –≤ –ë–î."})

    except Exception as e:
        results.append({"status": "error", "message": f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}"})

    response = {'status': '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω', 'results': results}
    return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')

@app.route('/parser_xrp', methods=['POST'])
def parser_xrp():
    results = []
    symbol = 'XRPUSDT'
    interval = '5m'
    desired_candles = 100000
    csv_file_path = None

    try:
        csv_file_path = parser_download_and_combine_with_library(
            symbol=symbol,
            interval=interval,
            months_to_fetch=12,
            desired_candles=desired_candles
        )
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞; –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–Ω—è—Ç–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
        try:
            import os as _os
            if not csv_file_path or not _os.path.exists(csv_file_path):
                results.append({"status": "warning", "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ CSV-—Ñ–∞–π–ª–æ–≤ –¥–ª—è XRPUSDT (–≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)."})
                response = {'status': '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω', 'results': results}
                return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')
        except Exception:
            pass
        results.append({"status": "success", "message": f"CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {csv_file_path}"})

        loaded_count = load_latest_candles_from_csv_to_db(
            file_path=csv_file_path,
            symbol_name=symbol,
            timeframe=interval
        )
        if loaded_count > 0:
            results.append({"status": "success", "message": f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} —Å–≤–µ—á–µ–π –∏–∑ CSV –≤ –ë–î."})
        else:
            results.append({"status": "warning", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ—á–∏ –∏–∑ CSV –≤ –ë–î."})

    except Exception as e:
        results.append({"status": "error", "message": f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}"})

    response = {'status': '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω', 'results': results}
    return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')

# –ù–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å–≤–µ—á–µ–π
@app.route('/parser_multi_crypto', methods=['POST'])
def parser_multi_crypto():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Å–≤–µ—á–∏ –¥–ª—è –≤—Å–µ—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ"""
    results = []
    interval = '5m'
    desired_candles = 100000
    
    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    crypto_symbols = [
        'BTCUSDT',  # –ë–∏—Ç–∫–æ–∏–Ω
        'TONUSDT',  # TON
        'ETHUSDT',  # –≠—Ñ–∏—Ä–∏—É–º
        'SOLUSDT',  # Solana
        'ADAUSDT',  # Cardano
        'BNBUSDT'   # Binance Coin
    ]
    
    print(f"üöÄ –ù–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å–≤–µ—á–µ–π –¥–ª—è {len(crypto_symbols)} –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç...")
    print(f"üìä –¢–∞–π–º—Ñ—Ä–µ–π–º: {interval}, –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {desired_candles}")
    
    for i, symbol in enumerate(crypto_symbols, 1):
        try:
            print(f"\nüì• [{i}/{len(crypto_symbols)}] –°–∫–∞—á–∏–≤–∞—é {symbol}...")
            
            # 1. –°–∫–∞—á–∏–≤–∞–µ–º —Å–≤–µ—á–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã
            csv_file_path = parser_download_and_combine_with_library(
                symbol=symbol,
                interval=interval,
                months_to_fetch=12,
                desired_candles=desired_candles
            )
            
            if csv_file_path:
                results.append({
                    "status": "success", 
                    "symbol": symbol,
                    "message": f"CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {csv_file_path}"
                })
                
                # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ—á–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                try:
                    loaded_count = load_latest_candles_from_csv_to_db(
                        file_path=csv_file_path,
                        symbol_name=symbol,
                        timeframe=interval
                    )
                    
                    if loaded_count > 0:
                        results.append({
                            "status": "success",
                            "symbol": symbol,
                            "message": f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} —Å–≤–µ—á–µ–π –≤ –ë–î"
                        })
                        print(f"  ‚úÖ {symbol}: {loaded_count} —Å–≤–µ—á–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ –ë–î")
                    else:
                        results.append({
                            "status": "warning",
                            "symbol": symbol,
                            "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ—á–∏ –≤ –ë–î"
                        })
                        print(f"  ‚ö†Ô∏è {symbol}: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î")
                        
                except Exception as db_error:
                    results.append({
                        "status": "error",
                        "symbol": symbol,
                        "message": f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î: {str(db_error)}"
                    })
                    print(f"  ‚ùå {symbol}: –æ—à–∏–±–∫–∞ –ë–î - {db_error}")
                    
            else:
                results.append({
                    "status": "error",
                    "symbol": symbol,
                    "message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å CSV —Ñ–∞–π–ª"
                })
                print(f"  ‚ùå {symbol}: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å CSV")
                
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {symbol}: {str(e)}"
            results.append({
                "status": "error",
                "symbol": symbol,
                "message": error_msg
            })
            print(f"  ‚ùå {symbol}: {error_msg}")
            continue
    
    # –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞–º
    successful = sum(1 for r in results if r['status'] == 'success')
    failed = sum(1 for r in results if r['status'] == 'error')
    warnings = sum(1 for r in results if r['status'] == 'warning')
    
    print(f"\n{'='*60}")
    print(f"üìä –°–í–û–î–ö–ê –°–ö–ê–ß–ò–í–ê–ù–ò–Ø")
    print(f"{'='*60}")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}")
    print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {warnings}")
    print(f"‚ùå –û—à–∏–±–∫–∏: {failed}")
    print(f"üìà –í—Å–µ–≥–æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç: {len(crypto_symbols)}")
    
    response = {
        'status': '–ú—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ',
        'summary': {
            'total_cryptos': len(crypto_symbols),
            'successful': successful,
            'warnings': warnings,
            'failed': failed
        },
        'results': results
    }
    
    return Response(json.dumps(response, ensure_ascii=False), mimetype='application/json')

@app.route('/clear_redis', methods=['POST'])
def clear_redis():
    """–û—á–∏—â–∞–µ—Ç Redis –≤—Ä—É—á–Ω—É—é"""
    try:
        global redis_client
        redis_client.flushall()
        return jsonify({
            "success": True,
            "message": "Redis –æ—á–∏—â–µ–Ω —É—Å–ø–µ—à–Ω–æ"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/models')
def models_page():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏"""
    return render_template('models.html')

@app.route('/cnn_training')
def cnn_training_page():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –æ–±—É—á–µ–Ω–∏—è CNN –º–æ–¥–µ–ª–µ–π"""
    return render_template('cnn_training.html')

# === CNN Training API Endpoints ===

@app.route('/cnn/start_training', methods=['POST'])
def cnn_start_training():
    """–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è CNN –º–æ–¥–µ–ª–∏"""
    try:
        data = request.get_json()
        symbols = data.get('symbols', ['BTCUSDT'])
        timeframes = data.get('timeframes', ['5m'])
        model_type = data.get('model_type', 'multiframe')
        
        print(f"üîç Flask: –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ CNN –æ–±—É—á–µ–Ω–∏–µ")
        print(f"üîç Flask: symbols={symbols}, model_type={model_type}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é Celery –∑–∞–¥–∞—á—É –¥–ª—è –æ–±—É—á–µ–Ω–∏—è CNN
        try:
            print(f"üîç Flask: –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º train_cnn_model...")
            from tasks.celery_tasks import train_cnn_model
            print(f"‚úÖ Flask: train_cnn_model –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
        except ImportError as e:
            print(f"‚ùå Flask: –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ train_cnn_model: {e}")
            raise
        
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –æ–¥–∏–Ω —Å–∏–º–≤–æ–ª –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫
        if isinstance(symbols, str):
            symbols = [symbols]
            print(f"üîç Flask: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∏ —Å–∏–º–≤–æ–ª –≤ —Å–ø–∏—Å–æ–∫: {symbols}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –û–î–ù–£ –∑–∞–¥–∞—á—É –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–∞–º–∞ –æ–±—É—á–∏—Ç –Ω–∞ –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–∞—Ö –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        print(f"üîç Flask: –ó–∞–ø—É—Å–∫–∞–µ–º –æ–¥–Ω—É –∑–∞–¥–∞—á—É –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Å–∏–º–≤–æ–ª–æ–≤: {symbols}...")
        try:
            # –ü–µ—Ä–µ–¥–∞–µ–º –ø–µ—Ä–≤—ã–π —Å–∏–º–≤–æ–ª –∫–∞–∫ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç (–∑–∞–¥–∞—á–∞ –≤–Ω—É—Ç—Ä–∏ –≤–æ–∑—å–º–µ—Ç –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∏–∑ config)
            task = train_cnn_model.delay(
                symbol=symbols[0] if symbols else "BTCUSDT",
                model_type=model_type
            )
            print(f"‚úÖ Flask: –ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞ —Å ID: {task.id}")
            task_results = [{
                "symbols": symbols,
                "task_id": task.id
            }]
        except Exception as e:
            print(f"‚ùå Flask: –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏: {e}")
            raise
        
        print(f"‚úÖ Flask: –í—Å–µ –∑–∞–¥–∞—á–∏ —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç.")
        
        result = {
            "success": True,
            "message": f"üß† CNN –æ–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ –¥–ª—è {symbols}",
            "task_results": task_results,
            "details": {
                "symbols": symbols,
                "timeframes": timeframes,
                "model_type": model_type,
                "note": "–í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è –±–µ—Ä—É—Ç—Å—è –∏–∑ config.py"
            }
        }
        
        print(f"üîç Flask: –û—Ç–≤–µ—Ç: {result}")
        return jsonify(result)
    except Exception as e:
        print(f"‚ùå Flask: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ CNN endpoint: {str(e)}")
        import traceback
        print(f"‚ùå Flask: Traceback: {traceback.format_exc()}")
        return jsonify({
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ CNN –æ–±—É—á–µ–Ω–∏—è: {str(e)}"
        }), 500

@app.route('/cnn/models', methods=['GET'])
def cnn_get_models():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ CNN –º–æ–¥–µ–ª–µ–π –∏–∑ cnn_training/result"""
    try:
        import os
        import json
        from datetime import datetime
        
        models = []
        result_dir = "cnn_training/result"
        
        if not os.path.exists(result_dir):
            return jsonify({
                "success": True,
                "models": []
            })
        
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Å–∏–º–≤–æ–ª–∞–º –≤ result/
        for symbol in os.listdir(result_dir):
            symbol_path = os.path.join(result_dir, symbol)
            if not os.path.isdir(symbol_path):
                continue
                
            runs_dir = os.path.join(symbol_path, "runs")
            if not os.path.exists(runs_dir):
                continue
            
            # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º run_id
            for run_id in os.listdir(runs_dir):
                run_path = os.path.join(runs_dir, run_id)
                if not os.path.isdir(run_path):
                    continue
                
                # –ò—â–µ–º manifest.json –∏ result_*.json
                manifest_path = os.path.join(run_path, "manifest.json")
                if not os.path.exists(manifest_path):
                    continue
                
                try:
                    # –ß–∏—Ç–∞–µ–º manifest.json
                    with open(manifest_path, 'r', encoding='utf-8') as f:
                        manifest = json.load(f)
                    
                    # –ò—â–µ–º result —Ñ–∞–π–ª—ã
                    result_files = [f for f in os.listdir(run_path) if f.startswith('result_') and f.endswith('.json')]
                    
                    # –ò—â–µ–º –º–æ–¥–µ–ª–∏ (–±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å)
                    model_files = [f for f in os.listdir(run_path) if f.endswith('.pth')]
                    
                    if model_files:
                        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —Å–Ω–∞—á–∞–ª–∞ best, –ø–æ—Ç–æ–º –æ–±—ã—á–Ω—É—é
                        best_model = None
                        regular_model = None
                        
                        for model_file in model_files:
                            if 'best' in model_file.lower():
                                best_model = model_file
                            else:
                                regular_model = model_file
                        
                        # –ë–µ—Ä–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ–±—ã—á–Ω—É—é
                        model_file = best_model if best_model else regular_model
                        model_path = os.path.join(run_path, model_file)
                        model_size = os.path.getsize(model_path)
                        
                        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ manifest
                        model_type = manifest.get('model_type', 'unknown')
                        timeframes = manifest.get('timeframes', [])
                        created_at = manifest.get('created_at', '')
                        symbols_trained = manifest.get('symbols', [])
                        
                        # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
                        accuracy = None
                        epochs_trained = None
                        train_loss = None
                        val_loss = None
                        
                        if result_files:
                            try:
                                result_path = os.path.join(run_path, result_files[0])
                                with open(result_path, 'r', encoding='utf-8') as f:
                                    result_data = json.load(f)
                                
                                accuracy = result_data.get('best_val_accuracy')
                                epochs_trained = result_data.get('epochs_trained')
                                train_loss = result_data.get('train_loss_last')
                                val_loss = result_data.get('val_loss_last')
                            except Exception:
                                pass
                        
                        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
                        model_info = {
                            "symbol": symbol,
                            "run_id": run_id,
                            "model_type": model_type,
                            "timeframes": timeframes,
                            "symbols_trained": symbols_trained,
                            "accuracy": accuracy,
                            "epochs_trained": epochs_trained,
                            "train_loss": train_loss,
                            "val_loss": val_loss,
                            "size": model_size,
                            "created": created_at,
                            "path": model_path,
                            "manifest": manifest,
                            "model_file": model_file
                        }
                        
                        models.append(model_info)
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {manifest_path}: {e}")
                    continue
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
        models.sort(key=lambda x: x.get('created', ''), reverse=True)
        
        return jsonify({
            "success": True,
            "models": models,
            "total": len(models)
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/cnn/test_model', methods=['POST'])
def cnn_test_model():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ CNN –º–æ–¥–µ–ª–∏"""
    try:
        data = request.get_json()
        model_path = data.get('model_path')
        
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ CNN –º–æ–¥–µ–ª–∏
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
        return jsonify({
            "success": True,
            "test_results": f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_path} –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ.\n–¢–æ—á–Ω–æ—Å—Ç—å: 75.2%\nLoss: 0.234\n–í—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: 45 —Å–µ–∫—É–Ω–¥"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/cnn/test_extraction', methods=['POST'])
def cnn_test_extraction():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    try:
        import time
        import torch
        import numpy as np
        
        data = request.get_json()
        model_path = data.get('model_path')
        test_symbol = data.get('test_symbol', 'BTCUSDT')
        
        if not model_path:
            return jsonify({
                "success": False,
                "error": "–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω"
            }), 400
        
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏: {model_path}")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏
        try:
            from cnn_training.feature_extractor import CNNFeatureExtractor
            from cnn_training.config import CNNTrainingConfig
            from cnn_training.data_loader import CryptoDataLoader
        except ImportError as e:
            return jsonify({
                "success": False,
                "error": f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π: {e}"
            }), 500
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config = CNNTrainingConfig(
            symbols=[test_symbol],
            timeframes=["5m", "15m", "1h"],
            device="auto"
        )
        
        # –°–æ–∑–¥–∞–µ–º feature extractor
        extractor = CNNFeatureExtractor(config)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        try:
            extractor.load_model(model_path)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
        except Exception as e:
            return jsonify({
                "success": False,
                "error": f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}"
            }), 500
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        data_loader = CryptoDataLoader(config)
        data_dict = data_loader.prepare_training_data([test_symbol], config.timeframes)
        
        if not data_dict:
            return jsonify({
                "success": False,
                "error": f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {test_symbol}"
            }), 500
        
        # –°–æ–∑–¥–∞–µ–º –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        train_dataset, val_dataset = data_loader.create_multiframe_dataset(data_dict)
        
        # –ë–µ—Ä–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        test_samples = []
        for i in range(min(10, len(val_dataset))):
            sample = val_dataset[i]
            test_samples.append(sample)
        
        print(f"üìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ {len(test_samples)} –æ–±—Ä–∞–∑—Ü–∞—Ö")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        start_time = time.time()
        features_list = []
        
        for sample in test_samples:
            try:
                features = extractor.extract_features(sample)
                features_list.append(features)
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—Ä–∞–∑—Ü–∞: {e}")
                continue
        
        extraction_time = (time.time() - start_time) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        
        if not features_list:
            return jsonify({
                "success": False,
                "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∏ –∏–∑ –æ–¥–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞"
            }), 500
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        features_array = np.array(features_list)
        
        results = {
            "success": True,
            "feature_size": int(features_array.shape[1]),
            "extraction_time": round(extraction_time, 2),
            "samples_tested": len(features_list),
            "feature_mean": round(float(np.mean(features_array)), 6),
            "feature_std": round(float(np.std(features_array)), 6),
            "feature_min": round(float(np.min(features_array)), 6),
            "feature_max": round(float(np.max(features_array)), 6),
            "feature_sample": features_array[0].tolist()[:10],  # –ü–µ—Ä–≤—ã–µ 10 –∑–Ω–∞—á–µ–Ω–∏–π
            "model_path": model_path,
            "test_symbol": test_symbol
        }
        
        print(f"‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {results}")
        return jsonify(results)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/cnn/integrate_dqn', methods=['POST'])
def cnn_integrate_dqn():
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è CNN —Å DQN"""
    try:
        data = request.get_json()
        model_path = data.get('model_path')
        
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é CNN —Å DQN
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
        return jsonify({
            "success": True,
            "model_path": model_path,
            "cnn_features_size": 64,
            "total_state_size": 128,
            "config_updated": True
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/cnn/monitoring', methods=['GET'])
def cnn_monitoring():
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è CNN"""
    try:
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
        return jsonify({
            "success": True,
            "metrics": {
                "current_epoch": 25,
                "train_loss": 0.234,
                "val_loss": 0.267,
                "val_accuracy": 0.752
            },
            "logs": [
                "Epoch 25/50: Train Loss: 0.234, Val Loss: 0.267, Val Acc: 75.2%",
                "Epoch 24/50: Train Loss: 0.241, Val Loss: 0.271, Val Acc: 74.8%",
                "Epoch 23/50: Train Loss: 0.248, Val Loss: 0.275, Val Acc: 74.5%"
            ]
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/cnn/validate_model', methods=['POST'])
def cnn_validate_model():
    """–í–∞–ª–∏–¥–∞—Ü–∏—è CNN –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö —Å–∏–º–≤–æ–ª–∞—Ö"""
    try:
        data = request.get_json()
        model_path = data.get('model_path')
        test_symbols = data.get('test_symbols', ['SOLUSDT', 'XRPUSDT', 'TONUSDT'])
        test_period = data.get('test_period', 'last_year')
        validation_type = data.get('validation_type', 'cross_symbol')
        
        if not model_path:
            return jsonify({
                "success": False,
                "error": "–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω"
            }), 400
        
        print(f"üß™ –í–∞–ª–∏–¥–∞—Ü–∏—è CNN –º–æ–¥–µ–ª–∏: {model_path}")
        print(f"üìä –¢–µ—Å—Ç–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã: {test_symbols}")
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {test_period}")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ç–æ—Ä
        try:
            from cnn_training.model_validator import validate_cnn_model
        except ImportError as e:
            return jsonify({
                "success": False,
                "error": f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞: {e}"
            }), 500
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é
        try:
            result = validate_cnn_model(
                model_path=model_path,
                test_symbols=test_symbols,
                test_period=test_period
            )
            
            if result['success']:
                print(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                print(f"üìà –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {result.get('overall_accuracy', 0):.2%}")
                return jsonify(result)
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                return jsonify(result), 500
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {str(e)}")
            import traceback
            print(f"‚ùå Traceback: {traceback.format_exc()}")
            return jsonify({
                "success": False,
                "error": f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {str(e)}"
            }), 500
            
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ endpoint –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {str(e)}")
        import traceback
        print(f"‚ùå Traceback: {traceback.format_exc()}")
        return jsonify({
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {str(e)}"
        }), 500

@app.route('/cnn/examples', methods=['GET'])
def cnn_examples():
    """–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è CNN –º–æ–¥—É–ª—è"""
    try:
        examples = """# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è CNN –º–æ–¥—É–ª—è

from cnn_training.config import CNNTrainingConfig
from cnn_training.trainer import CNNTrainer
from cnn_training.feature_extractor import create_cnn_wrapper

# 1. –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config = CNNTrainingConfig(
    symbols=["BTCUSDT", "ETHUSDT"],
    timeframes=["5m", "15m", "1h"],
    sequence_length=50,
    output_features=64
)

# 2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
trainer = CNNTrainer(config)
result = trainer.train_single_model("BTCUSDT", "5m", "prediction")

# 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è DQN
cnn_wrapper = create_cnn_wrapper(config)
features = cnn_wrapper.get_cnn_features("BTCUSDT", ohlcv_data)

# 4. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å DQN
combined_state = np.concatenate([base_dqn_state, features])"""
        
        return jsonify({
            "success": True,
            "examples": examples
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/trading_agent')
def trading_agent_page():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
    return render_template('trading_agent.html')

@app.route('/agent/<symbol>')
def agent_symbol_page(symbol: str):
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –∞–≥–µ–Ω—Ç–∞, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Å–∏–º–≤–æ–ª—É (BTCUSDT, TONUSDT –∏ —Ç.–¥.)"""
    try:
        sym = (symbol or '').upper().strip()
        # –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è: —Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü–∞ –∏ 'USDT' –≤ –∫–æ–Ω—Ü–µ
        import re
        if not re.match(r'^[A-Z]{2,10}USDT$', sym):
            # –¥–µ—Ñ–æ–ª—Ç –Ω–∞ BTCUSDT
            sym = 'BTCUSDT'
        return render_template('agent_symbol.html', symbol=sym)
    except Exception:
        return render_template('agent_symbol.html', symbol='BTCUSDT')

@app.route('/create_model_version', methods=['POST'])
def create_model_version():
    """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º ID"""
    import shutil
    import uuid
    from datetime import datetime
    from pathlib import Path
    import traceback
    
    try:
        # –ß–∏—Ç–∞–µ–º —Å–∏–º–≤–æ–ª –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        try:
            data = request.get_json(silent=True) or {}
        except Exception:
            data = {}
        requested_symbol = (data.get('symbol') or '').strip()
        requested_file = (data.get('file') or '').strip()
        requested_ensemble = (data.get('ensemble') or 'ensemble-a').strip() or 'ensemble-a'
        print(f"[create_model_version] payload: symbol='{requested_symbol}', file='{requested_file}', ensemble='{requested_ensemble}'")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID (4 —Å–∏–º–≤–æ–ª–∞)
        model_id = str(uuid.uuid4())[:4].upper()
        
        # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–ø–∫—É result/ –∏ —Å–∏–º–≤–æ–ª (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω)
        result_dir = Path('result')
        if not result_dir.exists():
            return jsonify({
                "success": False,
                "error": "–ü–∞–ø–∫–∞ result –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ."
            })
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º base_code (—Å–∏–º–≤–æ–ª—å–Ω—ã–π –ø—Ä–µ—Ñ–∏–∫—Å)
        def normalize_symbol(sym: str) -> str:
            if not sym:
                return ''
            s = sym.upper().replace('/', '')
            for suffix in ["USDT", "USD", "USDC", "BUSD", "USDP"]:
                if s.endswith(suffix):
                    s = s[:-len(suffix)]
                    break
            s = s.lower()
            if s in ("–º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–∞", "multi", "multicrypto"):
                s = "multi"
            return s
        
        base_code = normalize_symbol(requested_symbol)
        print(f"[create_model_version] base_code (from symbol): '{base_code}'")
        
        selected_result_file = None
        selected_model_file = None
        selected_replay_file = None
        run_dir_path = None
        # 1) –ï—Å–ª–∏ —Ñ—Ä–æ–Ω—Ç –ø—Ä–∏—Å–ª–∞–ª —è–≤–Ω—ã–π —Ñ–∞–π–ª ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if requested_file:
            from pathlib import Path as _Path
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–µ—à–∏ (Windows/Unix)
            req_norm = requested_file.replace('\\', '/')
            safe_path = _Path(req_norm)
            result_dir_abs = result_dir.resolve()
            print(f"[create_model_version] requested_file(normalized)='{req_norm}'")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç —Å —É—á—ë—Ç–æ–º —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ñ–æ—Ä–º–∞—Ç–∞ –ø—É—Ç–∏
            if safe_path.is_absolute():
                candidate = safe_path
            else:
                # –ï—Å–ª–∏ –ø—É—Ç—å —É–∂–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 'result/'
                if safe_path.parts and safe_path.parts[0].lower() == result_dir.name.lower():
                    candidate = _Path(req_norm)
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤–Ω—É—Ç—Ä–∏ result/
                    candidate = result_dir / safe_path.name

            try:
                cand_resolved = candidate.resolve()
            except Exception:
                cand_resolved = candidate
            print(f"[create_model_version] candidate='{cand_resolved}', exists={cand_resolved.exists()}, is_file={cand_resolved.is_file()}")

            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏ result/
            try:
                inside_result = str(cand_resolved).lower().startswith(str(result_dir_abs).lower())
            except Exception:
                inside_result = False
            print(f"[create_model_version] inside_result={inside_result}, result_dir_abs='{result_dir_abs}'")

            if inside_result and cand_resolved.exists() and cand_resolved.is_file():
                run_dir = cand_resolved.parent
                run_dir_path = run_dir
                name_low = cand_resolved.name.lower()
                # 1) –ï—Å–ª–∏ –≤—ã–±—Ä–∞–ª–∏ –º–æ–¥–µ–ª—å .pth –∏–∑ –ø–∞–ø–∫–∏ run ‚Äî –∏—â–µ–º —Ä—è–¥–æ–º replay –∏ results
                if cand_resolved.suffix == '.pth':
                    # –ø—Ä–∏–Ω–∏–º–∞–µ–º –ª—é–±–æ–π *.pth –∫–∞–∫ –º–æ–¥–µ–ª—å
                    selected_model_file = cand_resolved
                    for f in run_dir.iterdir():
                        if not f.is_file():
                            continue
                        n = f.name.lower()
                        if n.endswith('.pkl') and (n.startswith('replay_buffer') or 'replay' in n):
                            selected_replay_file = selected_replay_file or f
                        elif n.endswith('.pkl') and (n.startswith('train_result') or 'result' in n):
                            selected_result_file = selected_result_file or f
                    print(f"[create_model_version] from run dir found: model={selected_model_file}, replay={selected_replay_file}, result={selected_result_file}")
                    # –ï—Å–ª–∏ –∫–∞–∫–∏—Ö-—Ç–æ —Ñ–∞–π–ª–æ–≤ –Ω–µ—Ç ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º, –Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏–º
                    if not (selected_replay_file and selected_result_file):
                        print("[create_model_version] WARN: not all artifacts found near model; will copy available ones only")
                    try:
                        if selected_result_file is not None:
                            fname = selected_result_file.stem
                            parts = fname.split('_', 2)
                            if len(parts) >= 3:
                                base_code = parts[2].lower()
                    except Exception:
                        pass
                # 2) –ï—Å–ª–∏ –≤—ã–±—Ä–∞–ª–∏ train_result_*.pkl ‚Äî –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –∏—â–µ–º —Ä—è–¥–æ–º .pth –∏ replay
                elif cand_resolved.suffix == '.pkl' and name_low.startswith('train_result_'):
                    selected_result_file = cand_resolved
                    for f in run_dir.iterdir():
                        if not f.is_file():
                            continue
                        n = f.name.lower()
                        if n.endswith('.pth'):
                            selected_model_file = selected_model_file or f
                        elif n.endswith('.pkl') and (n.startswith('replay_buffer') or 'replay' in n):
                            selected_replay_file = selected_replay_file or f
                    print(f"[create_model_version] neighbor search: model={selected_model_file}, replay={selected_replay_file}, result={selected_result_file}")
                    if not selected_model_file:
                        return jsonify({
                            "success": False,
                            "error": "–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å *.pth —Ä—è–¥–æ–º —Å —Ñ–∞–π–ª–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
                        })
                    try:
                        fname = selected_result_file.stem
                        parts = fname.split('_', 2)
                        if len(parts) >= 3:
                            base_code = parts[2].lower()
                    except Exception:
                        pass
                else:
                    return jsonify({
                        "success": False,
                        "error": "–û–∂–∏–¥–∞–ª—Å—è .pth –∏–ª–∏ train_result_*.pkl –≤–Ω—É—Ç—Ä–∏ result/"
                    })
            else:
                return jsonify({
                    "success": False,
                    "error": "–ù–µ–≤–µ—Ä–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–Ω—É—Ç—Ä–∏ result/"
                })
        elif base_code:
            # –ò—â–µ–º —Ç–æ—á–Ω—ã–π train_result_<base_code>.pkl
            candidate = result_dir / f"train_result_{base_code}.pkl"
            print(f"[create_model_version] fallback by base_code: candidate='{candidate}' exists={candidate.exists()}")
            if candidate.exists():
                selected_result_file = candidate
            else:
                return jsonify({
                    "success": False,
                    "error": f"–§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å–∏–º–≤–æ–ª–∞ {base_code} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ result/"
                })
        else:
            # Fallback: –±–µ—Ä—ë–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π train_result_*.pkl
            result_files = list(result_dir.glob('train_result_*.pkl'))
            if not result_files:
                return jsonify({
                    "success": False,
                    "error": "–§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ result/"
                })
            selected_result_file = max(result_files, key=lambda x: x.stat().st_mtime)
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Å–∏–º–≤–æ–ª –∏–∑ –∏–º–µ–Ω–∏
            try:
                fname = selected_result_file.stem  # train_result_<code>
                parts = fname.split('_', 2)
                if len(parts) >= 3:
                    base_code = parts[2].lower()
            except Exception:
                pass

        if not base_code:
            base_code = "model"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        if selected_model_file and selected_replay_file and selected_result_file:
            model_file = selected_model_file
            replay_file = selected_replay_file
        else:
            model_file = result_dir / f'dqn_model_{base_code}.pth'
            replay_file = result_dir / f'replay_buffer_{base_code}.pkl'
        print(f"[create_model_version] sources: model='{model_file}', replay='{replay_file}', result='{selected_result_file}'")
        
        if not model_file.exists():
            return jsonify({
                "success": False,
                "error": f"–§–∞–π–ª {model_file.name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ result/"
            })
        # replay –∏ results –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É models/<symbol>/<ensemble>/vN
        named_id = f"{base_code}_{model_id}"
        try:
            from datetime import datetime as _dt
            from pathlib import Path as _Path
            import json as _json

            models_root = _Path('models')
            models_root.mkdir(exist_ok=True)

            # –°–∏–º–≤–æ–ª –ø–∞–ø–∫–∏ –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ (btc, bnb, ton)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–º–≤–æ–ª –∏–∑ –∫–æ–¥–∞ (–ø—Ä–µ—Ñ–∏–∫—Å –¥–æ –ø–µ—Ä–≤–æ–≥–æ '_')
            try:
                symbol_base = (base_code.split('_', 1)[0] or base_code).lower()
            except Exception:
                symbol_base = base_code.lower()
            symbol_dir = models_root / symbol_base
            symbol_dir.mkdir(exist_ok=True)

            # Ensemble –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –≤ payload, –∏–Ω–∞—á–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'ensemble-a'
            ensemble_name = (data.get('ensemble') or 'ensemble-a').strip() or 'ensemble-a'
            ensemble_dir = symbol_dir / ensemble_name
            ensemble_dir.mkdir(exist_ok=True)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–π –Ω–æ–º–µ—Ä –≤–µ—Ä—Å–∏–∏ vN
            existing_versions = []
            for p in ensemble_dir.iterdir():
                try:
                    if p.is_dir() and p.name.startswith('v'):
                        n = int(p.name[1:])
                        existing_versions.append(n)
                except Exception:
                    pass
            next_num = (max(existing_versions) + 1) if existing_versions else 1
            version_name = f'v{next_num}'
            version_dir = ensemble_dir / version_name
            version_dir.mkdir(exist_ok=False)
            print(f"[create_model_version] create version_dir='{version_dir}'")

            # –ö–æ–ø–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤–µ—Ä—Å–∏–∏ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤)
            ver_model = version_dir / model_file.name
            ver_replay = version_dir / (replay_file.name if replay_file.exists() else 'replay_buffer.pkl')
            ver_result = version_dir / (selected_result_file.name if (selected_result_file and selected_result_file.exists()) else 'train_result.pkl')
            shutil.copy2(model_file, ver_model)
            try:
                if replay_file.exists():
                    shutil.copy2(replay_file, ver_replay)
            except Exception:
                print(f"[create_model_version] WARN: replay not copied from '{replay_file}'")
            try:
                if selected_result_file and selected_result_file.exists():
                    shutil.copy2(selected_result_file, ver_result)
            except Exception:
                print(f"[create_model_version] WARN: results not copied from '{selected_result_file}'")
            print(f"[create_model_version] copied core files to '{version_dir.name}'")

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ –∑–∞–ø—É—Å–∫–∞ (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–∞)
            try:
                if run_dir_path is not None:
                    print(f"[create_model_version] copying extra files from run_dir='{run_dir_path}'")
                    for f in run_dir_path.iterdir():
                        if f.is_file():
                            dst = version_dir / f.name
                            try:
                                if not dst.exists():
                                    shutil.copy2(f, dst)
                                    print(f"[create_model_version] extra file copied: '{f.name}'")
                            except Exception:
                                print(f"[create_model_version] WARN: failed to copy extra file '{f}'")
            except Exception:
                print("[create_model_version] WARN: extra-files copy failed:\n" + traceback.format_exc())

            # –ü–∏—à–µ–º manifest.yaml (–±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç PyYAML)
            manifest_path = version_dir / 'manifest.yaml'
            try:
                # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                stats_brief = {}
                if ver_result.exists():
                    try:
                        import pickle as _pickle
                        with open(ver_result, 'rb') as _f:
                            _res = _pickle.load(_f)
                            if isinstance(_res, dict) and 'final_stats' in _res:
                                stats_brief = _res['final_stats'] or {}
                    except Exception:
                        print("[create_model_version] WARN: cannot read stats from ver_result")
                created_ts = _dt.utcnow().isoformat()
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º run_id –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –æ–Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω–∞
                manifest_id = (str(run_dir_path.name) if run_dir_path is not None else named_id)
                yaml_text = (
                    'id: "' + manifest_id + '"\n'
                    'symbol: "' + base_code.lower() + '"\n'
                    'ensemble: "' + ensemble_name + '"\n'
                    'version: "' + version_name + '"\n'
                    'created_at: "' + created_ts + '"\n'
                    'run_id: "' + manifest_id + '"\n'
                    + (('source_run_path: "' + str(run_dir_path).replace('\\','/') + '"\n') if run_dir_path is not None else '')
                    + 'files:\n'
                    '  model: "' + ver_model.name + '"\n'
                    '  replay: "' + ver_replay.name + '"\n'
                    '  results: "' + ver_result.name + '"\n'
                    'stats:\n' + ''.join([
                        f"  {k}: {v}\n" for k, v in (stats_brief.items() if isinstance(stats_brief, dict) else [])
                    ])
                )
                with open(manifest_path, 'w', encoding='utf-8') as mf:
                    mf.write(yaml_text)
            except Exception:
                print("[create_model_version] WARN: manifest write failed:\n" + traceback.format_exc())

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–∏–º–ª–∏–Ω–∫ current -> vN (–µ—Å–ª–∏ –Ω–µ —É–¥–∞—ë—Ç—Å—è ‚Äî —Å–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª-—É–∫–∞–∑–∞—Ç–µ–ª—å)
            current_link = ensemble_dir / 'current'
            try:
                if current_link.exists() or current_link.is_symlink():
                    try:
                        if current_link.is_symlink() or current_link.is_file():
                            current_link.unlink()
                        elif current_link.is_dir():
                            shutil.rmtree(current_link)
                    except Exception:
                        pass
                os.symlink(version_name, current_link)
            except Exception:
                # –§–æ–ª–ª–±–µ–∫: –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∏–º—è –≤–µ—Ä—Å–∏–∏ –≤ —Ñ–∞–π–ª
                try:
                    with open(current_link, 'w', encoding='utf-8') as fcur:
                        fcur.write(version_name)
                except Exception:
                    pass
        except Exception:
            # –ù–µ –≤–∞–ª–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π, –µ—Å–ª–∏ models/ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
            print("[create_model_version] WARN: version packaging failed:\n" + traceback.format_exc())
        
        return jsonify({
            "success": True,
            "model_id": (run_dir_path.name if run_dir_path is not None else named_id),
            "files": [
                ver_model.name,
                ver_replay.name if ver_replay.exists() else None,
                ver_result.name if ver_result.exists() else None
            ]
        })
        
    except Exception as e:
        print("[create_model_version] ERROR:\n" + traceback.format_exc())
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/get_models_list')
def get_models_list():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    from pathlib import Path
    import pickle
    from datetime import datetime
    
    try:
        models: list = []

        # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É models/

        # 2) –ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: models/<symbol>/<ensemble>/vN
        models_root = Path('models')
        if models_root.exists():
            for symbol_dir in models_root.iterdir():
                if not symbol_dir.is_dir():
                    continue
                for ensemble_dir in symbol_dir.iterdir():
                    if not ensemble_dir.is_dir():
                        continue
                    for version_dir in ensemble_dir.iterdir():
                        if not version_dir.is_dir() or not version_dir.name.startswith('v'):
                            continue
                        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
                        model_files = list(version_dir.glob('dqn_model_*.pth'))
                        replay_files = list(version_dir.glob('replay_buffer_*.pkl'))
                        result_files = list(version_dir.glob('train_result_*.pkl'))
                        if not model_files or not replay_files or not result_files:
                            continue
                        model_file = model_files[0]
                        replay_file = replay_files[0]
                        result_file = result_files[0]
            model_id = model_file.stem.replace('dqn_model_', '')
            model_size = f"{model_file.stat().st_size / 1024 / 1024:.1f} MB"
            replay_size = f"{replay_file.stat().st_size / 1024 / 1024:.1f} MB"
            result_size = f"{result_file.stat().st_size / 1024:.1f} KB"
            creation_time = datetime.fromtimestamp(model_file.stat().st_ctime)
            date_str = creation_time.strftime('%d.%m.%Y %H:%M')
            stats = {}
            try:
                with open(result_file, 'rb') as f:
                    results = pickle.load(f)
                    if isinstance(results, dict) and 'final_stats' in results:
                        stats = results['final_stats']
            except Exception:                                          
                pass
            models.append({
                "id": model_id,
                "date": date_str,
                "files": {
                                "model": model_file.name,
                    "model_size": model_size,
                                "replay": replay_file.name,
                    "replay_size": replay_size,
                                "results": result_file.name,
                    "results_size": result_size
                },
                "stats": stats
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        models.sort(key=lambda x: x['date'], reverse=True)
        
        return jsonify({
            "success": True,
            "models": models
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
        
@app.route('/list_ensembles')
def list_ensembles():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∞–Ω—Å–∞–º–±–ª–µ–π –∏ –≤–µ—Ä—Å–∏–π –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.
    Query params: symbol=BTCUSDT (–∏–ª–∏ btc)
    """
    try:
        symbol = (request.args.get('symbol') or '').strip()
        if not symbol:
            return jsonify({"success": False, "error": "symbol –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω"}), 400
        s = symbol.upper().replace('/', '')
        if s.endswith('USDT'):
            s = s[:-4]
        base_code = s.lower()

        from pathlib import Path
        import pickle as _pickle
        root = Path('models') / base_code
        if not root.exists():
            return jsonify({"success": True, "ensembles": {}})

        ensembles = {}
        for ens_dir in root.iterdir():
            if not ens_dir.is_dir():
                continue
            versions = []
            current = None
            canary = None
            # –°–æ–±–∏—Ä–∞–µ–º vN
            for vdir in ens_dir.iterdir():
                if vdir.is_dir() and vdir.name.startswith('v'):
                    # –ò—â–µ–º —Ñ–∞–π–ª—ã –∏ manifest
                    files = { 'model': None, 'replay': None, 'results': None }
                    # –§–æ–ª–±—ç–∫–∏, –µ—Å–ª–∏ –∏–º–µ–Ω–∞ –Ω–µ –ø–æ —à–∞–±–ª–æ–Ω—É
                    fallback_model = None
                    fallback_replay = None
                    fallback_results = None
                    manifest = None
                    stats = {}
                    for f in vdir.iterdir():
                        if f.name.startswith('dqn_model_') and f.suffix == '.pth':
                            files['model'] = f.name
                        elif f.name.startswith('replay_buffer_') and f.suffix == '.pkl':
                            files['replay'] = f.name
                        elif f.name.startswith('train_result_') and f.suffix == '.pkl':
                            files['results'] = f.name
                        elif f.name == 'manifest.yaml':
                            manifest = f.name
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ–ª–±—ç–∫–∏
                        elif f.suffix == '.pth' and fallback_model is None:
                            fallback_model = f.name
                        elif f.suffix == '.pkl':
                            n = f.name.lower()
                            if ('replay' in n) and fallback_replay is None:
                                fallback_replay = f.name
                            if (('train_result' in n) or ('result' in n)) and fallback_results is None:
                                fallback_results = f.name
                    # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ train_result_*.pkl
                    try:
                        # –í—ã–±–æ—Ä —Ñ–∞–π–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º —Ñ–æ–ª–±—ç–∫–æ–≤
                        res_name = files.get('results') or fallback_results
                        if res_name:
                            _res_path = vdir / res_name
                            if _res_path.exists():
                                with open(_res_path, 'rb') as _f:
                                    _res = _pickle.load(_f)
                                    if isinstance(_res, dict) and 'final_stats' in _res:
                                        stats = _res['final_stats'] or {}
                    except Exception:
                        stats = {}
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ–ª–±—ç–∫–∏, –µ—Å–ª–∏ —Å—Ç—Ä–æ–≥–∏–µ –∏–º–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
                    if files['model'] is None and fallback_model is not None:
                        files['model'] = fallback_model
                    if files['replay'] is None and fallback_replay is not None:
                        files['replay'] = fallback_replay
                    if files['results'] is None and fallback_results is not None:
                        files['results'] = fallback_results
                    
                    # –ß–∏—Ç–∞–µ–º ID –∏–∑ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                    manifest_id = None
                    if manifest:
                        try:
                            manifest_path = vdir / manifest
                            if manifest_path.exists():
                                with open(manifest_path, 'r', encoding='utf-8') as mf:
                                    manifest_content = mf.read()
                                    # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å id: "–∑–Ω–∞—á–µ–Ω–∏–µ"
                                    for line in manifest_content.split('\n'):
                                        if line.strip().startswith('id:'):
                                            manifest_id = line.split(':', 1)[1].strip().strip('"\'')
                                            break
                        except Exception:
                            pass
                    
                    versions.append({
                        'version': vdir.name,
                        'files': files,
                        'manifest': manifest,
                        'manifest_id': manifest_id,
                        'stats': stats,
                        'path': str(vdir).replace('\\','/')
                    })
                elif vdir.name == 'current':
                    current = str(vdir).replace('\\','/')
                elif vdir.name == 'canary':
                    canary = str(vdir).replace('\\','/')
            ensembles[ens_dir.name] = {
                'versions': sorted(versions, key=lambda x: int(x['version'][1:]) if x['version'].startswith('v') and x['version'][1:].isdigit() else 0),
                'current': current,
                'canary': canary,
                'path': str(ens_dir).replace('\\','/')
            }

        return jsonify({"success": True, "ensembles": ensembles})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/analyze_model', methods=['POST'])
def analyze_model():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å"""
    import pickle
    from pathlib import Path
    
    try:
        data = request.get_json()
        model_id = data.get('model_id')
        
        if not model_id:
            return jsonify({
                "success": False,
                "error": "ID –º–æ–¥–µ–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω"
            })
        
        # –ò—â–µ–º —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ models/
        result_file = None
        try:
            models_root = Path('models')
            for symbol_dir in models_root.iterdir():
                if not symbol_dir.is_dir():
                    continue
                for ensemble_dir in symbol_dir.iterdir():
                    if not ensemble_dir.is_dir():
                        continue
                    for version_dir in ensemble_dir.iterdir():
                        if not version_dir.is_dir():
                            continue
                        cand = version_dir / f'train_result_{model_id}.pkl'
                        if cand.exists():
                            result_file = cand
                            raise StopIteration
        except StopIteration:
            pass
        except Exception:
            pass
        if result_file is None:
            return jsonify({
                "success": False,
                "error": f"–§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω"
            })
        if not result_file.exists():
            return jsonify({
                "success": False,
                "error": f"–§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω"
            })
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        with open(result_file, 'rb') as f:
            results = pickle.load(f)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑
        analysis = f"""üìä –ê–ù–ê–õ–ò–ó –ú–û–î–ï–õ–ò {model_id}
{'='*50}

üìÖ –î–∞—Ç–∞ –æ–±—É—á–µ–Ω–∏—è: {results.get('training_date', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}
‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {results.get('total_training_time', 0) / 3600:.1f} —á–∞—Å–æ–≤
üéØ –≠–ø–∏–∑–æ–¥–æ–≤: {results.get('actual_episodes', results.get('episodes', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))}

üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
"""
        
        if 'final_stats' in results:
            stats = results['final_stats']
            analysis += f"""
‚Ä¢ Winrate: {stats.get('winrate', 0) * 100:.1f}%
‚Ä¢ P/L Ratio: {stats.get('pl_ratio', 0):.2f}
‚Ä¢ –°–¥–µ–ª–æ–∫: {stats.get('trades_count', 0)}
‚Ä¢ –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å: {stats.get('avg_profit', 0) * 100:.2f}%
‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —É–±—ã—Ç–æ–∫: {stats.get('avg_loss', 0) * 100:.2f}%
‚Ä¢ –ü–ª–æ—Ö–∏—Ö —Å–¥–µ–ª–æ–∫: {stats.get('bad_trades_count', 0)}
"""
        
        if 'all_trades' in results:
            trades = results['all_trades']
            analysis += f"""
üìä –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–î–ï–õ–û–ö:
‚Ä¢ –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {len(trades)}
‚Ä¢ –ü—Ä–∏–±—ã–ª—å–Ω—ã—Ö: {sum(1 for t in trades if t.get('roi', 0) > 0)}
‚Ä¢ –£–±—ã—Ç–æ—á–Ω—ã—Ö: {sum(1 for t in trades if t.get('roi', 0) < 0)}
‚Ä¢ –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö: {sum(1 for t in trades if abs(t.get('roi', 0)) < 0.001)}
"""
        
        return jsonify({
            "success": True,
            "analysis": analysis
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/delete_model', methods=['POST'])
def delete_model():
    """–£–¥–∞–ª—è–µ—Ç –º–æ–¥–µ–ª—å –∏ –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
    from pathlib import Path
    import os
    
    try:
        data = request.get_json()
        model_id = data.get('model_id')
        
        if not model_id:
            return jsonify({
                "success": False,
                "error": "ID –º–æ–¥–µ–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω"
            })
        
        # –£–¥–∞–ª—è–µ–º –º–æ–¥–µ–ª—å –∏–∑ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã models/
        models_root = Path('models')
        deleted_files = []
        if models_root.exists():
            for symbol_dir in models_root.iterdir():
                if not symbol_dir.is_dir():
                    continue
                for ensemble_dir in symbol_dir.iterdir():
                    if not ensemble_dir.is_dir():
                        continue
                    for version_dir in list(ensemble_dir.iterdir()):
                        if not version_dir.is_dir():
                            continue
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —Ñ–∞–π–ª–∞–º –º–æ–¥–µ–ª–∏
                        for name in [f'dqn_model_{model_id}.pth', f'replay_buffer_{model_id}.pkl', f'train_result_{model_id}.pkl']:
                            fp = version_dir / name
                            if fp.exists():
                                try:
                                    os.remove(fp)
                                    deleted_files.append(str(fp))
                                except Exception:
                                    pass
                        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—É—é –≤–µ—Ä—Å–∏—é
                        try:
                            if version_dir.is_dir() and not any(version_dir.iterdir()):
                                import shutil as _sh
                                _sh.rmtree(version_dir, ignore_errors=True)
                        except Exception:
                            pass
        
        if not deleted_files:
            return jsonify({
                "success": False,
                "error": f"–§–∞–π–ª—ã –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            })
        
        return jsonify({
            "success": True,
            "message": f"–ú–æ–¥–µ–ª—å {model_id} —É–¥–∞–ª–µ–Ω–∞",
            "deleted_files": deleted_files
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

# ==================== –¢–û–†–ì–û–í–´–ï ENDPOINT'–´ ====================

@app.route('/api/trading/save_config', methods=['POST'])
def save_trading_config():
    """–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π –∏ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –±–µ–∑ –∑–∞–ø—É—Å–∫–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏."""
    try:
        data = request.get_json() or {}
        try:
            app.logger.info(f"[save_config] payload symbols={data.get('symbols')} sel_paths={len(data.get('model_paths') or [])} counts={(data.get('consensus') or {}).get('counts')}")
            app.logger.info(f"[save_config] FULL payload: {data}")
            # –î–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥ consensus
            consensus = data.get('consensus')
            if consensus:
                app.logger.info(f"[save_config] consensus counts: {consensus.get('counts')}")
                app.logger.info(f"[save_config] consensus percents: {consensus.get('percents')}")
        except Exception:
            pass
        symbols = data.get('symbols') or []
        model_paths = data.get('model_paths') or []
        consensus = data.get('consensus') or None
        import json as _json
        rc = get_redis_client()
        if symbols:
            rc.set('trading:symbols', _json.dumps(symbols, ensure_ascii=False))
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏ –º–æ–¥–µ–ª–µ–π (–∏ –≥–ª–æ–±–∞–ª—å–Ω–æ, –∏ per‚Äësymbol)
        if isinstance(model_paths, list) and len(model_paths) > 0:
            rc.set('trading:model_paths', _json.dumps(model_paths, ensure_ascii=False))
            rc.set('trading:last_model_paths', _json.dumps(model_paths, ensure_ascii=False))
            # –ü–µ—Ä‚Äë—Å–∏–º–≤–æ–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏
            symbol = symbols[0] if symbols else 'ALL'
            rc.set(f'trading:model_paths:{symbol}', _json.dumps(model_paths, ensure_ascii=False))
            try:
                app.logger.info(f"[save_config] symbol={symbol} model_paths_selected={len(model_paths)} -> saved per-symbol model_paths")
            except Exception:
                pass
        # –ù–µ –ø–µ—Ä–µ—Ç–∏—Ä–∞–µ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å –ø—É—Å—Ç—ã–º–∏/–¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        if consensus is not None and isinstance(model_paths, list) and len(model_paths) > 0:
            symbol = symbols[0] if symbols else 'ALL'
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º total_selected —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º —Å–ø–∏—Å–∫–æ–º
            try:
                c = consensus.get('counts') if isinstance(consensus, dict) else None
                if isinstance(c, dict):
                    before = dict(c)
                    c['total_selected'] = len(model_paths)
                    app.logger.info(f"[save_config] symbol={symbol} counts_in={before} -> counts_saved={c}")
            except Exception:
                pass
            rc.set(f'trading:consensus:{symbol}', _json.dumps(consensus, ensure_ascii=False))
            try:
                app.logger.info(f"[save_config] symbol={symbol} consensus saved")
            except Exception:
                pass
        try:
            app.logger.info("[save_config] ‚úì done")
        except Exception:
            pass
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/trading/start', methods=['POST'])
def start_trading():
    """
    –ó–∞–ø—É—Å–∫ —Ç–æ—Ä–≥–æ–≤–ª–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ trading_agent —á–µ—Ä–µ–∑ Celery –∑–∞–¥–∞—á—É
    """
    try:
        data = request.get_json() or {}
        symbols = data.get('symbols', ['BTCUSDT'])
        account_id = str(data.get('account_id') or '').strip()
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞: model_paths (—Å–ø–∏—Å–æ–∫) + —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å model_path
        model_paths = data.get('model_paths') or []
        model_path = data.get('model_path')
        if (not model_path) and isinstance(model_paths, list) and len(model_paths) > 0:
            model_path = model_paths[0]
        if not model_path:
            model_path = '/workspace/models/btc/ensemble-a/current/dqn_model.pth'
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ Redis –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –≤—ã–∑–æ–≤–æ–≤ (status/stop/balance/history)
        try:
            import json as _json
            _rc = get_redis_client()
            _rc.set('trading:model_path', model_path)
            # –ù–ï –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±—â–∏–µ –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –Ω–µ —É–±–∏—Ç—å –¥—Ä—É–≥–∏–µ –∞–≥–µ–Ω—Ç—ã
            # try:
            #     if isinstance(model_paths, list):
            #         _rc.set('trading:model_paths', _json.dumps(model_paths, ensure_ascii=False))
            # except Exception:
            #     pass
            # –ù–ï –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±—â–∏–µ —Å–∏–º–≤–æ–ª—ã, —á—Ç–æ–±—ã –Ω–µ —É–±–∏—Ç—å –¥—Ä—É–≥–∏–µ –∞–≥–µ–Ω—Ç—ã
            # _rc.set('trading:symbols', _json.dumps(symbols, ensure_ascii=False))
            if account_id:
                _rc.set('trading:account_id', account_id)
            # –ö–æ–Ω—Å–µ–Ω—Å—É—Å (counts/percents) ‚Äî –∑–∞–ø–æ–º–∏–Ω–∞–µ–º –≤—ã–±–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            try:
                consensus = data.get('consensus')
                if consensus is not None:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
                    symbol = symbols[0] if symbols else 'ALL'
                    _rc.set(f'trading:consensus:{symbol}', _json.dumps(consensus, ensure_ascii=False))
                    # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–æ–ª—å—à–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞, —á—Ç–æ–±—ã –∞–≥–µ–Ω—Ç—ã –Ω–µ –ø–µ—Ä–µ—Ç–∏—Ä–∞–ª–∏ –¥—Ä—É–≥ –¥—Ä—É–≥–∞
            except Exception:
                pass
            # –û–±–Ω–æ–≤–∏–º last_model_paths –¥–ª—è —Ñ–æ–ª–±—ç–∫–∞ —Ç–∏–∫–æ–≤
            try:
                if isinstance(model_paths, list) and model_paths:
                    _rc.set('trading:last_model_paths', _json.dumps(model_paths, ensure_ascii=False))
            except Exception:
                pass
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            symbol = symbols[0] if symbols else 'ALL'
            _rc.set(f'trading:symbols:{symbol}', _json.dumps(symbols, ensure_ascii=False))
            _rc.set(f'trading:model_path:{symbol}', model_path)
            if isinstance(model_paths, list):
                _rc.set(f'trading:model_paths:{symbol}', _json.dumps(model_paths, ensure_ascii=False))
            
            # –ü–∏—à–µ–º –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–π ¬´–∞–∫—Ç–∏–≤–Ω—ã–π¬ª —Å—Ç–∞—Ç—É—Å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            initial_status = {
                'success': True,
                'is_trading': True,
                'trading_status': '–ê–∫—Ç–∏–≤–Ω–∞',
                'trading_status_emoji': 'üü¢',
                'trading_status_full': 'üü¢ –ê–∫—Ç–∏–≤–Ω–∞',
                'symbol': symbol,
                'symbol_display': symbol,
                'amount': None,
                'amount_display': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
                'amount_usdt': 0.0,
                'position': None,
                'trades_count': 0,
                'balance': {},
                'current_price': 0.0,
                'last_model_prediction': None,
            }
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            _rc.set(f'trading:status:{symbol}', _json.dumps(initial_status, ensure_ascii=False))
            # –ù–ï –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å, —á—Ç–æ–±—ã –Ω–µ —É–±–∏—Ç—å –¥—Ä—É–≥–∏–µ –∞–≥–µ–Ω—Ç—ã
            # _rc.set('trading:current_status', _json.dumps(initial_status, ensure_ascii=False))
            from datetime import datetime as _dt
            _rc.set('trading:current_status_ts', _dt.utcnow().isoformat())
        except Exception as _e:
            app.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–æ—Ä–≥–æ–≤–ª–∏ –≤ Redis: {_e}")

        # Redis-–ª–æ–∫: –µ—Å–ª–∏ —É–∂–µ –∏–¥—ë—Ç —Ç–æ—Ä–≥–æ–≤—ã–π —à–∞–≥ –¥–ª—è —ç—Ç–æ–≥–æ —Å–∏–º–≤–æ–ª–∞, –Ω–µ —Å—Ç–∞—Ä—Ç—É–µ–º –≤—Ç–æ—Ä–æ–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        try:
            _rc_lock = get_redis_client()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            symbol = symbols[0] if symbols else 'ALL'
            lock_key = f'trading:agent_lock:{symbol}'
            if _rc_lock.get(lock_key):
                return jsonify({
                    'success': False,
                    'error': f'–¢–æ—Ä–≥–æ–≤—ã–π —à–∞–≥ –¥–ª—è {symbol} —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è (agent_lock_active)'
                }), 429
        except Exception:
            pass

        # –ó–∞–ø—É—Å–∫–∞–µ–º Celery –∑–∞–¥–∞—á—É –¥–ª—è —Å—Ç–∞—Ä—Ç–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏ –≤ –æ—á–µ—Ä–µ–¥–∏ 'celery'
        task = start_trading_task.apply_async(args=[symbols, model_path], countdown=0, expires=300, queue='celery')
        
        return jsonify({
            'success': True,
            'message': '–¢–æ—Ä–≥–æ–≤–ª—è –∑–∞–ø—É—â–µ–Ω–∞ —á–µ—Ä–µ–∑ Celery –∑–∞–¥–∞—á—É',
            'task_id': task.id
        }), 200
    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏: {e}")
        return jsonify({
            'success': False, 
            'error': str(e)
        }), 500

@app.route('/api/trading/stop', methods=['POST'])
def stop_trading():
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ trading_agent"""
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Docker
        client = docker.from_env()
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä medoedai
            container = client.containers.get('medoedai')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—â–µ–Ω
            if container.status != 'running':
                return jsonify({
                    'success': False, 
                    'error': f'–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä medoedai –Ω–µ –∑–∞–ø—É—â–µ–Ω. –°—Ç–∞—Ç—É—Å: {container.status}'
                }), 500
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–Ω–µ–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            model_path = None
            try:
                mp = redis_client.get('trading:model_path')
                if mp:
                    model_path = mp.decode('utf-8')
            except Exception:
                pass

            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ—Ä–≥–æ–≤–ª—é —á–µ—Ä–µ–∑ exec
            if model_path:
                cmd = f'python -c "import json; from trading_agent.trading_agent import TradingAgent; agent = TradingAgent(model_path=\\"{model_path}\\"); result = agent.stop_trading(); print(\\"RESULT: \\" + json.dumps(result))"'
            else:
                cmd = 'python -c "import json; from trading_agent.trading_agent import TradingAgent; agent = TradingAgent(); result = agent.stop_trading(); print(\\"RESULT: \\" + json.dumps(result))"'
            
            exec_result = container.exec_run(cmd, tty=True)
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã
            app.logger.info(f"Stop trading - Exit code: {exec_result.exit_code}")
            if exec_result.output:
                output_str = exec_result.output.decode('utf-8')
                app.logger.info(f"Stop trading - Output: {output_str}")
            
            if exec_result.exit_code == 0:
                output = exec_result.output.decode('utf-8') if exec_result.output else ""
                # –ò—â–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤—ã–≤–æ–¥–µ
                if 'RESULT:' in output:
                    result_str = output.split('RESULT:')[1].strip()
                    try:
                        import json
                        result = json.loads(result_str)
                        return jsonify(result), 200
                    except Exception as parse_error:
                        app.logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {parse_error}")
                        return jsonify({
                            'success': True,
                            'message': '–¢–æ—Ä–≥–æ–≤–ª—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞',
                            'output': output
                        }), 200
                else:
                    return jsonify({
                        'success': True,
                        'message': '–¢–æ—Ä–≥–æ–≤–ª—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞',
                        'output': output
                    }), 200
            else:
                error_output = exec_result.output.decode('utf-8') if exec_result.output else "No error output"
                app.logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ç–æ—Ä–≥–æ–≤–ª–∏: {error_output}")
                return jsonify({
                    'success': False,
                    'error': f'–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã: {error_output}'
                }), 500
                
        except docker.errors.NotFound:
            return jsonify({
                'success': False, 
                'error': '–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä medoedai –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ docker-compose up medoedai'
            }), 500
        except Exception as e:
            return jsonify({
                'success': False, 
                'error': f'–û—à–∏–±–∫–∞ Docker: {str(e)}'
            }), 500
# –ü–µ—Ä–µ—Ö–≤–∞—Ç –≤–Ω–µ—à–Ω–µ–≥–æ try –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ stop_trading
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'–û—à–∏–±–∫–∞ stop_trading: {str(e)}'
        }), 500

# –ù–æ–≤—ã–π —É–ø—Ä–æ—â—ë–Ω–Ω—ã–π —Å—Ç–æ–ø –ø–æ —Å–∏–º–≤–æ–ª—É: —Å–Ω–∏–º–∞–µ–º Redis-–ª–æ–∫ –∏ –ø–æ–º–µ—á–∞–µ–º —Å—Ç–∞—Ç—É—Å –∫–∞–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π
@app.route('/api/trading/stop_symbol', methods=['POST'])
def stop_trading_symbol():
    try:
        data = request.get_json(silent=True) or {}
        symbol = str(data.get('symbol') or '').strip().upper()
        if not symbol:
            return jsonify({'success': False, 'error': 'symbol is required'}), 400
        rc = get_redis_client()
        # –°–Ω–∏–º–∞–µ–º –ª–æ–∫
        try:
            rc.delete(f'trading:agent_lock:{symbol}')
        except Exception:
            pass
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        try:
            import json as _json
            raw = rc.get(f'trading:status:{symbol}')
            status = _json.loads(raw) if raw else {}
            if not isinstance(status, dict):
                status = {}
            status.update({
                'is_trading': False,
                'trading_status': '–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞',
                'trading_status_emoji': 'üî¥',
                'trading_status_full': 'üî¥ –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'
            })
            rc.set(f'trading:status:{symbol}', _json.dumps(status, ensure_ascii=False))
        except Exception:
            pass
        return jsonify({'success': True, 'symbol': symbol})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# –°–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω—Ñ–∞ –ø–æ –∫–∞–∂–¥–æ–º—É
@app.route('/api/trading/agents', methods=['GET'])
def list_trading_agents():
    try:
        import json as _json
        from datetime import datetime as _dt
        rc = get_redis_client()
        # –ë–∞–∑–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
        known = ['BTCUSDT','ETHUSDT','SOLUSDT','TONUSDT','ADAUSDT','BNBUSDT','XRPUSDT']
        agents = []
        for sym in known:
            # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –ª–æ–∫–∞–º (–º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ —Ä–µ—Å—Ç–∞—Ä—Ç–∞)
            try:
                ttl = rc.ttl(f'trading:agent_lock:{sym}')
            except Exception:
                ttl = None
            # –°—Ç–∞—Ç—É—Å per-symbol
            try:
                raw = rc.get(f'trading:status:{sym}')
                status = _json.loads(raw) if raw else None
            except Exception:
                status = None
            # –§–æ–ª–±—ç–∫ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: –µ—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –≥–æ–≤–æ—Ä–∏—Ç, —á—Ç–æ —Ç–æ—Ä–≥—É–µ–º ‚Äî —Å—á–∏—Ç–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–º
            try:
                is_trading_flag = bool(status and (status.get('is_trading') is True or str(status.get('trading_status') or '').strip() in ('–ê–∫—Ç–∏–≤–Ω–∞','üü¢ –ê–∫—Ç–∏–≤–Ω–∞')))
            except Exception:
                is_trading_flag = False
            is_active = ((ttl is not None and isinstance(ttl, int) and ttl > 0) or is_trading_flag)
            # –ö–æ–Ω—Å–µ–Ω—Å—É—Å per-symbol
            try:
                cons_raw = rc.get(f'trading:consensus:{sym}')
                consensus = _json.loads(cons_raw) if cons_raw else None
            except Exception:
                consensus = None
            try:
                app.logger.info(f"[agents] {sym}: raw_consensus={consensus}")
            except Exception:
                pass
            # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
            total_models = 0
            try:
                mps_raw = rc.get(f'trading:model_paths:{sym}')
                if mps_raw:
                    parsed = _json.loads(mps_raw)
                    if isinstance(parsed, list):
                        total_models = len(parsed)
            except Exception:
                total_models = 0
            # –í—ã—á–∏—Å–ª—è–µ–º —Ç—Ä–µ–±—É–µ–º—ã–µ –ø–æ—Ä–æ–≥–∏ —Ç–∞–∫ –∂–µ, –∫–∞–∫ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
            def _required(total_sel: int, counts: dict | None, regime: str) -> tuple[int,int,int,str,int]:
                req_flat = None
                req_trend = None
                try:
                    c = counts or {}
                    if isinstance(c.get('flat'), (int, float)):
                        req_flat = int(max(1, c.get('flat')))
                    if isinstance(c.get('trend'), (int, float)):
                        req_trend = int(max(1, c.get('trend')))
                except Exception:
                    pass
                default_req = 2 if total_sel >= 3 else max(1, total_sel)
                if req_flat is None:
                    req_flat = default_req
                if req_trend is None:
                    req_trend = default_req
                req_flat = int(min(max(1, req_flat), total_sel if total_sel>0 else 1))
                req_trend = int(min(max(1, req_trend), total_sel if total_sel>0 else 1))
                req_type = 'trend' if regime in ('uptrend','downtrend') else 'flat'
                required = (req_trend if req_type=='trend' else req_flat)
                return total_sel, req_flat, req_trend, req_type, required
            counts = (consensus or {}).get('counts') if isinstance(consensus, dict) else None
            regime = (status or {}).get('market_regime') or 'flat'
            # –ù–∞—Å–∏–ª—å–Ω–æ –ø—Ä–∏–≤–æ–¥–∏–º total_selected –∫ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–º—É –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–µ–π
            try:
                if isinstance(counts, dict):
                    before_ts = counts.get('total_selected')
                    counts['total_selected'] = total_models
                    try:
                        app.logger.info(f"[agents] {sym}: total_models={total_models}, counts_in_ts={before_ts}, counts_out_ts={counts.get('total_selected')}, flat={counts.get('flat')}, trend={counts.get('trend')}, regime={regime}")
                    except Exception:
                        pass
                    # –ï—Å–ª–∏ –∏—Å–ø—Ä–∞–≤–∏–ª–∏ –≤ –ø–∞–º—è—Ç–∏, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ Redis
                    if before_ts != total_models and total_models > 0:
                        try:
                            consensus['counts'] = counts
                            rc.set(f'trading:consensus:{sym}', _json.dumps(consensus, ensure_ascii=False))
                            app.logger.info(f"[agents] {sym}: FIXED Redis total_selected {before_ts} -> {total_models}")
                        except Exception as e:
                            app.logger.error(f"[agents] {sym}: Failed to fix Redis: {e}")
            except Exception:
                pass
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ total_selected –∏–∑ counts
            corrected_total = counts.get('total_selected', total_models) if isinstance(counts, dict) else total_models
            total_sel, req_flat, req_trend, req_type, required = _required(corrected_total, counts, regime)
            try:
                app.logger.info(f"[agents] {sym}: required={required} ({req_type}), req_flat={req_flat}, req_trend={req_trend}")
            except Exception:
                pass
            agent_obj = {
                'symbol': sym,
                'active': bool(is_active),
                'status': status or {},
                'consensus': consensus or {},
                'total_models': total_models,
                'required_flat': req_flat,
                'required_trend': req_trend,
                'required_type': req_type,
                'required': required,
                'lock_ttl': (int(ttl) if ttl is not None else None)
            }
            try:
                app.logger.info(f"[agents] {sym}: agent_obj={agent_obj}")
            except Exception:
                pass
            agents.append(agent_obj)
        return jsonify({'success': True, 'agents': agents, 'ts': _dt.utcnow().isoformat()})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500
            
    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ç–æ—Ä–≥–æ–≤–ª–∏: {e}")
        return jsonify({
            'success': False, 
            'error': str(e)
        }), 500

@app.route('/api/trading/status', methods=['GET'])
def trading_status():
    """–°—Ç–∞—Ç—É—Å —Ç–æ—Ä–≥–æ–≤–ª–∏ –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ trading_agent"""
    try:
        # –í—Ö–æ–¥–Ω–∞—è —Ç–æ—á–∫–∞: —Ñ–∏–∫—Å–∏—Ä—É–µ–º –≤—ã–∑–æ–≤ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞
        try:
            app.logger.info("[trading_status] ‚ñ∂ request received")
        except Exception:
            pass
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ç—É—Å –∏–∑ Redis (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–º —Ç–∞—Å–∫–æ–º)
        try:
            _rc = get_redis_client()
            cached = _rc.get('trading:current_status')
            cached_ts = _rc.get('trading:current_status_ts')
            if cached:
                import json as _json
                status_obj = _json.loads(cached)
                # –ü—Ä–æ–≤–µ—Ä–∏–º —Å–≤–µ–∂–µ—Å—Ç—å (–Ω–µ —Å—Ç–∞—Ä–µ–µ 6 –º–∏–Ω—É—Ç, > –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ beat)
                from datetime import datetime, timedelta
                is_fresh = True
                try:
                    if cached_ts:
                        from datetime import datetime as _dt
                        ts = _dt.fromisoformat(cached_ts)
                        is_fresh = _dt.utcnow() <= (ts + timedelta(minutes=6))
                except Exception:
                    is_fresh = True
                if is_fresh:
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–ª–æ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–æ–º
                    flat = {'success': True, 'agent_status': status_obj}
                    if isinstance(status_obj, dict):
                        flat.update(status_obj)
                    try:
                        app.logger.info(f"[trading_status] ‚úì using cached status | keys={list(flat.keys())}")
                        # –ö—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä –≤–∞–∂–Ω—ã—Ö –ø–æ–ª–µ–π
                        app.logger.info("[trading_status] summary: is_trading=%s, position=%s, trades_count=%s",
                                        flat.get('is_trading'), bool(flat.get('position') or flat.get('current_position')), flat.get('trades_count'))
                    except Exception:
                        pass
                    return jsonify(flat), 200
        except Exception:
            pass

        # –ù–µ—Ç —Å–≤–µ–∂–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ –≤ Redis ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–Ω—è—Ç–Ω—ã–π OFF —Å—Ç–∞—Ç—É—Å –¥–ª—è UI
        try:
            default_status = {
                'success': True,
                'is_trading': False,
                'trading_status': '–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞',
                'trading_status_emoji': 'üî¥',
                'trading_status_full': 'üî¥ –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ (–∞–≥–µ–Ω—Ç –Ω–µ –∑–∞–ø—É—â–µ–Ω)',
                'symbol': None,
                'symbol_display': '–ù–µ —É–∫–∞–∑–∞–Ω–∞',
                'amount': None,
                'amount_display': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
                'amount_usdt': 0.0,
                'position': None,
                'trades_count': 0,
                'balance': {},
                'current_price': 0.0,
                'last_model_prediction': None,
                'is_fresh': False,
                'reason': 'status not available in redis'
            }
            flat = {'success': True, 'agent_status': default_status}
            flat.update(default_status)
            try:
                app.logger.info("[trading_status] ‚ö† no redis status, returning OFF state")
            except Exception:
                pass
            return jsonify(flat), 200
        except Exception:
            return jsonify({'success': False, 'error': 'status not available in redis', 'is_fresh': False}), 200
            
    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
        return jsonify({
            'success': False, 
            'error': str(e)
        }), 500

@app.route('/api/trading/status_all', methods=['GET'])
def trading_status_all():
    """–°—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤"""
    try:
        _rc = get_redis_client()
        active_agents = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å—ã –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ
        symbols = ['BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'TONUSDT', 'ADAUSDT', 'BNBUSDT', 'XRPUSDT']
        
        for symbol in symbols:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
                status_key = f'trading:status:{symbol}'
                status_data = _rc.get(status_key)
                
                if status_data:
                    import json as _json
                    status_obj = _json.loads(status_data)
                    if isinstance(status_obj, dict) and status_obj.get('is_trading'):
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞
                        lock_key = f'trading:agent_lock:{symbol}'
                        ttl = _rc.ttl(lock_key)
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –ª–æ–≥–∏–∫—É —á—Ç–æ –∏ –≤ /api/trading/agents
                        # –ê–≥–µ–Ω—Ç –∞–∫—Ç–∏–≤–µ–Ω –µ—Å–ª–∏ –ª–∏–±–æ lock TTL > 0, –ª–∏–±–æ —Å—Ç–∞—Ç—É—Å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç is_trading
                        is_trading_flag = bool(status_obj.get('is_trading') is True or 
                                             str(status_obj.get('trading_status') or '').strip() in ('–ê–∫—Ç–∏–≤–Ω–∞','üü¢ –ê–∫—Ç–∏–≤–Ω–∞'))
                        is_active = ((ttl is not None and isinstance(ttl, int) and ttl > 0) or is_trading_flag)
                        
                        if is_active:
                            agent_status = {
                                'symbol': symbol,
                                'is_active': True,
                                'ttl_seconds': int(ttl) if ttl is not None and ttl > 0 else 0,
                                'status': '–ê–∫—Ç–∏–≤–Ω–∞',
                                'current_price': status_obj.get('current_price'),
                                'position': status_obj.get('position'),
                                'trades_count': status_obj.get('trades_count'),
                                'last_prediction': status_obj.get('last_model_prediction'),
                                'amount': status_obj.get('amount'),
                                'amount_display': status_obj.get('amount_display')
                            }
                            active_agents.append(agent_status)
            except Exception:
                continue
        
        return jsonify({
            'success': True,
            'active_agents': active_agents,
            'total_active': len(active_agents)
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False, 
            'error': str(e)
        }), 500

@app.route('/api/trading/latest_results', methods=['GET'])
def trading_latest_results():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–æ—Ä–≥–æ–≤–ª–∏ –∏–∑ Celery"""
    try:
        requested_symbol = (request.args.get('symbol') or '').upper().strip()
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ Redis (–∫–ª—é—á–∏ —Å —Ç–∞–π–º—Å—Ç–∞–º–ø–æ–º)
        latest_results = []
        try:
            keys = redis_client.keys('trading:latest_result_*') or []
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            for k in keys:
                try:
                    raw = redis_client.get(k)
                    if not raw:
                        continue
                    try:
                        result = json.loads(raw.decode('utf-8'))
                    except Exception:
                        result = json.loads(raw)
                    latest_results.append(result)
                except Exception as e:                
                        app.logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {k}: {e}")
        except Exception as e:
            app.logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª—é—á–µ–π trading:latest_result_*: {e}")

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å–∏–º–≤–æ–ª—É, –µ—Å–ª–∏ –∑–∞–¥–∞–Ω
        if requested_symbol:
            try:
                latest_results = [r for r in latest_results if isinstance(r.get('symbols'), list) and requested_symbol in r.get('symbols')]
            except Exception:
                pass
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        try:
            latest_results.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        except Exception:
            pass
        
        return jsonify({
            'success': True,
            'latest_results': latest_results,
            'total_results': len(latest_results)
        }), 200
        
    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/trading/balance', methods=['GET'])
def trading_balance():
    """–ë–∞–ª–∞–Ω—Å –±–µ—Ä—ë–º –∏–∑ Redis-–∫—ç—à–∞ trading:current_status. –ë–µ–∑ Docker exec."""
    try:
        _rc = get_redis_client()
        cached = _rc.get('trading:current_status') if _rc else None
        resp_obj = None
        if cached:
            import json as _json
            try:
                st = _json.loads(cached)
                if isinstance(st, dict) and st.get('balance'):
                    resp_obj = {
                        'success': True,
                        'balance': st.get('balance'),
                        'is_trading': st.get('is_trading', False),
                        'is_fresh': st.get('is_fresh', False)
                    }
            except Exception:
                resp_obj = None

        if resp_obj is None:
            resp_obj = {
                'success': True,
                'balance': {},
                'message': 'balance not available (agent not running)'
            }

        return jsonify(resp_obj), 200
    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –±–∞–ª–∞–Ω—Å–∞: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/trading/test_order', methods=['POST'])
def trading_test_order():
    """–ú–≥–Ω–æ–≤–µ–Ω–Ω–æ–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ –†–ï–ê–õ–¨–ù–û–ì–û —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –æ—Ä–¥–µ—Ä–∞ BUY/SELL –≤ –æ–±—Ö–æ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
    –ù–∏—á–µ–≥–æ –Ω–µ –ø–∏—à–µ—Ç –≤ –ë–î/–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥. –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ medoedai —á–µ—Ä–µ–∑ TradingAgent.execute_direct_order.
    Body: { action: 'buy'|'sell', symbol?: 'BTCUSDT', quantity?: float }
    """
    try:
        data = request.get_json() or {}
        action = (data.get('action') or '').lower()
        symbol = data.get('symbol')
        quantity = data.get('quantity')

        if action not in ('buy', 'sell'):
            return jsonify({'success': False, 'error': "action –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'buy' –∏–ª–∏ 'sell'"}), 400

        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Docker
        client = docker.from_env()
        try:
            container = client.containers.get('medoedai')
            if container.status != 'running':
                return jsonify({'success': False, 'error': f'–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä medoedai –Ω–µ –∑–∞–ø—É—â–µ–Ω. –°—Ç–∞—Ç—É—Å: {container.status}'}), 500

            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–Ω–µ–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å), —á—Ç–æ–±—ã TradingAgent –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –±–∏—Ä–∂—É
            model_path = None
            try:
                mp = redis_client.get('trading:model_path')
                if mp:
                    model_path = mp.decode('utf-8')
            except Exception:
                pass

            # –§–æ—Ä–º–∏—Ä—É–µ–º python-–∫–æ–º–∞–Ω–¥—É –±–µ–∑ –≤–ª–æ–∂–µ–Ω–Ω–æ–≥–æ JSON, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å –∫–∞–≤—ã—á–∫–∞–º–∏
            def _py_str_literal(s):
                if s is None:
                    return 'None'
                return "'" + str(s).replace("'", "\\'") + "'"

            py_action = _py_str_literal(action)
            py_symbol = _py_str_literal(symbol)
            py_quantity = 'None' if quantity is None else str(float(quantity))

            def _disc():
                ak = os.environ.get('BYBIT_1_API_KEY')
                sk = os.environ.get('BYBIT_1_SECRET_KEY')
                if ak and sk:
                    return ak, sk
                # –ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–≥–æ BYBIT_<ID>_*
                c = []
                for k, v in os.environ.items():
                    if not k.startswith('BYBIT_') or not k.endswith('_API_KEY'):
                        continue
                    idx = k[len('BYBIT_'):-len('_API_KEY')]
                    sec = f'BYBIT_{idx}_SECRET_KEY'
                    sv = os.environ.get(sec)
                    if v and sv:
                        c.append((k, v, sec, sv))
                if c:
                    c.sort(key=lambda x: x[0])
                    return c[0][1], c[0][3]
                return '', ''
            api_key, secret_key = _disc()
            api_key_esc = api_key.replace("'", "\\'")
            secret_key_esc = secret_key.replace("'", "\\'")
            if model_path:
                cmd = (
                    f"python -c \"import json, os; os.environ['BYBIT_1_API_KEY']='{api_key_esc}'; os.environ['BYBIT_1_SECRET_KEY']='{secret_key_esc}'; "
                    f"from trading_agent.trading_agent import TradingAgent; agent = TradingAgent(model_path=\\\"{model_path}\\\"); "
                    f"action = {py_action}; symbol = {py_symbol}; quantity = {py_quantity}; "
                    f"result = agent.execute_direct_order(action, symbol, quantity); print(\\\"RESULT: \\\" + json.dumps(result))\""
                )
            else:
                cmd = (
                    "python -c \"import json, os; os.environ['BYBIT_1_API_KEY']='{api_key_esc}'; os.environ['BYBIT_1_SECRET_KEY']='{secret_key_esc}'; "
                    "from trading_agent.trading_agent import TradingAgent; agent = TradingAgent(); "
                    f"action = {py_action}; symbol = {py_symbol}; quantity = {py_quantity}; "
                    "result = agent.execute_direct_order(action, symbol, quantity); print(\\\"RESULT: \\\" + json.dumps(result))\""
                )

            exec_result = container.exec_run(cmd, tty=True)
            output = exec_result.output.decode('utf-8') if exec_result.output else ''
            app.logger.info(f"test_order exit={exec_result.exit_code} output={output}")

            if exec_result.exit_code == 0 and 'RESULT:' in output:
                result_str = output.split('RESULT:')[1].strip()
                try:
                    import json
                    result = json.loads(result_str)
                except Exception as parse_err:
                    return jsonify({'success': False, 'error': f'–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {parse_err}', 'raw_output': output}), 500
                return jsonify(result), 200
            else:
                return jsonify({'success': False, 'error': '–ö–æ–º–∞–Ω–¥–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π', 'raw_output': output}), 500

        except docker.errors.NotFound:
            return jsonify({'success': False, 'error': '–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä medoedai –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 500
        except Exception as e:
            return jsonify({'success': False, 'error': f'–û—à–∏–±–∫–∞ Docker: {str(e)}'}), 500

    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ test_order: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/trades/recent', methods=['GET'])
def get_recent_trades_api():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–¥–µ–ª–æ–∫ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:

        
        limit = request.args.get('limit', 50, type=int)
        trades = get_recent_trades(limit=limit)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        trades_data = []
        for trade in trades:
            trades_data.append({
                'trade_number': trade.trade_number,
                'symbol': trade.symbol.name if trade.symbol else 'Unknown',
                'action': trade.action,
                'status': trade.status,
                'quantity': trade.quantity,
                'price': trade.price,
                'total_value': trade.total_value,
                'model_prediction': trade.model_prediction,
                'current_balance': trade.current_balance,
                'position_pnl': trade.position_pnl,
                'created_at': trade.created_at.isoformat() if trade.created_at else None,
                'executed_at': trade.executed_at.isoformat() if trade.executed_at else None,
                'is_successful': trade.is_successful,
                'error_message': trade.error_message
            })
        
        return jsonify({
            'success': True,
            'trades': trades_data,
            'total_trades': len(trades_data)
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/trades/statistics', methods=['GET'])
def get_trade_statistics_api():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–¥–µ–ª–∫–∞–º"""
    try:

        
        symbol = request.args.get('symbol', None)
        stats = get_trade_statistics(symbol_name=symbol)
        
        return jsonify({
            'success': True,
            'statistics': stats
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/trades/by_symbol/<symbol_name>', methods=['GET'])
def get_trades_by_symbol_api(symbol_name):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫ –ø–æ —Å–∏–º–≤–æ–ª—É"""
    try:

        
        limit = request.args.get('limit', 100, type=int)
        trades = get_trades_by_symbol(symbol_name, limit=limit)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        trades_data = []
        for trade in trades:
            trades_data.append({
                'trade_number': trade.trade_number,
                'symbol': trade.symbol.name if trade.symbol else 'Unknown',
                'action': trade.action,
                'status': trade.status,
                'quantity': trade.quantity,
                'price': trade.price,
                'total_value': trade.total_value,
                'model_prediction': trade.model_prediction,
                'current_balance': trade.current_balance,
                'position_pnl': trade.position_pnl,
                'created_at': trade.created_at.isoformat() if trade.created_at else None,
                'executed_at': trade.executed_at.isoformat() if trade.executed_at else None,
                'is_successful': trade.is_successful,
                'error_message': trade.error_message
            })
        
        return jsonify({
            'success': True,
            'trades': trades_data,
            'total_trades': len(trades_data),
            'symbol': symbol_name
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/trades/matched_full', methods=['GET'])
def get_matched_full_trades():
    """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç BUY‚ÜíSELL —Å–¥–µ–ª–∫–∏ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –≤ —Ç–æ–π –∂–µ 5–º —Å–≤–µ—á–µ (–¥–æ–ø—É—Å–∫ ¬±1 —Å–≤–µ—á–∞)."""
    try:
        symbol = request.args.get('symbol')
        limit_trades = request.args.get('limit_trades', 200, type=int)
        limit_predictions = request.args.get('limit_predictions', 1000, type=int)
        tolerance_buckets = request.args.get('tolerance_buckets', 1, type=int)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–¥–µ–ª–∫–∏
        if symbol:
            trades = get_trades_by_symbol(symbol_name=symbol, limit=limit_trades)
        else:
            trades = get_recent_trades(limit=limit_trades)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        preds = get_model_predictions(symbol=symbol, action=None, limit=limit_predictions)

        # –•–µ–ª–ø–µ—Ä—ã
        def unify_symbol(s: str) -> str:
            try:
                return (s or '').upper().replace('/', '')
            except Exception:
                return ''

        def to_ms(v):
            if not v:
                return None
            try:
                if isinstance(v, (int, float)):
                    return int(v)
                s = str(v)
                # ISO –±–µ–∑ TZ —Ç—Ä–∞–∫—Ç—É–µ–º –∫–∞–∫ UTC
                has_tz = ('Z' in s) or ('z' in s) or ('+' in s) or ('-' in s and 'T' in s and s.rfind('-') > s.find('T'))
                if not has_tz and len(s) >= 19 and s[10] == 'T':
                    s = s + 'Z'
                from datetime import datetime
                dt = datetime.fromisoformat(s.replace('Z', '+00:00'))
                return int(dt.timestamp() * 1000)
            except Exception:
                return None

        def bucket_5m(ms: int):
            return None if ms is None else (ms // 300000)

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: bucket ‚Üí symbol ‚Üí {buy, sell, hold}
        preds_by_bucket = {}
        for p in preds:
            ts = to_ms(p.timestamp.isoformat() if getattr(p, 'timestamp', None) else None)
            b = bucket_5m(ts)
            if b is None:
                continue
            act = (p.action or '').lower()
            sym = unify_symbol(getattr(p, 'symbol', ''))
            if b not in preds_by_bucket:
                preds_by_bucket[b] = {}
            if sym not in preds_by_bucket[b]:
                preds_by_bucket[b][sym] = { 'buy': [], 'sell': [], 'hold': [] }
            if act in preds_by_bucket[b][sym]:
                try:
                    q_vals = json.loads(p.q_values) if p.q_values else []
                except Exception:
                    q_vals = []
                preds_by_bucket[b][sym][act].append({
                    'timestamp': getattr(p.timestamp, 'isoformat', lambda: None)(),
                    'symbol': getattr(p, 'symbol', None),
                    'action': p.action,
                    'q_values': q_vals,
                    'current_price': getattr(p, 'current_price', None),
                    'position_status': getattr(p, 'position_status', None),
                    'confidence': getattr(p, 'confidence', None),
                    'model_path': getattr(p, 'model_path', None),
                })

        def pick_pred(bkt: int, sym_u: str, typ: str):
            for delta in [0] + [d for d in range(-tolerance_buckets, tolerance_buckets+1) if d != 0]:
                bb = bkt + delta
                bucket = preds_by_bucket.get(bb)
                if not bucket:
                    continue
                by_sym = bucket.get(sym_u)
                if not by_sym:
                    continue
                arr = by_sym.get(typ) or []
                if arr:
                    return arr[0]
            return None

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–¥–µ–ª–∫–∏ –∏ —Å–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä—ã BUY‚ÜíSELL (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ù–ï –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã)
        norm_trades = []
        for t in trades:
            ms = to_ms((t.executed_at or t.created_at or None).isoformat() if getattr(t, 'executed_at', None) or getattr(t, 'created_at', None) else None)
            act_raw = (t.action or '').lower()
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ: —Å—á–∏—Ç–∞–µ–º sell_partial –∫–∞–∫ sell
            if 'buy' in act_raw:
                act = 'buy'
            elif 'sell' in act_raw:
                act = 'sell'
            else:
                continue
            sym = unify_symbol(t.symbol.name if getattr(t, 'symbol', None) else getattr(t, 'symbol', '') or '')
            price = float(getattr(t, 'price', 0.0) or 0.0)
            if not (price and price > 0):
                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω—É–ª–µ–≤—ã–µ/–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ü–µ–Ω—ã –∫–∞–∫ —à—É–º
                continue
            qty = float(getattr(t, 'quantity', None) or getattr(t, 'total_value', 0.0) / price if price else (getattr(t, 'quantity', 0.0) or 0.0))
            if ms is None or act not in ('buy', 'sell'):
                continue
            norm_trades.append({ 'ms': ms, 'action': act, 'symbol': sym, 'price': price, 'qty': qty })

        norm_trades.sort(key=lambda x: x['ms'])

        # –ü–æ–¥—Å—á—ë—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        num_buys = sum(1 for x in norm_trades if x['action'] == 'buy')
        num_sells = sum(1 for x in norm_trades if x['action'] == 'sell')

        used_sell_idx = set()
        pairs = []
        for i, tb in enumerate(norm_trades):
            if tb['action'] != 'buy':
                continue
            b_buy = bucket_5m(tb['ms'])
            pred_buy = pick_pred(b_buy, tb['symbol'], 'buy')  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
            # –ù–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –ø—Ä–æ–¥–∞–∂—É –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ BUY —Ç–æ–≥–æ –∂–µ —Å–∏–º–≤–æ–ª–∞
            sell_j = None
            next_buy_idx = None
            for j in range(i+1, len(norm_trades)):
                ts = norm_trades[j]
                if ts['symbol'] != tb['symbol']:
                    continue
                if ts['action'] == 'buy':
                    next_buy_idx = j
                    break
            # –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ sell: (i, next_buy_idx) –∏–ª–∏ –¥–æ –∫–æ–Ω—Ü–∞
            end_idx = next_buy_idx if next_buy_idx is not None else len(norm_trades)
            for j in range(i+1, end_idx):
                if j in used_sell_idx:
                    continue
                ts = norm_trades[j]
                if ts['symbol'] != tb['symbol']:
                    continue
                if ts['action'] == 'sell':
                    sell_j = j  # –∑–∞–ø–æ–º–∏–Ω–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø—Ä–æ–¥–∞–∂—É –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            if sell_j is None:
                continue
            if sell_j is None:
                continue
            ts = norm_trades[sell_j]
            b_sell = bucket_5m(ts['ms'])
            pred_sell = pick_pred(b_sell, ts['symbol'], 'sell')  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ

            used_sell_idx.add(sell_j)
            qty = tb['qty'] or ts['qty'] or 0.0
            pnl_abs = (ts['price'] - tb['price']) * qty
            pnl_pct = ((ts['price'] - tb['price']) / tb['price'] * 100.0) if tb['price'] else None

            from datetime import datetime, timezone
            entry_iso = datetime.fromtimestamp(tb['ms']/1000.0, tz=timezone.utc).isoformat()
            exit_iso = datetime.fromtimestamp(ts['ms']/1000.0, tz=timezone.utc).isoformat()

            pairs.append({
                'symbol': tb['symbol'],
                'entry_time': entry_iso,
                'exit_time': exit_iso,
                'entry_price': tb['price'],
                'exit_price': ts['price'],
                'qty': qty,
                'pnl_abs': pnl_abs,
                'pnl_pct': pnl_pct,
                'pred_buy': pred_buy,
                'pred_sell': pred_sell,
            })

        # –î–æ–ø. –æ—Ç–ª–∞–¥–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É
        debug_payload = None
        try:
            if (request.args.get('debug') in ('1','true','yes')):
                app.logger.info(
                    f"[matched_full] trades={len(trades)} norm={len(norm_trades)} (buy={num_buys}/sell={num_sells}) pairs={len(pairs)} preds={len(preds)} symbol={symbol or 'ALL'} tol={tolerance_buckets}"
                )
                from datetime import datetime, timezone
                sample = []
                for it in norm_trades[:10]:
                    sample.append({
                        'time': datetime.fromtimestamp(it['ms']/1000.0, tz=timezone.utc).isoformat(),
                        'action': it['action'],
                        'symbol': it['symbol'],
                        'price': it['price'],
                        'qty': it['qty']
                    })
                debug_payload = {
                    'trades_total': len(trades),
                    'norm_total': len(norm_trades),
                    'norm_buys': num_buys,
                    'norm_sells': num_sells,
                    'pairs_total': len(pairs),
                    'norm_sample': sample,
                }
        except Exception:
            debug_payload = None

        resp = {'success': True, 'pairs': pairs, 'total_pairs': len(pairs)}
        if debug_payload is not None:
            resp['debug'] = debug_payload
        return jsonify(resp), 200

    except Exception as e:
        return jsonify({ 'success': False, 'error': str(e) }), 500

@app.route('/api/analysis/qvalues_vs_pnl', methods=['GET'])
def analysis_qvalues_vs_pnl():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç BUY‚ÜíSELL –ø–∞—Ä —Å P&L –∏ q_values –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä–æ–≥–æ–≤.

    Params:
      symbol: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å–∏–º–≤–æ–ª—É
      limit_trades: –º–∞–∫—Å–∏–º—É–º —Å–¥–µ–ª–æ–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 400)
      limit_predictions: –º–∞–∫—Å–∏–º—É–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 2000)
      tolerance_buckets: –¥–æ–ø—É—Å–∫ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤ 5–º —Å–≤–µ—á–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1)
    """
    try:
        symbol = request.args.get('symbol')
        limit_trades = request.args.get('limit_trades', 400, type=int)
        limit_predictions = request.args.get('limit_predictions', 2000, type=int)
        tolerance_buckets = request.args.get('tolerance_buckets', 1, type=int)

        # –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–≥–∏–∫—É —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        with app.test_request_context(
            f"/api/trades/matched_full?symbol={symbol or ''}&limit_trades={limit_trades}&limit_predictions={limit_predictions}&tolerance_buckets={tolerance_buckets}"
        ):
            resp_raw = get_matched_full_trades()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º (Response | (Response, status))
        if isinstance(resp_raw, tuple):
            resp_obj, status_code = resp_raw
        else:
            resp_obj, status_code = resp_raw, getattr(resp_raw, 'status_code', 200)
        if status_code != 200:
            return resp_obj, status_code
        payload = resp_obj.get_json() or {}
        if not payload.get('success'):
            return jsonify(payload), 200

        rows = []
        counters = {
            'pairs_total': 0,
            'pairs_with_buy_q': 0,
            'pairs_with_sell_q': 0
        }
        for p in payload.get('pairs', []):
            counters['pairs_total'] += 1
            pred_buy = p.get('pred_buy') or {}
            pred_sell = p.get('pred_sell') or {}
            q_vals_buy = pred_buy.get('q_values') or []
            q_vals_sell = pred_sell.get('q_values') or []
            # –Ø–≤–Ω–æ –±–µ—Ä–µ–º Q(BUY) –∏ —Ä–∞–∑—Ä—ã–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ max(HOLD, SELL)
            q_buy = None
            q_buy_gap = None
            try:
                if isinstance(q_vals_buy, list) and len(q_vals_buy) >= 2:
                    q_buy = float(q_vals_buy[1])  # [hold, buy, sell]
                    other = []
                    if len(q_vals_buy) >= 1:
                        other.append(float(q_vals_buy[0]))
                    if len(q_vals_buy) >= 3:
                        other.append(float(q_vals_buy[2]))
                    if other:
                        q_buy_gap = q_buy - max(other)
                    counters['pairs_with_buy_q'] += 1
            except Exception:
                q_buy = None
                q_buy_gap = None

            # –î–ª—è SELL: Q(SELL) –∏ —Ä–∞–∑—Ä—ã–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ max(HOLD, BUY)
            q_sell = None
            q_sell_gap = None
            try:
                if isinstance(q_vals_sell, list) and len(q_vals_sell) >= 3:
                    q_sell = float(q_vals_sell[2])
                    other_s = []
                    if len(q_vals_sell) >= 1:
                        other_s.append(float(q_vals_sell[0]))
                    if len(q_vals_sell) >= 2:
                        other_s.append(float(q_vals_sell[1]))
                    if other_s:
                        q_sell_gap = q_sell - max(other_s)
                    counters['pairs_with_sell_q'] += 1
            except Exception:
                q_sell = None
                q_sell_gap = None

            rows.append({
                'symbol': p.get('symbol'),
                'entry_time': p.get('entry_time'),
                'exit_time': p.get('exit_time'),
                'pnl_abs': p.get('pnl_abs'),
                'pnl_pct': p.get('pnl_pct'),
                'buy_confidence': pred_buy.get('confidence'),
                'sell_confidence': pred_sell.get('confidence'),
                'buy_q_values': q_vals_buy,
                'sell_q_values': pred_sell.get('q_values') or [],
                'buy_max_q': q_buy,
                'buy_gap_q': q_buy_gap,
                'sell_max_q': q_sell,
                'sell_gap_q': q_sell_gap,
            })

        return jsonify({ 'success': True, 'rows': rows, 'total': len(rows), 'counters': counters }), 200

    except Exception as e:
        return jsonify({ 'success': False, 'error': str(e) }), 500

@app.route('/api/analysis/qgate_suggest', methods=['GET'])
def analysis_qgate_suggest():
    """–ü–æ–¥–±–∏—Ä–∞–µ—Ç –ø–æ—Ä–æ–≥–∏ T1/T2 (maxQ/gapQ) –ø–æ —Å–µ—Ç–∫–µ –∫–≤–∞–Ω—Ç–∏–ª–µ–π –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.

    Params: —Ç–∞–∫–∏–µ –∂–µ, –∫–∞–∫ —É /api/analysis/qvalues_vs_pnl
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: { T1, T2, hit_rate, n, score }
    """
    try:
        symbol = request.args.get('symbol')
        limit_trades = request.args.get('limit_trades', 400, type=int)
        limit_predictions = request.args.get('limit_predictions', 2000, type=int)
        tolerance_buckets = request.args.get('tolerance_buckets', 1, type=int)
        metric = request.args.get('metric', 'hit_rate')  # hit_rate | pnl_sum | pnl_per_trade
        min_n = request.args.get('min_n', 20, type=int)
        grid_points = request.args.get('grid_points', 15, type=int)
        side = request.args.get('side', 'buy')  # buy | sell

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        with app.test_request_context(
            f"/api/analysis/qvalues_vs_pnl?symbol={symbol or ''}&limit_trades={limit_trades}&limit_predictions={limit_predictions}&tolerance_buckets={tolerance_buckets}"
        ):
            resp_raw = analysis_qvalues_vs_pnl()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º (Response | (Response, status))
        if isinstance(resp_raw, tuple):
            resp_obj, status_code = resp_raw
        else:
            resp_obj, status_code = resp_raw, getattr(resp_raw, 'status_code', 200)
        if status_code != 200:
            return resp_obj, status_code
        js = resp_obj.get_json() or {}
        if not js.get('success'):
            return jsonify(js), 200

        rows = js.get('rows', [])
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –ø—Ä–æ—Å—Ç—ã–µ –º–∞—Å—Å–∏–≤—ã
        maxqs = []
        gapqs = []
        wins = []
        for r in rows:
            if side == 'sell':
                max_q = r.get('sell_max_q')
                gap_q = r.get('sell_gap_q')
            else:
                max_q = r.get('buy_max_q')
                gap_q = r.get('buy_gap_q')
            pnl_abs = r.get('pnl_abs')
            if max_q is None:
                continue
            maxqs.append(float(max_q))
            gapqs.append(float(gap_q) if gap_q is not None else float('nan'))
            wins.append(1.0 if (pnl_abs is not None and float(pnl_abs) > 0.0) else 0.0)

        if not maxqs:
            return jsonify({ 'success': False, 'error': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö' }), 200

        # –ö–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ —Å–µ—Ç–∫–∏
        def quantiles(arr, qs):
            a = sorted([x for x in arr if not (x is None or (isinstance(x, float) and (x != x)))])
            if not a:
                return []
            res = []
            n = len(a)
            for q in qs:
                if q <= 0:
                    res.append(a[0])
                elif q >= 1:
                    res.append(a[-1])
                else:
                    idx = int(q * (n - 1))
                    res.append(a[idx])
            return res

        gp = max(5, grid_points)
        qs = [0.2 + i*(0.7/(gp-1)) for i in range(gp)]  # 0.2..0.9, gp —Ç–æ—á–µ–∫
        maxq_vals = quantiles(maxqs, qs)
        has_gap = any(not (g != g) for g in gapqs)  # –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –Ω–µ-NaN
        gapq_clean = [g for g in gapqs if not (isinstance(g, float) and (g != g))]
        gapq_vals = quantiles(gapq_clean, qs) if gapq_clean else [0.0]

        best = None
        total = len(maxqs)
        for t1 in maxq_vals:
            for t2 in gapq_vals:
                selected = 0
                wins_sel = 0
                pnl_sum = 0.0
                for i in range(total):
                    ok = (maxqs[i] >= t1)
                    if has_gap and i < len(gapqs) and not (isinstance(gapqs[i], float) and (gapqs[i] != gapqs[i])):
                        ok = ok and (gapqs[i] >= t2)
                    if ok:
                        selected += 1
                        wins_sel += wins[i]
                        # –¥–æ–±–∞–≤–ª—è–µ–º pnl, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                        try:
                            pnl_val = float(rows[i].get('pnl_abs') or 0.0)
                        except Exception:
                            pnl_val = 0.0
                        pnl_sum += pnl_val
                if selected < min_n:
                    continue
                hit = wins_sel / selected if selected > 0 else 0.0
                if metric == 'hit_rate':
                    score = hit * (selected / total)
                elif metric == 'pnl_sum':
                    score = pnl_sum
                else:  # pnl_per_trade
                    score = (pnl_sum / selected) if selected else -1e9
                if (best is None) or (score > best['score']):
                    best = { 'T1': float(t1), 'T2': float(t2), 'hit_rate': float(hit), 'n': int(selected), 'score': float(score), 'pnl_sum': float(pnl_sum), 'pnl_per_trade': float((pnl_sum/selected) if selected else 0.0) }

        if not best:
            # –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ–ª–±—ç–∫ –ø–æ –∫–≤–∞–Ω—Ç–∏–ª—è–º, —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å —Ä–∞–∑—É–º–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–∞–∂–µ –Ω–∞ –º–∞–ª–æ–π –≤—ã–±–æ—Ä–∫–µ
            def quantile_one(arr, q):
                a = sorted([x for x in arr if not (isinstance(x, float) and (x != x))])
                if not a:
                    return None
                if q <= 0:
                    return a[0]
                if q >= 1:
                    return a[-1]
                idx = int(q * (len(a) - 1))
                return a[idx]

            t1_fb = quantile_one(maxqs, 0.7) or maxqs[0]
            t2_fb = quantile_one(gapq_clean if gapq_clean else [0.0], 0.6) if has_gap else 0.0

            # –û—Ü–µ–Ω–∏–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ñ–æ–ª–±—ç–∫–∞
            selected = 0
            wins_sel = 0
            pnl_sum = 0.0
            for i in range(total):
                ok = (maxqs[i] >= t1_fb)
                if has_gap and i < len(gapqs) and not (isinstance(gapqs[i], float) and (gapqs[i] != gapqs[i])):
                    ok = ok and (gapqs[i] >= t2_fb)
                if ok:
                    selected += 1
                    wins_sel += wins[i]
                    try:
                        pnl_val = float(rows[i].get('pnl_abs') or 0.0)
                    except Exception:
                        pnl_val = 0.0
                    pnl_sum += pnl_val
            hit = wins_sel / selected if selected else 0.0
            best = { 'T1': float(t1_fb), 'T2': float(t2_fb), 'hit_rate': float(hit), 'n': int(selected), 'score': float(hit * (selected/total) if total else 0.0), 'pnl_sum': float(pnl_sum), 'pnl_per_trade': float((pnl_sum/selected) if selected else 0.0) }
            approx = True
        else:
            approx = False

        # –°–≤–æ–¥–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –ø–æ win/loss
        def summarize(arr, mask):
            vals = [float(arr[i]) for i in range(len(arr)) if mask[i] and not (isinstance(arr[i], float) and (arr[i] != arr[i]))]
            if not vals:
                return { 'n': 0 }
            vals_sorted = sorted(vals)
            def q(p):
                if not vals_sorted:
                    return None
                idx = int(p * (len(vals_sorted)-1))
                return vals_sorted[idx]
            return {
                'n': len(vals_sorted),
                'mean': sum(vals_sorted)/len(vals_sorted),
                'q10': q(0.1), 'q50': q(0.5), 'q90': q(0.9)
            }

        mask_win = [w == 1.0 for w in wins]
        mask_loss = [w == 0.0 for w in wins]
        summary = {
            'q_buy_win': summarize(maxqs, mask_win),
            'q_buy_loss': summarize(maxqs, mask_loss),
            'gap_win': summarize(gapqs, mask_win),
            'gap_loss': summarize(gapqs, mask_loss)
        }

        env_str = (f"QGATE_{'SELL_' if side=='sell' else ''}MAXQ={best['T1']:.6f} "
                   f"QGATE_{'SELL_' if side=='sell' else ''}GAPQ={best['T2']:.6f}")
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—á–µ—Ç—á–∏–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ q-–∑–Ω–∞—á–µ–Ω–∏–π
        counters = None
        try:
            with app.test_request_context(
                f"/api/analysis/qvalues_vs_pnl?symbol={symbol or ''}&limit_trades={limit_trades}&limit_predictions={limit_predictions}&tolerance_buckets={tolerance_buckets}"
            ):
                resp_raw2 = analysis_qvalues_vs_pnl()
            if isinstance(resp_raw2, tuple):
                resp_obj2, status_code2 = resp_raw2
            else:
                resp_obj2, status_code2 = resp_raw2, getattr(resp_raw2, 'status_code', 200)
            if status_code2 == 200:
                js2 = resp_obj2.get_json() or {}
                counters = js2.get('counters')
        except Exception:
            counters = None

        return jsonify({ 'success': True, 'suggestion': best, 'env': env_str, 'summary': summary, 'side': side, 'approx': approx, 'counters': counters }), 200

    except Exception as e:
        return jsonify({ 'success': False, 'error': str(e) }), 500


@app.route('/api/trading/history', methods=['GET'])
def trading_history():
    """–ò—Å—Ç–æ—Ä–∏—è —Ç–æ—Ä–≥–æ–≤–ª–∏ –±–µ–∑ Docker exec: —á–∏—Ç–∞–µ–º –∏–∑ Redis –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Celery."""
    try:
        # –ß–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ Redis (–∫–∞–∫ –≤ /api/trading/latest_results)
        latest_results = []
        try:
            keys = redis_client.keys('trading:latest_result_*') or []
            for k in keys:
                try:
                    raw = redis_client.get(k)
                    if not raw:
                        continue
                    try:
                        item = json.loads(raw.decode('utf-8'))
                    except Exception:
                        item = json.loads(raw)
                    latest_results.append(item)
                except Exception as e:
                    app.logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {k}: {e}")
        except Exception as e:
            app.logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª—é—á–µ–π trading:latest_result_*: {e}")

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —É–ø—Ä–æ—â—ë–Ω–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
        trades = []
        for r in sorted(latest_results, key=lambda x: x.get('timestamp', ''), reverse=True):
            try:
                tr = r.get('trade_result') or {}
                decision = r.get('decision') or (r.get('parsed_result') or {}).get('action')
                action = None
                if isinstance(tr, dict):
                    # –Ø–≤–Ω–∞—è –º–µ—Ç–∫–∞ –∏–∑ trade_result (hold –∏–ª–∏ —Ñ–∞–∫—Ç —Å–¥–µ–ª–∫–∏)
                    action = tr.get('action') or tr.get('trade_executed')
                if not action:
                    action = decision
                if not action:
                    action = 'hold'
                action = str(action).lower()

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —á–∏—Å—Ç—ã–µ HOLD, —á—Ç–æ–±—ã –∏—Å—Ç–æ—Ä–∏—è –±—ã–ª–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–π
                if action == 'hold':
                    continue

                # –í—Ä–µ–º—è
                tstamp = r.get('timestamp')
                # –¶–µ–Ω–∞
                price = None
                order = tr.get('order') if isinstance(tr, dict) else None
                if isinstance(order, dict):
                    for key in ('price', 'average'):
                        v = order.get(key)
                        if v is not None:
                            try:
                                price = float(v)
                                break
                            except Exception:
                                pass
                    if price is None:
                        info = order.get('info') or {}
                        for key in ('avgPrice', 'lastPrice', 'orderPrice'):
                            v = info.get(key)
                            if v is not None:
                                try:
                                    price = float(v)
                                    break
                                except Exception:
                                    pass
                if price is None:
                    # –§–æ–ª–±—ç–∫: —Ü–µ–Ω–∞ –∏–∑ parsed_result –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                    parsed = r.get('parsed_result') or {}
                    v = parsed.get('price')
                    try:
                        price = float(v) if v is not None else None
                    except Exception:
                        price = None

                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ
                amount = None
                if action.startswith('sell') and isinstance(tr, dict):
                    amount = tr.get('sold_amount') or (tr.get('closed_position') or {}).get('amount')
                if amount is None and isinstance(tr, dict):
                    pos = tr.get('position') or tr.get('remaining_position') or tr.get('closed_position')
                    if isinstance(pos, dict):
                        amount = pos.get('amount')
                # –§–æ–ª–±—ç–∫
                if amount is None:
                    amount = r.get('trade_amount')

                # –°–±–æ—Ä –∑–∞–ø–∏—Å–∏
                trades.append({
                    'time': tstamp,
                    'action': 'sell' if action.startswith('sell') else 'buy',
                    'price': price,
                    'amount': amount
                })
            except Exception:
                continue

        return jsonify({
            'success': True,
            'trades': trades,
            'total_trades': len(trades)
        }), 200

    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ==== –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ —Ä—ã–Ω–∫–∞ (multi-window) —á–µ—Ä–µ–∑ Redis ====
@app.route('/api/trading/regime_config', methods=['GET', 'POST'])
def regime_config():
    """GET ‚Äî –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º—É–ª—å—Ç–∏-–æ–∫–æ–Ω/–ø–æ—Ä–æ–≥–æ–≤, POST ‚Äî —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å.

    JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (–ø—Ä–∏–º–µ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é):
    {
      "windows": [60, 180, 300],
      "weights": [1, 1, 1],
      "voting": "majority",            # majority | weighted
      "tie_break": "flat",             # flat | longest
      "drift_threshold": 0.002,
      "flat_vol_threshold": 0.0025,
      "use_regression": false,
      "reg_slope_min": 0.0,
      "reg_r2_min": 0.2,
      "use_adx": false,
      "adx_period": 14,
      "adx_trend_min": 25
    }
    """
    try:
        import json as _json
        rc = get_redis_client()
        key = 'trading:regime_config'
        if request.method == 'POST':
            cfg = request.get_json(silent=True) or {}
            rc.set(key, _json.dumps(cfg, ensure_ascii=False))
            return jsonify({ 'success': True, 'saved': True, 'config': cfg })
        else:
            raw = rc.get(key)
            if raw:
                try:
                    js = _json.loads(raw)
                except Exception:
                    js = None
            else:
                js = None
            # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if not isinstance(js, dict):
                js = {
                    'windows': [60, 180, 300],
                    'weights': [1, 1, 1],
                    'voting': 'majority',
                    'tie_break': 'flat',
                    'drift_threshold': 0.002,
                    'flat_vol_threshold': 0.0025,
                    'use_regression': False,
                    'reg_slope_min': 0.0,
                    'reg_r2_min': 0.2,
                    'use_adx': False,
                    'adx_period': 14,
                    'adx_trend_min': 25
                }
            return jsonify({ 'success': True, 'config': js })
    except Exception as e:
        return jsonify({ 'success': False, 'error': str(e) }), 500


@app.route('/api/predictions/recent')
def get_recent_predictions():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏"""
    try:
        symbol = request.args.get('symbol')
        action = request.args.get('action')
        limit = int(request.args.get('limit', 50))
        
        # 1) –û—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å: –±–µ—Ä—ë–º –∏–∑ –ë–î
        predictions = get_model_predictions(symbol=symbol, action=action, limit=limit)

        # 2) –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–º–≤–æ–ª–∞ (fallback): BTCUSDT <-> BTC/USDT
        if (not predictions) and symbol:
            try:
                alt = None
                if '/' in symbol:
                    alt = symbol.replace('/', '')
                else:
                    # –≤—Å—Ç–∞–≤–∏–º —Å–ª—ç—à –ø–µ—Ä–µ–¥ USDT/USDC/FDUSD/DAI –∏ —Ç.–ø. (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é USDT)
                    if symbol.upper().endswith('USDT'):
                        alt = symbol[:-4] + '/' + symbol[-4:]
                if alt and alt != symbol:
                    alt_predictions = get_model_predictions(symbol=alt, action=action, limit=limit)
                    if alt_predictions:
                        predictions = alt_predictions
                        symbol = alt  # —Å–æ–æ–±—â–∏–º –≤ –æ—Ç–≤–µ—Ç–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Å–∏–º–≤–æ–ª
            except Exception:
                pass
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        predictions_data = []
        for prediction in predictions or []:
            try:
                q_values = json.loads(prediction.q_values) if prediction.q_values else []
                market_conditions = json.loads(prediction.market_conditions) if prediction.market_conditions else {}
            except:
                q_values = []
                market_conditions = {}
            
            prediction_data = {
                'id': prediction.id,
                'timestamp': prediction.timestamp.isoformat() if prediction.timestamp else None,
                'symbol': prediction.symbol,
                'action': prediction.action,
                'q_values': q_values,
                'current_price': prediction.current_price,
                'position_status': prediction.position_status,
                'confidence': prediction.confidence,
                'model_path': prediction.model_path,
                'market_conditions': market_conditions,
                'created_at': prediction.created_at.isoformat() if prediction.created_at else None
            }
            predictions_data.append(prediction_data)
        
        # 3) –ï—Å–ª–∏ –ë–î –ø—É—Å—Ç–∞ ‚Äî –æ—Ç–¥–∞—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–Ω–∏–º–æ–∫ –∏–∑ Redis (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã celery-trade)
        if len(predictions_data) == 0:
            try:
                from utils.redis_utils import get_redis_client as _get_rc
                _rc = _get_rc()
                keys = sorted(_rc.keys('trading:latest_result_*') or [], reverse=True)
                for k in keys:
                    try:
                        raw = _rc.get(k)
                        if not raw:
                            continue
                        snap = json.loads(raw)
                        preds = snap.get('predictions') or []
                        if not preds:
                            continue
                        ts = snap.get('timestamp')
                        # –í —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö —Å–∏–º–≤–æ–ª –Ω–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è ‚Äî –ø–æ–¥—Å—Ç–∞–≤–∏–º –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π
                        sym_for_resp = symbol or (snap.get('symbols') or [None])[0]
                        for p in preds[:limit]:
                            predictions_data.append({
                                'id': None,
                                'timestamp': ts,
                                'symbol': sym_for_resp,
                                'action': p.get('action'),
                                'q_values': p.get('q_values') or [],
                                'current_price': None,
                                'position_status': None,
                                'confidence': p.get('confidence'),
                                'model_path': p.get('model_path'),
                                'market_conditions': {},
                                'created_at': ts
                            })
                        if predictions_data:
                            break
                    except Exception:
                        continue
            except Exception:
                pass

        return jsonify({
            'success': True,
            'predictions': predictions_data,
            'total_predictions': len(predictions_data)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/predictions/statistics')
def get_prediction_statistics_api():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏"""
    try:
        symbol = request.args.get('symbol')
        stats = get_prediction_statistics(symbol=symbol)
        
        return jsonify({
            'success': True,
            'statistics': stats
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# =============================================================

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ Flask —Å–µ—Ä–≤–µ—Ä–∞
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5050))  # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    debug_mode = os.environ.get("FLASK_DEBUG", "False").lower() == "true"
    print(f"üöÄ –ó–∞–ø—É—Å–∫–∞—é Flask —Å–µ—Ä–≤–µ—Ä –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    print(f"üåê –û—Ç–∫—Ä–æ–π—Ç–µ: http://localhost:{port}")
    print(f"üîß Debug —Ä–µ–∂–∏–º: {'–í–ö–õ–Æ–ß–ï–ù' if debug_mode else '–û–¢–ö–õ–Æ–ß–ï–ù'}")
    
    # –£–±–∏—Ä–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    # init_trading_agent()
    
    app.run(host="0.0.0.0", port=port, debug=debug_mode)
