import os
import logging
import time
import json
from datetime import datetime
from redis import Redis  # type: ignore
import pandas as pd  # type: ignore

from dotenv import load_dotenv, find_dotenv  # type: ignore

from agents.vdqn.v_train_model import train_model
from agents.vdqn.v_train_model_optimized import train_model_optimized

from utils.db_utils import db_get_or_fetch_ohlcv
from utils.db_utils import load_latest_candles_from_csv_to_db
from utils.parser import parser_download_and_combine_with_library
from utils.seed import set_global_seed
from utils.config_loader import get_config_value
from tasks import celery
from agents.vdqn.tianshou_train import train_tianshou_dqn

logger = logging.getLogger(__name__)

# API –∫–ª—é—á–∏ Bybit (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–æ–≤—ã—Ö –∏–º—ë–Ω BYBIT_<N>_*)
def _discover_bybit_api_keys() -> tuple[str | None, str | None]:
    try:
        ak = os.getenv('BYBIT_1_API_KEY')
        sk = os.getenv('BYBIT_1_SECRET_KEY')
        if ak and sk:
            return ak, sk
        # –ê–≤—Ç–æ—Å–∫–∞–Ω: BYBIT_<ID>_API_KEY
        candidates = []
        for k, v in os.environ.items():
            if not k.startswith('BYBIT_') or not k.endswith('_API_KEY'):
                continue
            idx = k[len('BYBIT_'):-len('_API_KEY')]
            sec_name = f'BYBIT_{idx}_SECRET_KEY'
            sec_val = os.getenv(sec_name)
            if v and sec_val:
                candidates.append((k, v, sec_name, sec_val))
        if candidates:
            candidates.sort(key=lambda x: x[0])
            return candidates[0][1], candidates[0][3]
        return None, None
    except Exception:
        return None, None

BYBIT_API_KEY, BYBIT_SECRET_KEY = _discover_bybit_api_keys()

def are_bybit_keys_configured() -> bool:
    try:
        return bool(BYBIT_API_KEY) and bool(BYBIT_SECRET_KEY)
    except Exception:
        return False

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Celery —Å Redis –∫–∞–∫ –±—Ä–æ–∫–µ—Ä–æ–º –∏ –±–µ–∫–µ–Ω–¥–æ–º
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–¥–∞—á

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—á–µ—Ä–µ–¥–∏ –∏ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é –∑–∞–¥–∞—á:
# –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ –∑–∞–¥–∞—á–∏ –∏–¥—É—Ç –≤ –æ—á–µ—Ä–µ–¥—å 'celery',
# –∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ –Ω–∞–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –æ—á–µ—Ä–µ–¥—å 'train'.

@celery.task(bind=True, autoretry_for=(Exception,), retry_kwargs={'max_retries': 0})
def search_lstm_task(self, query):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–æ–ª–≥–æ"""
    self.update_state(state="IN_PROGRESS", meta={"progress": 0})

    for i in range(5):  # –ò–º–∏—Ç–∞—Ü–∏—è –¥–æ–ª–≥–æ–≥–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        time.sleep(2)
        self.update_state(state="IN_PROGRESS", meta={"progress": (i + 1) * 20})

    return {"message": "Task completed!", "query": query}

@celery.task(bind=True, acks_late=False, autoretry_for=(Exception,), retry_kwargs={'max_retries': 0}, queue='train')  # –¥–æ–±–∞–≤–ª–µ–Ω–æ acks_late=False
def train_dqn(self, seed: int | None = None):
    
    self.update_state(state="IN_PROGRESS", meta={"progress": 0})
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∏–¥, –µ—Å–ª–∏ –∑–∞–¥–∞–Ω –∞—Ä–≥—É–º–µ–Ω—Ç–æ–º
    seed = int(seed) if seed is not None else None
    if seed is not None:
        set_global_seed(seed)
        print(f"üîí Seed —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {seed}")
        # ENV –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è —Å–∏–¥–æ–≤

    print("üöÄ –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è...")
    
    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    crypto_symbols = [
        'BTCUSDT',  # –ë–∏—Ç–∫–æ–∏–Ω
        'TONUSDT',  # TON
        'ETHUSDT',  # –≠—Ñ–∏—Ä–∏—É–º
        'SOLUSDT',  # Solana
        'ADAUSDT',  # Cardano
        'BNBUSDT',  # Binance Coin
        'XMRUSDT',  # Monero
        'XRPUSDT'   # Ripple
    ]
    
    all_dfs = {}
    
    for symbol in crypto_symbols:
        try:
            print(f"üì• –ó–∞–≥—Ä—É–∂–∞—é {symbol}...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã
            df_5min = db_get_or_fetch_ohlcv(
                symbol_name=symbol, 
                timeframe='5m', 
                limit_candles=100000,
                exchange_id='bybit'
            )
            
            if df_5min is not None and not df_5min.empty:
                print(f"  ‚úÖ {symbol}: {len(df_5min)} —Å–≤–µ—á–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
                df_5min['datetime'] = pd.to_datetime(df_5min['timestamp'], unit='ms')
                df_5min.set_index('datetime', inplace=True)
                
                # –°–æ–∑–¥–∞–µ–º 15-–º–∏–Ω—É—Ç–Ω—ã–µ –∏ 1-—á–∞—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                df_15min = df_5min.resample('15min').agg({
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last',
                    'volume': 'sum',
                }).dropna().reset_index()
                
                df_1h = df_5min.resample('1h').agg({
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last',
                    'volume': 'sum',
                }).dropna().reset_index()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å
                all_dfs[symbol] = {
                    'df_5min': df_5min,
                    'df_15min': df_15min,
                    'df_1h': df_1h,
                    'symbol': symbol,
                    'candle_count': len(df_5min)
                }
                
            else:
                print(f"  ‚ö†Ô∏è {symbol}: –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                
        except Exception as e:
            print(f"  ‚ùå {symbol}: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ - {e}")
            continue
    
    if not all_dfs:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∏ –¥–ª—è –æ–¥–Ω–æ–π –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã")
        return {"message": "–û—à–∏–±–∫–∞: –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã"}
    
    print(f"\nüìà –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_dfs)} –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π
    for symbol, data in all_dfs.items():
        print(f"  ‚Ä¢ {symbol}: {data['candle_count']} —Å–≤–µ—á–µ–π")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—É –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ç–µ–∫—É—â–∏–º –∫–æ–¥–æ–º
    # –í –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    first_symbol = list(all_dfs.keys())[0]
    df = {
        'df_5min': all_dfs[first_symbol]['df_5min'],
        'df_15min': all_dfs[first_symbol]['df_15min'],
        'df_1h': all_dfs[first_symbol]['df_1h']
    }
    
    # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ df –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
    for key, value in df.items():
        records = value[:2].copy()
        if 'timestamp' in records.columns:
            records['timestamp'] = records['timestamp'].astype(str)
        else:
            for col in records.columns:
                if records[col].dtype.name == 'datetime64[ns]':
                    records[col] = records[col].astype(str)
        print(f"{key}: {json.dumps(records.to_dict(orient='records'), ensure_ascii=False, indent=2)}")
    
    print(f"\nüéØ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {first_symbol}...")
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    episodes = int(os.getenv('DEFAULT_EPISODES', 10000))
    print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤: {episodes}")
    
    result = train_model_optimized(dfs=df, episodes=episodes, seed=seed)
    return {"message": result}

@celery.task(bind=True, acks_late=False, autoretry_for=(Exception,), retry_kwargs={'max_retries': 0}, queue='train')  # –¥–æ–±–∞–≤–ª–µ–Ω–æ acks_late=False
def train_dqn_symbol(self, symbol: str, episodes: int = None, seed: int | None = None, episode_length: int = 2000, engine: str = 'optimized', encoder_id: str | None = None, train_encoder: bool = False):
    """–û–±—É—á–µ–Ω–∏–µ DQN –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ (BTCUSDT/ETHUSDT/...)

    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î, –≥–æ—Ç–æ–≤–∏—Ç 5m/15m/1h, –∑–∞–ø—É—Å–∫–∞–µ—Ç train_model_optimized.
    """
    self.update_state(state="IN_PROGRESS", meta={"progress": 0, "symbol": symbol})

    # –ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: –µ—Å–ª–∏ —ç—Ç–æ—Ç task_id —É–∂–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∞–ª—Å—è, –ø—Ä–æ–ø—É—Å—Ç–∏–º –ø–æ–≤—Ç–æ—Ä–Ω—É—é –¥–æ—Å—Ç–∞–≤–∫—É
    try:
        from utils.redis_utils import get_redis_client  # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç
        _rc = get_redis_client()
        _task_id = getattr(getattr(self, 'request', None), 'id', None)
        if _task_id:
            _done_key = f"celery:train:done:{_task_id}"
            if _rc.get(_done_key):
                return {"message": f"‚è≠Ô∏è –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞ –∑–∞–¥–∞—á–∏ {symbol} –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∞ (—É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞)", "skipped": True}
        # –ë–∏–∑–Ω–µ—Å-–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: —Ç–æ—Ç –∂–µ –Ω–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ–¥–∞–≤–Ω–æ –∑–∞–≤–µ—Ä—à–∞–ª—Å—è ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        _engine = (engine or '').lower()
        _enc = (encoder_id or '-')
        _train_enc = 1 if train_encoder else 0
        _eps = episodes if (episodes is not None) else 'env'
        _ep_len = episode_length if (episode_length is not None) else 'cfg'
        _biz_key = f"{(symbol or '').upper()}|{_engine}|{_enc}|{_train_enc}|{_eps}|{_ep_len}"
        _finished_key = f"celery:train:finished:{_biz_key}"
        _queued_key = f"celery:train:queued:{_biz_key}"
        _running_key_biz = f"celery:train:running:{_biz_key}"
        if _rc.get(_finished_key):
            return {"message": f"‚è≠Ô∏è {symbol}: —Ç–∞–∫–æ–π –∑–∞–ø—É—Å–∫ —É–∂–µ –Ω–µ–¥–∞–≤–Ω–æ –∑–∞–≤–µ—Ä—à–∞–ª—Å—è (–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è)", "skipped": True}
        try:
            # –ü–æ–º–µ—á–∞–µ–º –±–∏–∑–Ω–µ—Å-‚Äòrunning‚Äô –∏ –æ—á–∏—â–∞–µ–º ‚Äòqueued‚Äô (–µ—Å–ª–∏ –±—ã–ª –¥–≤–æ–π–Ω–æ–π –∫–ª–∏–∫)
            _rc.setex(_running_key_biz, 48 * 3600, _task_id or '1')
            _rc.delete(_queued_key)
        except Exception:
            pass
    except Exception:
        pass

    try:
        # –°–∏–¥ –¥–æ –ª—é–±—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–π
        seed = int(seed) if seed is not None else None
        if seed is not None:
            set_global_seed(seed)
            print(f"üîí Seed —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {seed}")
            # ENV –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è —Å–∏–¥–æ–≤

        print(f"\nüöÄ –°—Ç–∞—Ä—Ç –æ–±—É—á–µ–Ω–∏—è –¥–ª—è {symbol} [{datetime.now()}]")
        if encoder_id:
            print(f"üß© –í—ã–±—Ä–∞–Ω —ç–Ω–∫–æ–¥–µ—Ä: {encoder_id} | —Ä–µ–∂–∏–º: {'unfrozen' if train_encoder else 'frozen'}")
        df_5min = db_get_or_fetch_ohlcv(
            symbol_name=symbol,
            timeframe='5m',
            limit_candles=100000,
            exchange_id='bybit'
        )

        if df_5min is None or df_5min.empty:
            # –ü—ã—Ç–∞–µ–º—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∞—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ—á–∏ –≤ –ë–î
            try:
                print(f"üì• –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {symbol}. –ü—ã—Ç–∞—é—Å—å —Å–∫–∞—á–∞—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ –ë–î...")
                csv_file_path = parser_download_and_combine_with_library(
                    symbol=symbol,
                    interval='5m',
                    months_to_fetch=12,
                    desired_candles=100000
                )
                if csv_file_path:
                    loaded_count = load_latest_candles_from_csv_to_db(
                        file_path=csv_file_path,
                        symbol_name=symbol,
                        timeframe='5m'
                    )
                    print(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –ë–î –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {loaded_count} —Å–≤–µ—á–µ–π")
                # –ü–æ–≤—Ç–æ—Ä–Ω–æ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ë–î
                df_5min = db_get_or_fetch_ohlcv(
                    symbol_name=symbol,
                    timeframe='5m',
                    limit_candles=100000,
                    exchange_id='bybit'
                )
            except Exception as fetch_err:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}: {fetch_err}")
                df_5min = None
        
        if df_5min is None or df_5min.empty:
            return {"message": f"‚ùå –î–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"}

        import pandas as pd
        df_5min['datetime'] = pd.to_datetime(df_5min['timestamp'], unit='ms')
        df_5min.set_index('datetime', inplace=True)

        df_15min = df_5min.resample('15min').agg({
            'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last', 'volume': 'sum',
        }).dropna().reset_index()

        df_1h = df_5min.resample('1h').agg({
            'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last', 'volume': 'sum',
        }).dropna().reset_index()

        dfs = {
            'df_5min': df_5min,
            'df_15min': df_15min,
            'df_1h': df_1h,
            'symbol': symbol,
            'encoder': {
                'id': encoder_id,
                'train_encoder': bool(train_encoder),
            },
        }

        print(f"üìà {symbol}: 5m={len(df_5min)}, 15m={len(df_15min)}, 1h={len(df_1h)}")

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
        if episodes is None:
            episodes = int(os.getenv('DEFAULT_EPISODES', 5))
        print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤: {episodes}")

        # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏–Ω—É —ç–ø–∏–∑–æ–¥–∞ –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –∏–ª–∏ GConfig
        if episode_length is None:
            # –ë–µ—Ä–µ–º –∏–∑ GConfig –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            from envs.dqn_model.gym.gconfig import GConfig
            episode_length = GConfig.episode_length
        print(f"üìè –î–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞: {episode_length}")

        # –ü—Ä–æ–∫–∏–¥—ã–≤–∞–µ–º –ø—É—Ç–∏ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –∏–∑ ENV/Redis –µ—Å–ª–∏ –∑–∞–¥–∞–Ω—ã
        load_model_path = os.environ.get('CONTINUE_MODEL_PATH')
        load_buffer_path = os.environ.get('CONTINUE_BUFFER_PATH')
        # –û–ø—Ä–µ–¥–µ–ª–∏–º —Ä–æ–¥–∏—Ç–µ–ª—è/–∫–æ—Ä–µ–Ω—å –¥–ª—è —Ü–µ–ø–æ—á–∫–∏ run'–æ–≤ –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏
        parent_run_id = None
        root_run_id = None
        try:
            # –ü–æ–ø—Ä–æ–±—É–µ–º Redis –∫–∞–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
            r = Redis(host='redis', port=6379, db=0, decode_responses=True)
            v_model = r.get('continue:model_path')
            v_buffer = r.get('continue:buffer_path')
            if v_model:
                load_model_path = v_model
            if v_buffer:
                load_buffer_path = v_buffer
            # –ß–∏—Å—Ç–∏–º –∫–ª—é—á–∏, —á—Ç–æ–±—ã –Ω–µ –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ –¥—Ä—É–≥–∏–µ –∑–∞–¥–∞—á–∏
            if v_model:
                r.delete('continue:model_path')
            if v_buffer:
                r.delete('continue:buffer_path')
        except Exception:
            pass

        # –ï—Å–ª–∏ –¥–æ–æ–±—É—á–∞–µ–º –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏ runs/.../model.pth ‚Äî –ø—Ä–æ—Å—Ç–∞–≤–∏–º —Å–≤—è–∑–∏
        try:
            if isinstance(load_model_path, str):
                norm_path = load_model_path.replace('\\', '/')
                parts = norm_path.split('/')
                if len(parts) >= 4 and parts[-1] == 'model.pth' and 'runs' in parts:
                    runs_idx = parts.index('runs')
                    if runs_idx + 1 < len(parts):
                        parent_run_id = parts[runs_idx + 1]
                        # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å root_id –∏–∑ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞ —Ä–æ–¥–∏—Ç–µ–ª—è
                        try:
                            parent_dir = os.path.dirname(load_model_path)
                            manifest_path = os.path.join(parent_dir, 'manifest.json')
                            if os.path.exists(manifest_path):
                                import json as _json
                                with open(manifest_path, 'r', encoding='utf-8') as mf:
                                    mf_data = _json.load(mf)
                                root_run_id = mf_data.get('root_id') or parent_run_id
                            else:
                                root_run_id = parent_run_id
                        except Exception:
                            root_run_id = parent_run_id
        except Exception:
            parent_run_id = parent_run_id or None
            root_run_id = root_run_id or None

        if (engine or '').lower() in ('ts','tianshou'):
            # –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ Tianshou —Ç—Ä–µ–Ω–µ—Ä
            run_dir = train_tianshou_dqn(
                dfs=dfs,
                episodes=episodes or int(os.getenv('DEFAULT_EPISODES', 5)),
                n_envs=int(get_config_value('TS_NUM_ENVS', '4')),
                batch_size=int(os.getenv('TS_BATCH_SIZE', '256')),
                lr=float(os.getenv('TS_LR', '0.001')),
                gamma=float(os.getenv('TS_GAMMA', '0.99')),
                n_step=int(os.getenv('TS_N_STEP', '1')),
                target_update_freq=int(os.getenv('TS_TARGET_UPDATE', '500')),
                memory_size=int(os.getenv('TS_MEMORY', '500000')),
                episode_length=episode_length,
                run_id=None,
                symbol_hint=symbol,
                parent_run_id=parent_run_id,
                root_id=root_run_id,
                load_model_path=load_model_path,
                load_buffer_path=load_buffer_path,
                save_frequency=int(os.getenv('TS_SAVE_FREQ', '50')),
                buffer_save_frequency=None,
                save_replay_on_improvement=True,
                seed=seed,
            )
            return {"message": f"Tianshou run saved to {run_dir}"}
        else:
            result = train_model_optimized(
                dfs=dfs,
                episodes=episodes,
                load_model_path=load_model_path,
                load_buffer_path=load_buffer_path,
                seed=seed,
                parent_run_id=parent_run_id,
                root_id=root_run_id,
                episode_length=episode_length
            )
        return {"message": f"‚úÖ –û–±—É—á–µ–Ω–∏–µ {symbol} –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {result}"}
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"message": f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è {symbol}: {str(e)}"}
    finally:
        # –°–Ω–∏–º–∞–µ–º per-symbol running_key –∏ —É–¥–∞–ª—è–µ–º —Ç–µ–∫—É—â—É—é –∑–∞–¥–∞—á—É –∏–∑ UI-—Å–ø–∏—Å–∫–∞
        try:
            from utils.redis_utils import get_redis_client  # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç —á—Ç–æ–±—ã –Ω–µ —Ç—è–Ω—É—Ç—å –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            redis_client = get_redis_client()
            running_key = f"celery:train:task:{(symbol or '').upper()}"
            try:
                redis_client.delete(running_key)
            except Exception:
                pass
            # –£–¥–∞–ª—è–µ–º —Ç–µ–∫—É—â–∏–π task_id –∏–∑ ui:tasks
            try:
                ui_tasks_key = "ui:tasks"
                current_task_id = getattr(getattr(self, 'request', None), 'id', None)
                if current_task_id:
                    redis_client.lrem(ui_tasks_key, 0, current_task_id)
                    # –ü–æ–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—É—é –¥–ª—è –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ 24 —á–∞—Å–∞
                    try:
                        redis_client.setex(f"celery:train:done:{current_task_id}", 24 * 3600, "1")
                    except Exception:
                        pass
                # –°–Ω–∏–º–∞–µ–º –±–∏–∑–Ω–µ—Å-‚Äòrunning‚Äô –∏ –æ—Ç–º–µ—á–∞–µ–º ‚Äòfinished‚Äô –ø–æ –Ω–∞–±–æ—Ä—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                try:
                    _engine = (engine or '').lower()
                    _enc = (encoder_id or '-')
                    _train_enc = 1 if train_encoder else 0
                    _eps = episodes if (episodes is not None) else 'env'
                    _ep_len = episode_length if (episode_length is not None) else 'cfg'
                    _biz_key = f"{(symbol or '').upper()}|{_engine}|{_enc}|{_train_enc}|{_eps}|{_ep_len}"
                    _running_key_biz = f"celery:train:running:{_biz_key}"
                    _finished_key = f"celery:train:finished:{_biz_key}"
                    redis_client.delete(_running_key_biz)
                    # TTL ¬´–Ω–µ–¥–∞–≤–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ¬ª: –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1 —á–∞—Å (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å ENV TRAIN_FINISHED_TTL)
                    try:
                        _ttl = int(os.environ.get('TRAIN_FINISHED_TTL', '3600'))
                    except Exception:
                        _ttl = 3600
                    redis_client.setex(_finished_key, max(60, _ttl), '1')
                except Exception:
                    pass
            except Exception:
                pass
        except Exception:
            pass

@celery.task(bind=True, autoretry_for=(Exception,), retry_kwargs={'max_retries': 0}, queue='train')
def train_dqn_multi_crypto(self, episodes: int | None = None, seed: int | None = None, episode_length: int = 2000):
    """–ó–∞–¥–∞—á–∞ –¥–ª—è –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è DQN"""
    self.update_state(state="IN_PROGRESS", meta={"progress": 0})
    # –°–∏–¥ –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞/ENV
    seed = int(seed) if seed is not None else None
    if seed is not None:
        set_global_seed(seed)
        print(f"üîí Seed —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {seed}")
        # ENV –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è —Å–∏–¥–æ–≤

    print("üöÄ –ù–∞—á–∏–Ω–∞—é –º—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ DQN...")
    try:
        # –ù–æ–≤—ã–π –º–æ–¥—É–ª—å –¥–ª—è –º—É–ª—å—Ç–∏-–æ–±—É—á–µ–Ω–∏—è
        from agents.multi.v_train_multi import train_multi
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
        episodes = int(os.getenv('DEFAULT_EPISODES', 10001))
        print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –¥–ª—è –º—É–ª—å—Ç–∏-–æ–±—É—á–µ–Ω–∏—è: {episodes}")

        # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏–Ω—É —ç–ø–∏–∑–æ–¥–∞ –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –∏–ª–∏ GConfig
        if episode_length is None:
            # –ë–µ—Ä–µ–º –∏–∑ GConfig –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            from envs.dqn_model.gym.gconfig import GConfig
            episode_length = GConfig.episode_length
        print(f"üìè –î–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞ –¥–ª—è –º—É–ª—å—Ç–∏-–æ–±—É—á–µ–Ω–∏—è: {episode_length}")
        
        result = train_multi(symbols=[
            'BTCUSDT','TONUSDT','ETHUSDT','SOLUSDT','ADAUSDT','BNBUSDT'
        ], episodes=episodes, episode_length=episode_length)
        return {"message": f"–ú—É–ª—å—Ç–∏–≤–∞–ª—é—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {result}"}
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"message": f"–û—à–∏–±–∫–∞ –º—É–ª—å—Ç–∏-–æ–±—É—á–µ–Ω–∏—è: {str(e)}"}

# --- CNN Training Task ---
@celery.task(bind=True, autoretry_for=(Exception,), retry_kwargs={'max_retries': 0}, queue='train')
def train_cnn_model(self, symbol: str, model_type: str = "multiframe", 
                   seed: int = None):
    """–û–±—É—á–µ–Ω–∏–µ CNN –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç"""
    
    self.update_state(state="IN_PROGRESS", meta={"progress": 0, "symbol": symbol})
    
    try:
        print(f"üß† –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ CNN –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º CNN –º–æ–¥—É–ª–∏
        try:
            from cnn_training.config import CNNTrainingConfig
            from cnn_training.trainer import CNNTrainer
        except ImportError as ie:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ CNN –º–æ–¥—É–ª–µ–π: {ie}")
            raise Exception(f"CNN –º–æ–¥—É–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {ie}")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (–≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ config.py)
        config = CNNTrainingConfig(
            symbols=["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT"],  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            timeframes=["5m", "15m", "1h"],
            device="auto"
        )
        
        # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
        trainer = CNNTrainer(config)
        
        self.update_state(state="IN_PROGRESS", meta={"progress": 20, "message": "CNN —Ç—Ä–µ–Ω–µ—Ä —Å–æ–∑–¥–∞–Ω"})
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å prediction —Ç–∏–ø–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
        print(f"üéØ –û–±—É—á–µ–Ω–∏–µ CNN –º–æ–¥–µ–ª–∏ {model_type} –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤: {config.symbols}")
        
        if model_type == "multiframe":
            # –û–±—É—á–∞–µ–º –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—É—é –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–∞—Ö
            result = trainer.train_multiframe_model(config.symbols)
        else:
            # –û–±—É—á–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è 5m —Ñ—Ä–µ–π–º–∞ (–æ—Å–Ω–æ–≤–Ω–æ–π –¥–ª—è DQN)
            result = trainer.train_single_model(symbol, "5m", model_type)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π –æ—Ç–≤–µ—Ç (–±–µ–∑ PyTorch-–º–æ–¥–µ–ª–µ–π –∏ –ø—Ä–æ—á–∏—Ö –Ω–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤)
        safe_result = None
        try:
            if isinstance(result, dict):
                best_val_accuracy = result.get('best_val_accuracy')
                safe_result = {
                    "best_val_accuracy": float(best_val_accuracy) if best_val_accuracy is not None else None,
                    "train_steps": int(len(result.get('train_losses', []) or [])),
                    "val_steps": int(len(result.get('val_losses', []) or [])),
                }
        except Exception:
            safe_result = {"best_val_accuracy": None, "train_steps": 0, "val_steps": 0}

        self.update_state(state="SUCCESS", meta={
            "progress": 100,
            "message": f"CNN –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –¥–ª—è {symbol}",
            "result": safe_result
        })

        return {
            "success": True,
            "message": f"CNN –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –¥–ª—è {symbol}",
            "symbol": symbol,
            "model_type": model_type,
            "result": safe_result
        }
        
    except Exception as e:
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è CNN –¥–ª—è {symbol}: {str(e)}"
        print(error_msg)
        import traceback
        print(traceback.format_exc())
        
        self.update_state(state="FAILURE", meta={
            "progress": 0,
            "error": error_msg
        })
        
        return {
            "success": False,
            "error": error_msg,
            "symbol": symbol
        }

